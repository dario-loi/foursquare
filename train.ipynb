{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare dataset next-POI Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off we import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as rs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as pl\n",
    "import lightning.pytorch as torchpl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataclasses import dataclass\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define WANDB_NOTEBOOK_NAME\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"dario_nb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "# clean CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# sometimes jupyter notebook does not release memory, we leave this here so a run-all\n",
    "# can *sometimes* fix leaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the data, we utilize `polars` since it is much more efficient than `pandas` and can handle large datasets with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"user\", \"poi\", \"date\", \"TZ\"]\n",
    "data = rs.read_csv(\n",
    "    \"dataset_TIST2015/dataset_TIST2015_Checkins.txt\",\n",
    "    has_header=False,\n",
    "    low_memory=True,\n",
    "    separator=\"\\t\",\n",
    ")\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (33_263_633, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>poi</th><th>date</th><th>TZ</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>50756</td><td>&quot;4f5e3a72e4b053fd6a4313f6&quot;</td><td>&quot;Tue Apr 03 18:00:06 +0000 2012&quot;</td><td>240</td></tr><tr><td>190571</td><td>&quot;4b4b87b5f964a5204a9f26e3&quot;</td><td>&quot;Tue Apr 03 18:00:07 +0000 2012&quot;</td><td>180</td></tr><tr><td>221021</td><td>&quot;4a85b1b3f964a520eefe1fe3&quot;</td><td>&quot;Tue Apr 03 18:00:08 +0000 2012&quot;</td><td>-240</td></tr><tr><td>66981</td><td>&quot;4b4606f2f964a520751426e3&quot;</td><td>&quot;Tue Apr 03 18:00:08 +0000 2012&quot;</td><td>-300</td></tr><tr><td>21010</td><td>&quot;4c2b4e8a9a559c74832f0de2&quot;</td><td>&quot;Tue Apr 03 18:00:09 +0000 2012&quot;</td><td>240</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>16349</td><td>&quot;4c957755c8a1bfb7e89024f3&quot;</td><td>&quot;Mon Sep 16 23:24:11 +0000 2013&quot;</td><td>-240</td></tr><tr><td>256757</td><td>&quot;4c8bbb6d9ef0224bd2d6667b&quot;</td><td>&quot;Mon Sep 16 23:24:13 +0000 2013&quot;</td><td>-180</td></tr><tr><td>66425</td><td>&quot;513e82a5e4b0ed4f0f3bcf2d&quot;</td><td>&quot;Mon Sep 16 23:24:14 +0000 2013&quot;</td><td>-180</td></tr><tr><td>1830</td><td>&quot;4b447865f964a5204cf525e3&quot;</td><td>&quot;Mon Sep 16 23:24:14 +0000 2013&quot;</td><td>120</td></tr><tr><td>22704</td><td>&quot;50df4ee5e4b0c48b5a1c2968&quot;</td><td>&quot;Mon Sep 16 23:24:15 +0000 2013&quot;</td><td>180</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (33_263_633, 4)\n",
       "┌────────┬──────────────────────────┬────────────────────────────────┬──────┐\n",
       "│ user   ┆ poi                      ┆ date                           ┆ TZ   │\n",
       "│ ---    ┆ ---                      ┆ ---                            ┆ ---  │\n",
       "│ i64    ┆ str                      ┆ str                            ┆ i64  │\n",
       "╞════════╪══════════════════════════╪════════════════════════════════╪══════╡\n",
       "│ 50756  ┆ 4f5e3a72e4b053fd6a4313f6 ┆ Tue Apr 03 18:00:06 +0000 2012 ┆ 240  │\n",
       "│ 190571 ┆ 4b4b87b5f964a5204a9f26e3 ┆ Tue Apr 03 18:00:07 +0000 2012 ┆ 180  │\n",
       "│ 221021 ┆ 4a85b1b3f964a520eefe1fe3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -240 │\n",
       "│ 66981  ┆ 4b4606f2f964a520751426e3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -300 │\n",
       "│ 21010  ┆ 4c2b4e8a9a559c74832f0de2 ┆ Tue Apr 03 18:00:09 +0000 2012 ┆ 240  │\n",
       "│ …      ┆ …                        ┆ …                              ┆ …    │\n",
       "│ 16349  ┆ 4c957755c8a1bfb7e89024f3 ┆ Mon Sep 16 23:24:11 +0000 2013 ┆ -240 │\n",
       "│ 256757 ┆ 4c8bbb6d9ef0224bd2d6667b ┆ Mon Sep 16 23:24:13 +0000 2013 ┆ -180 │\n",
       "│ 66425  ┆ 513e82a5e4b0ed4f0f3bcf2d ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ -180 │\n",
       "│ 1830   ┆ 4b447865f964a5204cf525e3 ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ 120  │\n",
       "│ 22704  ┆ 50df4ee5e4b0c48b5a1c2968 ┆ Mon Sep 16 23:24:15 +0000 2013 ┆ 180  │\n",
       "└────────┴──────────────────────────┴────────────────────────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from what suggested by the professor, we utilize the full TIST2015 dataset, which has a far greater scale compared to the reduced NY one. However, by following the pruning steps detailed in the paper (http://dx.doi.org/10.1145/3477495.3531989, section 5.1), we obtain sequences that are much smaller in size, resulting in a dataset that is usable on Google Colab's free tier (as required by the assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users = (\n",
    "    data.lazy()\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        [\n",
    "            rs.col(\"poi\").n_unique().alias(\"n_pois\"),\n",
    "            rs.col(\"poi\").count().alias(\"n_checkins\"),\n",
    "            # turn the rest into a list\n",
    "            rs.col(\"poi\").alias(\"pois\"),\n",
    "            rs.col(\"date\").alias(\"dates\"),\n",
    "            rs.col(\"TZ\").alias(\"TZs\"),\n",
    "        ]\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>133455.0</td><td>56.477459</td><td>124.62537</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>77050.135837</td><td>45.968603</td><td>140.692138</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>66728.0</td><td>30.0</td><td>61.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>133455.0</td><td>49.0</td><td>93.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>200182.0</td><td>71.0</td><td>148.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>1246.0</td><td>5430.0</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬──────────────┬───────────┬────────────┬──────────┬──────────┬──────────┐\n",
       "│ statistic  ┆ user         ┆ n_pois    ┆ n_checkins ┆ pois     ┆ dates    ┆ TZs      │\n",
       "│ ---        ┆ ---          ┆ ---       ┆ ---        ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str        ┆ f64          ┆ f64       ┆ f64        ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞════════════╪══════════════╪═══════════╪════════════╪══════════╪══════════╪══════════╡\n",
       "│ count      ┆ 266909.0     ┆ 266909.0  ┆ 266909.0   ┆ 266909.0 ┆ 266909.0 ┆ 266909.0 │\n",
       "│ null_count ┆ 0.0          ┆ 0.0       ┆ 0.0        ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "│ mean       ┆ 133455.0     ┆ 56.477459 ┆ 124.62537  ┆ null     ┆ null     ┆ null     │\n",
       "│ std        ┆ 77050.135837 ┆ 45.968603 ┆ 140.692138 ┆ null     ┆ null     ┆ null     │\n",
       "│ min        ┆ 1.0          ┆ 1.0       ┆ 1.0        ┆ null     ┆ null     ┆ null     │\n",
       "│ 25%        ┆ 66728.0      ┆ 30.0      ┆ 61.0       ┆ null     ┆ null     ┆ null     │\n",
       "│ 50%        ┆ 133455.0     ┆ 49.0      ┆ 93.0       ┆ null     ┆ null     ┆ null     │\n",
       "│ 75%        ┆ 200182.0     ┆ 71.0      ┆ 148.0      ┆ null     ┆ null     ┆ null     │\n",
       "│ max        ┆ 266909.0     ┆ 1246.0    ┆ 5430.0     ┆ null     ┆ null     ┆ null     │\n",
       "└────────────┴──────────────┴───────────┴────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_culled = data_users.filter(\n",
    "    (rs.col(\"n_checkins\") > 20) & (rs.col(\"n_checkins\") < 50)\n",
    ").drop_nulls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the original dataset is huge, we delete it and call the python garbage collector to free up memory. We then proceed with the second pruning step (frequency-based pruning) as detailed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "del data_users\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique elements from each lists in data_culled[\"pois\"]\n",
    "out = data_culled.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\").list.unique(),\n",
    "        rs.col(\"pois\").list.unique().list.len().alias(\"n_unique_pois\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_697, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th><th>n_unique_pois</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td><td>u32</td></tr></thead><tbody><tr><td>149657</td><td>36</td><td>39</td><td>[&quot;4a68c120f964a520edca1fe3&quot;, &quot;4aa6a083f964a5206c4a20e3&quot;, … &quot;4a95e31ef964a5203c2520e3&quot;]</td><td>[&quot;Sun Aug 12 19:54:01 +0000 2012&quot;, &quot;Sun Aug 19 13:45:35 +0000 2012&quot;, … &quot;Wed Sep 11 22:31:06 +0000 2013&quot;]</td><td>[-300, 180, … 120]</td><td>36</td></tr><tr><td>41566</td><td>21</td><td>23</td><td>[&quot;4b0bc661f964a5208b3323e3&quot;, &quot;4b6d85e9f964a520227a2ce3&quot;, … &quot;51f6957d498efee67b2f2015&quot;]</td><td>[&quot;Thu Apr 04 17:46:08 +0000 2013&quot;, &quot;Sun Apr 07 07:44:52 +0000 2013&quot;, … &quot;Sat Aug 17 12:27:43 +0000 2013&quot;]</td><td>[120, 120, … 120]</td><td>21</td></tr><tr><td>128414</td><td>32</td><td>36</td><td>[&quot;41059b00f964a520850b1fe3&quot;, &quot;4a3da675f964a52093a21fe3&quot;, … &quot;4bc45f05abf49521e2e4c493&quot;]</td><td>[&quot;Wed Apr 11 01:35:21 +0000 2012&quot;, &quot;Wed Apr 11 01:36:41 +0000 2012&quot;, … &quot;Sun Sep 08 21:35:09 +0000 2013&quot;]</td><td>[480, 480, … -240]</td><td>32</td></tr><tr><td>168476</td><td>21</td><td>22</td><td>[&quot;4d4de46280cb6dcb1f2c1601&quot;, &quot;4ba2df43f964a520881f38e3&quot;, … &quot;4d002d84574d60fc938e476c&quot;]</td><td>[&quot;Thu Apr 12 03:25:22 +0000 2012&quot;, &quot;Thu Apr 12 04:55:17 +0000 2012&quot;, … &quot;Fri Aug 17 18:38:33 +0000 2012&quot;]</td><td>[480, 480, … 480]</td><td>21</td></tr><tr><td>23250</td><td>37</td><td>43</td><td>[&quot;40b13b00f964a52023f51ee3&quot;, &quot;4ebfdd226da15b4ddf0a3f2d&quot;, … &quot;4f77371ce4b03b459d303804&quot;]</td><td>[&quot;Mon Apr 16 19:51:24 +0000 2012&quot;, &quot;Mon Apr 16 19:51:43 +0000 2012&quot;, … &quot;Mon Apr 22 23:21:28 +0000 2013&quot;]</td><td>[-240, -240, … -240]</td><td>37</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>137631</td><td>29</td><td>29</td><td>[&quot;4a31751af964a520d7991fe3&quot;, &quot;4a3d0b90f964a520bfa11fe3&quot;, … &quot;4a306132f964a5205b991fe3&quot;]</td><td>[&quot;Sat May 19 17:30:58 +0000 2012&quot;, &quot;Fri Jul 13 00:24:21 +0000 2012&quot;, … &quot;Mon Sep 02 10:49:08 +0000 2013&quot;]</td><td>[-240, -240, … -240]</td><td>29</td></tr><tr><td>173203</td><td>28</td><td>31</td><td>[&quot;4b554e5ef964a52047e127e3&quot;, &quot;4bcd3b1c937ca5934c93ac92&quot;, … &quot;4bac6ed2f964a520e5f43ae3&quot;]</td><td>[&quot;Tue Jun 05 04:45:27 +0000 2012&quot;, &quot;Tue Jun 05 05:49:46 +0000 2012&quot;, … &quot;Thu Sep 05 10:52:34 +0000 2013&quot;]</td><td>[420, 420, … 420]</td><td>28</td></tr><tr><td>253938</td><td>27</td><td>41</td><td>[&quot;4b6c6155f964a52038352ce3&quot;, &quot;4ef0f7e19a52cecf4394e068&quot;, … &quot;4fc7b905e4b08845d9ed275d&quot;]</td><td>[&quot;Wed Sep 05 16:59:28 +0000 2012&quot;, &quot;Wed Sep 05 17:29:59 +0000 2012&quot;, … &quot;Tue Sep 03 17:39:07 +0000 2013&quot;]</td><td>[180, 180, … 180]</td><td>27</td></tr><tr><td>151895</td><td>11</td><td>47</td><td>[&quot;4aa9dde9f964a520755520e3&quot;, &quot;4b7adf2bf964a5209e422fe3&quot;, … &quot;4ccef4adba79a1cd5bdd49cb&quot;]</td><td>[&quot;Thu Jan 03 01:05:47 +0000 2013&quot;, &quot;Thu Jan 03 23:14:03 +0000 2013&quot;, … &quot;Sat Sep 07 20:11:56 +0000 2013&quot;]</td><td>[-360, -360, … -300]</td><td>11</td></tr><tr><td>246525</td><td>23</td><td>42</td><td>[&quot;4f1a7503e4b04ae08214f952&quot;, &quot;5128f71de4b0447ba6ccbd85&quot;, … &quot;4bd11a9977b29c7490368c82&quot;]</td><td>[&quot;Fri Dec 07 13:42:45 +0000 2012&quot;, &quot;Thu Dec 27 09:04:19 +0000 2012&quot;, … &quot;Fri Sep 06 15:43:10 +0000 2013&quot;]</td><td>[120, 120, … 180]</td><td>23</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_697, 7)\n",
       "┌────────┬────────┬────────────┬─────────────────┬────────────────┬────────────────┬───────────────┐\n",
       "│ user   ┆ n_pois ┆ n_checkins ┆ pois            ┆ dates          ┆ TZs            ┆ n_unique_pois │\n",
       "│ ---    ┆ ---    ┆ ---        ┆ ---             ┆ ---            ┆ ---            ┆ ---           │\n",
       "│ i64    ┆ u32    ┆ u32        ┆ list[str]       ┆ list[str]      ┆ list[i64]      ┆ u32           │\n",
       "╞════════╪════════╪════════════╪═════════════════╪════════════════╪════════════════╪═══════════════╡\n",
       "│ 149657 ┆ 36     ┆ 39         ┆ [\"4a68c120f964a ┆ [\"Sun Aug 12   ┆ [-300, 180, …  ┆ 36            │\n",
       "│        ┆        ┆            ┆ 520edca1fe3\",   ┆ 19:54:01 +0000 ┆ 120]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 41566  ┆ 21     ┆ 23         ┆ [\"4b0bc661f964a ┆ [\"Thu Apr 04   ┆ [120, 120, …   ┆ 21            │\n",
       "│        ┆        ┆            ┆ 5208b3323e3\",   ┆ 17:46:08 +0000 ┆ 120]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 128414 ┆ 32     ┆ 36         ┆ [\"41059b00f964a ┆ [\"Wed Apr 11   ┆ [480, 480, …   ┆ 32            │\n",
       "│        ┆        ┆            ┆ 520850b1fe3\",   ┆ 01:35:21 +0000 ┆ -240]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 168476 ┆ 21     ┆ 22         ┆ [\"4d4de46280cb6 ┆ [\"Thu Apr 12   ┆ [480, 480, …   ┆ 21            │\n",
       "│        ┆        ┆            ┆ dcb1f2c1601\",   ┆ 03:25:22 +0000 ┆ 480]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 23250  ┆ 37     ┆ 43         ┆ [\"40b13b00f964a ┆ [\"Mon Apr 16   ┆ [-240, -240, … ┆ 37            │\n",
       "│        ┆        ┆            ┆ 52023f51ee3\",   ┆ 19:51:24 +0000 ┆ -240]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ …      ┆ …      ┆ …          ┆ …               ┆ …              ┆ …              ┆ …             │\n",
       "│ 137631 ┆ 29     ┆ 29         ┆ [\"4a31751af964a ┆ [\"Sat May 19   ┆ [-240, -240, … ┆ 29            │\n",
       "│        ┆        ┆            ┆ 520d7991fe3\",   ┆ 17:30:58 +0000 ┆ -240]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 173203 ┆ 28     ┆ 31         ┆ [\"4b554e5ef964a ┆ [\"Tue Jun 05   ┆ [420, 420, …   ┆ 28            │\n",
       "│        ┆        ┆            ┆ 52047e127e3\",   ┆ 04:45:27 +0000 ┆ 420]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 253938 ┆ 27     ┆ 41         ┆ [\"4b6c6155f964a ┆ [\"Wed Sep 05   ┆ [180, 180, …   ┆ 27            │\n",
       "│        ┆        ┆            ┆ 52038352ce3\",   ┆ 16:59:28 +0000 ┆ 180]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 151895 ┆ 11     ┆ 47         ┆ [\"4aa9dde9f964a ┆ [\"Thu Jan 03   ┆ [-360, -360, … ┆ 11            │\n",
       "│        ┆        ┆            ┆ 520755520e3\",   ┆ 01:05:47 +0000 ┆ -300]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 246525 ┆ 23     ┆ 42         ┆ [\"4f1a7503e4b04 ┆ [\"Fri Dec 07   ┆ [120, 120, …   ┆ 23            │\n",
       "│        ┆        ┆            ┆ ae08214f952\",   ┆ 13:42:45 +0000 ┆ 180]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "└────────┴────────┴────────────┴─────────────────┴────────────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = out[\"pois\"][0].to_list()\n",
    "len(set(l))  # print number of unique POIs in first sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = data_culled[\"pois\"][0].to_list()\n",
    "len(l2)  # print sequence length of first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(l2))  # confirm that the two match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a Polars query to obtain all the frequent POIs, the ones expected to survive the filtering\n",
    "unique_pois = out[\"pois\"]\n",
    "frequent_pois = unique_pois.list.explode().value_counts().filter(rs.col(\"count\") >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;4b7264eff964a520b1792de3&quot;</td><td>13</td></tr><tr><td>&quot;4a86f5baf964a520ca0120e3&quot;</td><td>12</td></tr><tr><td>&quot;4b135e9bf964a520ad9623e3&quot;</td><td>10</td></tr><tr><td>&quot;4b0ce6b2f964a5207e4223e3&quot;</td><td>25</td></tr><tr><td>&quot;4b35a0aaf964a5204a2e25e3&quot;</td><td>10</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4f5b435ae4b0695cb9f5278e&quot;</td><td>10</td></tr><tr><td>&quot;4b59181cf964a5203f7c28e3&quot;</td><td>43</td></tr><tr><td>&quot;45ab7c7af964a52044411fe3&quot;</td><td>15</td></tr><tr><td>&quot;4da9c68a0437dccbd7f40484&quot;</td><td>11</td></tr><tr><td>&quot;4bae5562f964a52017a43be3&quot;</td><td>21</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 2)\n",
       "┌──────────────────────────┬───────┐\n",
       "│ pois                     ┆ count │\n",
       "│ ---                      ┆ ---   │\n",
       "│ str                      ┆ u32   │\n",
       "╞══════════════════════════╪═══════╡\n",
       "│ 4b7264eff964a520b1792de3 ┆ 13    │\n",
       "│ 4a86f5baf964a520ca0120e3 ┆ 12    │\n",
       "│ 4b135e9bf964a520ad9623e3 ┆ 10    │\n",
       "│ 4b0ce6b2f964a5207e4223e3 ┆ 25    │\n",
       "│ 4b35a0aaf964a5204a2e25e3 ┆ 10    │\n",
       "│ …                        ┆ …     │\n",
       "│ 4f5b435ae4b0695cb9f5278e ┆ 10    │\n",
       "│ 4b59181cf964a5203f7c28e3 ┆ 43    │\n",
       "│ 45ab7c7af964a52044411fe3 ┆ 15    │\n",
       "│ 4da9c68a0437dccbd7f40484 ┆ 11    │\n",
       "│ 4bae5562f964a52017a43be3 ┆ 21    │\n",
       "└──────────────────────────┴───────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_pois = frequent_pois[\"pois\"]\n",
    "frequent_pois = set(frequent_pois.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_697, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td></tr></thead><tbody><tr><td>149657</td><td>36</td><td>39</td><td>[&quot;4a837790f964a52037fb1fe3&quot;, &quot;5030ed47e4b08345cd889459&quot;, … &quot;522f30d011d2eff1eb2cfbf7&quot;]</td><td>[&quot;Sun Aug 12 19:54:01 +0000 2012&quot;, &quot;Sun Aug 19 13:45:35 +0000 2012&quot;, … &quot;Wed Sep 11 22:31:06 +0000 2013&quot;]</td><td>[-300, 180, … 120]</td></tr><tr><td>41566</td><td>21</td><td>23</td><td>[&quot;4b05886af964a52055c422e3&quot;, &quot;516052dde4b082ab16a96008&quot;, … &quot;4b2a81d5f964a52081aa24e3&quot;]</td><td>[&quot;Thu Apr 04 17:46:08 +0000 2013&quot;, &quot;Sun Apr 07 07:44:52 +0000 2013&quot;, … &quot;Sat Aug 17 12:27:43 +0000 2013&quot;]</td><td>[120, 120, … 120]</td></tr><tr><td>128414</td><td>32</td><td>36</td><td>[&quot;4bc556f15935c9b640dfa5d2&quot;, &quot;4f81321de4b0a458bac037ac&quot;, … &quot;4d0a9fe6d8d78cfa36dd17be&quot;]</td><td>[&quot;Wed Apr 11 01:35:21 +0000 2012&quot;, &quot;Wed Apr 11 01:36:41 +0000 2012&quot;, … &quot;Sun Sep 08 21:35:09 +0000 2013&quot;]</td><td>[480, 480, … -240]</td></tr><tr><td>168476</td><td>21</td><td>22</td><td>[&quot;4f4acf30e4b0927adb4174fd&quot;, &quot;4d002d84574d60fc938e476c&quot;, … &quot;4d1b255a6526a35d8d140d16&quot;]</td><td>[&quot;Thu Apr 12 03:25:22 +0000 2012&quot;, &quot;Thu Apr 12 04:55:17 +0000 2012&quot;, … &quot;Fri Aug 17 18:38:33 +0000 2012&quot;]</td><td>[480, 480, … 480]</td></tr><tr><td>23250</td><td>37</td><td>43</td><td>[&quot;4459d2f1f964a520d7321fe3&quot;, &quot;4b8baecef964a520d8a632e3&quot;, … &quot;4b57c21bf964a520963f28e3&quot;]</td><td>[&quot;Mon Apr 16 19:51:24 +0000 2012&quot;, &quot;Mon Apr 16 19:51:43 +0000 2012&quot;, … &quot;Mon Apr 22 23:21:28 +0000 2013&quot;]</td><td>[-240, -240, … -240]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>137631</td><td>29</td><td>29</td><td>[&quot;4dd2f9cc18381e5587c09f64&quot;, &quot;4e5022e5922e36d08cac37fc&quot;, … &quot;4d4c74db5f9db60cfea73550&quot;]</td><td>[&quot;Sat May 19 17:30:58 +0000 2012&quot;, &quot;Fri Jul 13 00:24:21 +0000 2012&quot;, … &quot;Mon Sep 02 10:49:08 +0000 2013&quot;]</td><td>[-240, -240, … -240]</td></tr><tr><td>173203</td><td>28</td><td>31</td><td>[&quot;4bebde1561aca5933c798500&quot;, &quot;4bcd3b1c937ca5934c93ac92&quot;, … &quot;4f968020e4b07ffbb215c367&quot;]</td><td>[&quot;Tue Jun 05 04:45:27 +0000 2012&quot;, &quot;Tue Jun 05 05:49:46 +0000 2012&quot;, … &quot;Thu Sep 05 10:52:34 +0000 2013&quot;]</td><td>[420, 420, … 420]</td></tr><tr><td>253938</td><td>27</td><td>41</td><td>[&quot;4d2edc844377224bf7f71138&quot;, &quot;4fcbf94ae4b0928dc23a5fd1&quot;, … &quot;508830f2e4b00a726d98b053&quot;]</td><td>[&quot;Wed Sep 05 16:59:28 +0000 2012&quot;, &quot;Wed Sep 05 17:29:59 +0000 2012&quot;, … &quot;Tue Sep 03 17:39:07 +0000 2013&quot;]</td><td>[180, 180, … 180]</td></tr><tr><td>151895</td><td>11</td><td>47</td><td>[&quot;4ae38bbff964a5207a9621e3&quot;, &quot;4b1559d8f964a52066ab23e3&quot;, … &quot;4b9d317ef964a5201a9836e3&quot;]</td><td>[&quot;Thu Jan 03 01:05:47 +0000 2013&quot;, &quot;Thu Jan 03 23:14:03 +0000 2013&quot;, … &quot;Sat Sep 07 20:11:56 +0000 2013&quot;]</td><td>[-360, -360, … -300]</td></tr><tr><td>246525</td><td>23</td><td>42</td><td>[&quot;4fd4f98ee4b02bbdc63f9432&quot;, &quot;4bd11a9977b29c7490368c82&quot;, … &quot;4bd11a9977b29c7490368c82&quot;]</td><td>[&quot;Fri Dec 07 13:42:45 +0000 2012&quot;, &quot;Thu Dec 27 09:04:19 +0000 2012&quot;, … &quot;Fri Sep 06 15:43:10 +0000 2013&quot;]</td><td>[120, 120, … 180]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_697, 6)\n",
       "┌────────┬────────┬────────────┬──────────────────────┬──────────────────────┬─────────────────────┐\n",
       "│ user   ┆ n_pois ┆ n_checkins ┆ pois                 ┆ dates                ┆ TZs                 │\n",
       "│ ---    ┆ ---    ┆ ---        ┆ ---                  ┆ ---                  ┆ ---                 │\n",
       "│ i64    ┆ u32    ┆ u32        ┆ list[str]            ┆ list[str]            ┆ list[i64]           │\n",
       "╞════════╪════════╪════════════╪══════════════════════╪══════════════════════╪═════════════════════╡\n",
       "│ 149657 ┆ 36     ┆ 39         ┆ [\"4a837790f964a52037 ┆ [\"Sun Aug 12         ┆ [-300, 180, … 120]  │\n",
       "│        ┆        ┆            ┆ fb1fe3\", \"…          ┆ 19:54:01 +0000 20…   ┆                     │\n",
       "│ 41566  ┆ 21     ┆ 23         ┆ [\"4b05886af964a52055 ┆ [\"Thu Apr 04         ┆ [120, 120, … 120]   │\n",
       "│        ┆        ┆            ┆ c422e3\", \"…          ┆ 17:46:08 +0000 20…   ┆                     │\n",
       "│ 128414 ┆ 32     ┆ 36         ┆ [\"4bc556f15935c9b640 ┆ [\"Wed Apr 11         ┆ [480, 480, … -240]  │\n",
       "│        ┆        ┆            ┆ dfa5d2\", \"…          ┆ 01:35:21 +0000 20…   ┆                     │\n",
       "│ 168476 ┆ 21     ┆ 22         ┆ [\"4f4acf30e4b0927adb ┆ [\"Thu Apr 12         ┆ [480, 480, … 480]   │\n",
       "│        ┆        ┆            ┆ 4174fd\", \"…          ┆ 03:25:22 +0000 20…   ┆                     │\n",
       "│ 23250  ┆ 37     ┆ 43         ┆ [\"4459d2f1f964a520d7 ┆ [\"Mon Apr 16         ┆ [-240, -240, …      │\n",
       "│        ┆        ┆            ┆ 321fe3\", \"…          ┆ 19:51:24 +0000 20…   ┆ -240]               │\n",
       "│ …      ┆ …      ┆ …          ┆ …                    ┆ …                    ┆ …                   │\n",
       "│ 137631 ┆ 29     ┆ 29         ┆ [\"4dd2f9cc18381e5587 ┆ [\"Sat May 19         ┆ [-240, -240, …      │\n",
       "│        ┆        ┆            ┆ c09f64\", \"…          ┆ 17:30:58 +0000 20…   ┆ -240]               │\n",
       "│ 173203 ┆ 28     ┆ 31         ┆ [\"4bebde1561aca5933c ┆ [\"Tue Jun 05         ┆ [420, 420, … 420]   │\n",
       "│        ┆        ┆            ┆ 798500\", \"…          ┆ 04:45:27 +0000 20…   ┆                     │\n",
       "│ 253938 ┆ 27     ┆ 41         ┆ [\"4d2edc844377224bf7 ┆ [\"Wed Sep 05         ┆ [180, 180, … 180]   │\n",
       "│        ┆        ┆            ┆ f71138\", \"…          ┆ 16:59:28 +0000 20…   ┆                     │\n",
       "│ 151895 ┆ 11     ┆ 47         ┆ [\"4ae38bbff964a5207a ┆ [\"Thu Jan 03         ┆ [-360, -360, …      │\n",
       "│        ┆        ┆            ┆ 9621e3\", \"…          ┆ 01:05:47 +0000 20…   ┆ -300]               │\n",
       "│ 246525 ┆ 23     ┆ 42         ┆ [\"4fd4f98ee4b02bbdc6 ┆ [\"Fri Dec 07         ┆ [120, 120, … 180]   │\n",
       "│        ┆        ┆            ┆ 3f9432\", \"…          ┆ 13:42:45 +0000 20…   ┆                     │\n",
       "└────────┴────────┴────────────┴──────────────────────┴──────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_culled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_culled = data_culled.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\")\n",
    "        .list.eval(\n",
    "            rs.element().is_in(frequent_pois),\n",
    "        )\n",
    "        .alias(\"is_frequent\")\n",
    "    ]\n",
    ")  # prep mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = (\n",
    "    data_culled.lazy()\n",
    "    .with_row_index()\n",
    "    .explode(\n",
    "        [\n",
    "            \"pois\",\n",
    "            \"dates\",\n",
    "            \"TZs\",\n",
    "            \"is_frequent\",\n",
    "        ]\n",
    "    )\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        [\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).alias(\"pois\"),\n",
    "            rs.col(\"dates\").filter(rs.col(\"is_frequent\")).alias(\"dates\"),\n",
    "            rs.col(\"TZs\").filter(rs.col(\"is_frequent\")).alias(\"TZs\"),\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).n_unique().alias(\"n_pois\"),\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).count().alias(\"n_checkins\"),\n",
    "        ]\n",
    "    )\n",
    "    .filter(rs.col(\"n_checkins\") > 0)\n",
    "    .filter(rs.col(\"n_pois\") > 0)\n",
    "    .collect()\n",
    ")  # filter out infrequent pois and users with no pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>pois</th><th>dates</th><th>TZs</th><th>n_pois</th><th>n_checkins</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>156852.822274</td><td>null</td><td>null</td><td>null</td><td>6.123452</td><td>8.831437</td></tr><tr><td>&quot;std&quot;</td><td>76314.892884</td><td>null</td><td>null</td><td>null</td><td>4.609024</td><td>6.877662</td></tr><tr><td>&quot;min&quot;</td><td>49.0</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>95613.0</td><td>null</td><td>null</td><td>null</td><td>3.0</td><td>4.0</td></tr><tr><td>&quot;50%&quot;</td><td>167846.0</td><td>null</td><td>null</td><td>null</td><td>5.0</td><td>7.0</td></tr><tr><td>&quot;75%&quot;</td><td>224576.0</td><td>null</td><td>null</td><td>null</td><td>8.0</td><td>12.0</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>null</td><td>null</td><td>null</td><td>32.0</td><td>46.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬───────────────┬─────────┬─────────┬─────────┬──────────┬────────────┐\n",
       "│ statistic  ┆ user          ┆ pois    ┆ dates   ┆ TZs     ┆ n_pois   ┆ n_checkins │\n",
       "│ ---        ┆ ---           ┆ ---     ┆ ---     ┆ ---     ┆ ---      ┆ ---        │\n",
       "│ str        ┆ f64           ┆ f64     ┆ f64     ┆ f64     ┆ f64      ┆ f64        │\n",
       "╞════════════╪═══════════════╪═════════╪═════════╪═════════╪══════════╪════════════╡\n",
       "│ count      ┆ 19862.0       ┆ 19862.0 ┆ 19862.0 ┆ 19862.0 ┆ 19862.0  ┆ 19862.0    │\n",
       "│ null_count ┆ 0.0           ┆ 0.0     ┆ 0.0     ┆ 0.0     ┆ 0.0      ┆ 0.0        │\n",
       "│ mean       ┆ 156852.822274 ┆ null    ┆ null    ┆ null    ┆ 6.123452 ┆ 8.831437   │\n",
       "│ std        ┆ 76314.892884  ┆ null    ┆ null    ┆ null    ┆ 4.609024 ┆ 6.877662   │\n",
       "│ min        ┆ 49.0          ┆ null    ┆ null    ┆ null    ┆ 1.0      ┆ 1.0        │\n",
       "│ 25%        ┆ 95613.0       ┆ null    ┆ null    ┆ null    ┆ 3.0      ┆ 4.0        │\n",
       "│ 50%        ┆ 167846.0      ┆ null    ┆ null    ┆ null    ┆ 5.0      ┆ 7.0        │\n",
       "│ 75%        ┆ 224576.0      ┆ null    ┆ null    ┆ null    ┆ 8.0      ┆ 12.0       │\n",
       "│ max        ┆ 266909.0      ┆ null    ┆ null    ┆ null    ┆ 32.0     ┆ 46.0       │\n",
       "└────────────┴───────────────┴─────────┴─────────┴─────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, culling is done, we can appreciate that `polars`'s SQL/functional-style API is different from Pandas, but it is very powerful and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is geohashing the POIs, that is, we want to convert the latitude-longitude positions of the POIs into a grid-based geohash representation, which will form the basis for our network's embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash2 as gh\n",
    "\n",
    "pois = rs.read_csv(\n",
    "    \"dataset_TIST2015/dataset_TIST2015_POIs.txt\",\n",
    "    has_header=False,\n",
    "    low_memory=True,\n",
    "    separator=\"\\t\",\n",
    ")\n",
    "pois.columns = [\"poi\", \"lat\", \"long\", \"category\", \"country\"]\n",
    "pois = pois.drop(\"category\").drop(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = (\n",
    "    pois.lazy()\n",
    "    .filter(rs.col(\"poi\").is_in(frequent_pois))\n",
    "    .select(\n",
    "        [\n",
    "            rs.col(\"poi\"),\n",
    "            rs.struct(\n",
    "                [\n",
    "                    rs.col(\"lat\").cast(rs.Float32),\n",
    "                    rs.col(\"long\").cast(rs.Float32),\n",
    "                ]\n",
    "            )\n",
    "            .alias(\"location\")\n",
    "            .map_elements(\n",
    "                lambda s: gh.encode(s[\"lat\"], s[\"long\"], precision=6),\n",
    "                return_dtype=rs.String,\n",
    "            )\n",
    "            .alias(\"geohash\"),\n",
    "        ]\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "poi_geo_dict = dict(zip(pois[\"poi\"], pois[\"geohash\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row in final_data, add the geohash of the pois by hitting the poi_geo_dict\n",
    "\n",
    "final_data = final_data.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\")\n",
    "        .map_elements(\n",
    "            lambda s: [poi_geo_dict[s] for s in s],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "        .alias(\"geohashes\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thu Jul 05 22:51:35 +0000 2012',\n",
       " 'Sun Aug 12 16:47:05 +0000 2012',\n",
       " 'Wed Sep 05 22:48:13 +0000 2012',\n",
       " 'Wed Sep 05 22:54:21 +0000 2012',\n",
       " 'Fri Oct 12 23:28:25 +0000 2012',\n",
       " 'Sun Oct 28 02:00:24 +0000 2012',\n",
       " 'Thu Nov 22 03:44:13 +0000 2012',\n",
       " 'Sun Dec 09 17:38:36 +0000 2012',\n",
       " 'Fri Jan 18 17:08:59 +0000 2013',\n",
       " 'Mon Jan 21 18:09:23 +0000 2013',\n",
       " 'Mon Jan 21 18:21:09 +0000 2013']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"dates\"][79].to_list()  # check out a temporal sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-240, -240, -240, -240, -240, -240, -300, -300, -300, -300, -300]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"TZs\"][79].to_list()  # ... and the corresponding timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work *might* seem over, however, we still have timezones to account for, we want to normalize everything according to GMT, so we convert the timestamps accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def UTC_to_local(utc, tz):\n",
    "\n",
    "    date = datetime.datetime.strptime(utc, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    date = date.replace(tzinfo=datetime.timezone.utc)\n",
    "\n",
    "    # shift by tz offset\n",
    "    date = date.astimezone(datetime.timezone(datetime.timedelta(minutes=tz)))\n",
    "\n",
    "    date_s = datetime.datetime.strftime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return date_s\n",
    "\n",
    "\n",
    "def to_UNIX_time(date):\n",
    "    return datetime.datetime.strptime(\n",
    "        date, \"%Y-%m-%d %H:%M:%S\"\n",
    "    ).timestamp()  # we use UNIX time as a key for sorting the POIs in our polars query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-05-21 08:53:01'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UTC_to_local(\"Mon May 21 15:53:01 +0000 2012\", -420)  # example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.with_columns(\n",
    "    [\n",
    "        rs.struct([rs.col(\"dates\"), rs.col(\"TZs\")])\n",
    "        .alias(\"times\")\n",
    "        .map_elements(\n",
    "            lambda struct: [\n",
    "                UTC_to_local(date, tz)\n",
    "                for date, tz in zip(struct[\"dates\"], struct[\"TZs\"])\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "    ]\n",
    ")  # This performs timezone conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sorted = final_data.select(  # sort the times\n",
    "    [\n",
    "        rs.col(\"user\"),\n",
    "        rs.struct(\n",
    "            [\n",
    "                rs.col(\"pois\"),\n",
    "                rs.col(\"times\"),\n",
    "            ]\n",
    "        ).map_elements(\n",
    "            lambda struct: [\n",
    "                poi\n",
    "                for poi, _ in sorted(\n",
    "                    zip(  # here we sort the POIs struct by UNIX timestamps of the GMT times\n",
    "                        struct[\"pois\"], [to_UNIX_time(date) for date in struct[\"times\"]]\n",
    "                    ),\n",
    "                    key=lambda s: s[1],\n",
    "                )\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        ),\n",
    "        rs.struct(\n",
    "            [\n",
    "                rs.col(\"geohashes\"),\n",
    "                rs.col(\"times\"),\n",
    "            ]\n",
    "        ).map_elements(\n",
    "            lambda struct: [\n",
    "                geo\n",
    "                for geo, _ in sorted(\n",
    "                    zip(\n",
    "                        struct[\"geohashes\"],  # same thing goes on for geohashes\n",
    "                        [to_UNIX_time(date) for date in struct[\"times\"]],\n",
    "                    ),\n",
    "                    key=lambda s: s[1],\n",
    "                )\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        ),\n",
    "        rs.col(\"times\")\n",
    "        .map_elements(\n",
    "            lambda dates: sorted(dates, key=to_UNIX_time),\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "        .alias(\"times_sorted\"),\n",
    "        rs.col(\"n_checkins\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# P.S, admittedly, it would have been more efficient to encode the geohashes *after* sorting the POIs,\n",
    "# so that we could save on the sorting of the geohashes. Tough luck, you can't win 'em all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (19_862, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>pois</th><th>geohashes</th><th>times_sorted</th><th>n_checkins</th></tr><tr><td>i64</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>u32</td></tr></thead><tbody><tr><td>173901</td><td>[&quot;4ba64cdff964a520e04339e3&quot;, &quot;4e4866437d8b91a065a9a2df&quot;, … &quot;4e4866437d8b91a065a9a2df&quot;]</td><td>[&quot;sxk90z&quot;, &quot;sxk928&quot;, … &quot;sxk928&quot;]</td><td>[&quot;2013-07-28 19:08:48&quot;, &quot;2013-07-29 17:08:01&quot;, … &quot;2013-09-16 16:45:15&quot;]</td><td>21</td></tr><tr><td>23804</td><td>[&quot;4b5775bff964a520dd3728e3&quot;, &quot;4b5775bff964a520dd3728e3&quot;]</td><td>[&quot;9ewmyf&quot;, &quot;9ewmyf&quot;]</td><td>[&quot;2012-09-14 19:45:44&quot;, &quot;2012-09-15 11:49:13&quot;]</td><td>2</td></tr><tr><td>153405</td><td>[&quot;4b19f837f964a520a2e623e3&quot;, &quot;4b42a9c9f964a5206dd825e3&quot;, … &quot;4b42a9c9f964a5206dd825e3&quot;]</td><td>[&quot;xn77ht&quot;, &quot;xn76g1&quot;, … &quot;xn76g1&quot;]</td><td>[&quot;2013-01-27 06:19:06&quot;, &quot;2013-07-01 22:27:22&quot;, … &quot;2013-08-27 23:32:08&quot;]</td><td>22</td></tr><tr><td>118523</td><td>[&quot;4c97edbdf419a09395806b88&quot;, &quot;4a513b17f964a520d2b01fe3&quot;, … &quot;45d3780ff964a520be421fe3&quot;]</td><td>[&quot;dr5rm0&quot;, &quot;dr5x83&quot;, … &quot;dqcjpx&quot;]</td><td>[&quot;2012-05-16 17:45:42&quot;, &quot;2012-05-18 19:49:42&quot;, … &quot;2013-09-07 15:53:49&quot;]</td><td>7</td></tr><tr><td>55399</td><td>[&quot;4b297be1f964a520ad9f24e3&quot;, &quot;4b0f9c5cf964a5209f6323e3&quot;, … &quot;4dd04fcd183899ddfb02624c&quot;]</td><td>[&quot;xn739r&quot;, &quot;xn739m&quot;, … &quot;xn774c&quot;]</td><td>[&quot;2012-04-25 20:10:24&quot;, &quot;2012-04-25 20:26:34&quot;, … &quot;2013-05-30 20:37:23&quot;]</td><td>19</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>22734</td><td>[&quot;3fd66200f964a520ddf01ee3&quot;, &quot;3fd66200f964a520ddf01ee3&quot;, … &quot;4459d2f1f964a520d7321fe3&quot;]</td><td>[&quot;dr72mb&quot;, &quot;dr72mb&quot;, … &quot;dr5r2p&quot;]</td><td>[&quot;2012-04-29 12:43:40&quot;, &quot;2012-05-13 12:22:06&quot;, … &quot;2013-07-23 10:18:19&quot;]</td><td>11</td></tr><tr><td>90265</td><td>[&quot;4b925aeff964a5200ef433e3&quot;, &quot;4b925aeff964a5200ef433e3&quot;, … &quot;4b56c29ff964a520871a28e3&quot;]</td><td>[&quot;u20fbg&quot;, &quot;u20fbg&quot;, … &quot;u1j16n&quot;]</td><td>[&quot;2012-04-27 19:38:56&quot;, &quot;2012-05-11 23:11:01&quot;, … &quot;2013-09-08 22:44:53&quot;]</td><td>18</td></tr><tr><td>212611</td><td>[&quot;4b723eeef964a5206d752de3&quot;, &quot;4b0588c9f964a52034da22e3&quot;, … &quot;4c217a8034faef3b396d586d&quot;]</td><td>[&quot;6gycc7&quot;, &quot;6gyf5r&quot;, … &quot;6ztxb8&quot;]</td><td>[&quot;2012-04-07 17:45:04&quot;, &quot;2012-06-26 14:25:42&quot;, … &quot;2012-08-09 13:40:06&quot;]</td><td>7</td></tr><tr><td>141099</td><td>[&quot;4c217a8034faef3b396d586d&quot;, &quot;4bae2e91f964a520c98e3be3&quot;, … &quot;4b2d0e1af964a52037cd24e3&quot;]</td><td>[&quot;6ztxb8&quot;, &quot;6u35eg&quot;, … &quot;6gycd7&quot;]</td><td>[&quot;2012-08-10 15:04:17&quot;, &quot;2012-11-16 13:45:37&quot;, … &quot;2013-07-21 14:37:34&quot;]</td><td>20</td></tr><tr><td>113503</td><td>[&quot;4b0586c9f964a520a26e22e3&quot;]</td><td>[&quot;dhvr44&quot;]</td><td>[&quot;2012-07-08 12:03:22&quot;]</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (19_862, 5)\n",
       "┌────────┬──────────────────────────────┬────────────────────────┬────────────────────┬────────────┐\n",
       "│ user   ┆ pois                         ┆ geohashes              ┆ times_sorted       ┆ n_checkins │\n",
       "│ ---    ┆ ---                          ┆ ---                    ┆ ---                ┆ ---        │\n",
       "│ i64    ┆ list[str]                    ┆ list[str]              ┆ list[str]          ┆ u32        │\n",
       "╞════════╪══════════════════════════════╪════════════════════════╪════════════════════╪════════════╡\n",
       "│ 173901 ┆ [\"4ba64cdff964a520e04339e3\", ┆ [\"sxk90z\", \"sxk928\", … ┆ [\"2013-07-28       ┆ 21         │\n",
       "│        ┆ \"…                           ┆ \"sxk928…               ┆ 19:08:48\", \"2013-… ┆            │\n",
       "│ 23804  ┆ [\"4b5775bff964a520dd3728e3\", ┆ [\"9ewmyf\", \"9ewmyf\"]   ┆ [\"2012-09-14       ┆ 2          │\n",
       "│        ┆ \"…                           ┆                        ┆ 19:45:44\", \"2012-… ┆            │\n",
       "│ 153405 ┆ [\"4b19f837f964a520a2e623e3\", ┆ [\"xn77ht\", \"xn76g1\", … ┆ [\"2013-01-27       ┆ 22         │\n",
       "│        ┆ \"…                           ┆ \"xn76g1…               ┆ 06:19:06\", \"2013-… ┆            │\n",
       "│ 118523 ┆ [\"4c97edbdf419a09395806b88\", ┆ [\"dr5rm0\", \"dr5x83\", … ┆ [\"2012-05-16       ┆ 7          │\n",
       "│        ┆ \"…                           ┆ \"dqcjpx…               ┆ 17:45:42\", \"2012-… ┆            │\n",
       "│ 55399  ┆ [\"4b297be1f964a520ad9f24e3\", ┆ [\"xn739r\", \"xn739m\", … ┆ [\"2012-04-25       ┆ 19         │\n",
       "│        ┆ \"…                           ┆ \"xn774c…               ┆ 20:10:24\", \"2012-… ┆            │\n",
       "│ …      ┆ …                            ┆ …                      ┆ …                  ┆ …          │\n",
       "│ 22734  ┆ [\"3fd66200f964a520ddf01ee3\", ┆ [\"dr72mb\", \"dr72mb\", … ┆ [\"2012-04-29       ┆ 11         │\n",
       "│        ┆ \"…                           ┆ \"dr5r2p…               ┆ 12:43:40\", \"2012-… ┆            │\n",
       "│ 90265  ┆ [\"4b925aeff964a5200ef433e3\", ┆ [\"u20fbg\", \"u20fbg\", … ┆ [\"2012-04-27       ┆ 18         │\n",
       "│        ┆ \"…                           ┆ \"u1j16n…               ┆ 19:38:56\", \"2012-… ┆            │\n",
       "│ 212611 ┆ [\"4b723eeef964a5206d752de3\", ┆ [\"6gycc7\", \"6gyf5r\", … ┆ [\"2012-04-07       ┆ 7          │\n",
       "│        ┆ \"…                           ┆ \"6ztxb8…               ┆ 17:45:04\", \"2012-… ┆            │\n",
       "│ 141099 ┆ [\"4c217a8034faef3b396d586d\", ┆ [\"6ztxb8\", \"6u35eg\", … ┆ [\"2012-08-10       ┆ 20         │\n",
       "│        ┆ \"…                           ┆ \"6gycd7…               ┆ 15:04:17\", \"2012-… ┆            │\n",
       "│ 113503 ┆ [\"4b0586c9f964a520a26e22e3\"] ┆ [\"dhvr44\"]             ┆ [\"2012-07-08       ┆ 1          │\n",
       "│        ┆                              ┆                        ┆ 12:03:22\"]         ┆            │\n",
       "└────────┴──────────────────────────────┴────────────────────────┴────────────────────┴────────────┘"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now need to obtain a dataframe containing: each POI, it's geohash, and a set of all the check-ins it appears in\n",
    "this is just one `polars` query away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_checkins = final_sorted.explode([\"pois\", \"geohashes\"]).drop(\"n_checkins\")\n",
    "\n",
    "pois_checkins = (\n",
    "    pois_checkins.with_columns(\n",
    "        [\n",
    "            rs.col(\"geohashes\").map_elements(lambda s: s[:4], rs.String).alias(\"g4\"),\n",
    "        ]\n",
    "    )\n",
    "    .drop(\"geohashes\")\n",
    "    .group_by([\"pois\", \"g4\"])\n",
    "    .agg([rs.col(\"times_sorted\").flatten().alias(\"checkin_times\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4d078e032f96f04dd1642d54&quot;</td><td>&quot;gcpv&quot;</td><td>[&quot;2012-05-08 18:59:49&quot;, &quot;2012-05-23 18:28:28&quot;, … &quot;2013-02-04 10:49:54&quot;]</td></tr><tr><td>&quot;4b482acef964a5205b4926e3&quot;</td><td>&quot;qw8n&quot;</td><td>[&quot;2012-05-27 16:15:21&quot;, &quot;2012-05-27 18:35:08&quot;, … &quot;2012-11-16 23:43:03&quot;]</td></tr><tr><td>&quot;42bf4180f964a520b4251fe3&quot;</td><td>&quot;dr4e&quot;</td><td>[&quot;2012-04-28 13:58:17&quot;, &quot;2012-11-06 07:05:05&quot;, … &quot;2013-09-06 14:14:57&quot;]</td></tr><tr><td>&quot;4c0e41a2c700c9b69d87a3dd&quot;</td><td>&quot;u0j2&quot;</td><td>[&quot;2012-05-28 17:15:54&quot;, &quot;2012-06-10 16:46:00&quot;, … &quot;2012-07-03 19:37:11&quot;]</td></tr><tr><td>&quot;4e490f101f6e29f10dc728f9&quot;</td><td>&quot;dp3w&quot;</td><td>[&quot;2012-06-20 23:04:42&quot;, &quot;2012-06-20 23:05:27&quot;, … &quot;2013-07-24 16:31:38&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4b8c641bf964a52069ce32e3&quot;</td><td>&quot;6gkz&quot;</td><td>[&quot;2012-04-27 07:28:22&quot;, &quot;2012-05-01 13:39:52&quot;, … &quot;2012-12-27 15:11:06&quot;]</td></tr><tr><td>&quot;4dfe04d91f6e05048d8b2d43&quot;</td><td>&quot;swvs&quot;</td><td>[&quot;2012-07-14 00:51:45&quot;, &quot;2012-07-14 03:02:44&quot;, … &quot;2013-05-18 23:52:16&quot;]</td></tr><tr><td>&quot;4e3502d57d8b0c62b2d054ba&quot;</td><td>&quot;sxk8&quot;</td><td>[&quot;2013-02-11 10:58:51&quot;, &quot;2013-02-12 16:56:11&quot;, … &quot;2013-09-01 22:42:38&quot;]</td></tr><tr><td>&quot;4c6adbac9669e21e06a6a951&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-04-19 09:40:09&quot;, &quot;2012-05-03 19:22:43&quot;, … &quot;2013-05-10 15:21:57&quot;]</td></tr><tr><td>&quot;4b632514f964a5202d662ae3&quot;</td><td>&quot;7pkd&quot;</td><td>[&quot;2013-04-30 14:35:19&quot;, &quot;2012-05-21 21:38:15&quot;, … &quot;2013-01-04 18:46:54&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 3)\n",
       "┌──────────────────────────┬──────┬─────────────────────────────────┐\n",
       "│ pois                     ┆ g4   ┆ checkin_times                   │\n",
       "│ ---                      ┆ ---  ┆ ---                             │\n",
       "│ str                      ┆ str  ┆ list[str]                       │\n",
       "╞══════════════════════════╪══════╪═════════════════════════════════╡\n",
       "│ 4d078e032f96f04dd1642d54 ┆ gcpv ┆ [\"2012-05-08 18:59:49\", \"2012-… │\n",
       "│ 4b482acef964a5205b4926e3 ┆ qw8n ┆ [\"2012-05-27 16:15:21\", \"2012-… │\n",
       "│ 42bf4180f964a520b4251fe3 ┆ dr4e ┆ [\"2012-04-28 13:58:17\", \"2012-… │\n",
       "│ 4c0e41a2c700c9b69d87a3dd ┆ u0j2 ┆ [\"2012-05-28 17:15:54\", \"2012-… │\n",
       "│ 4e490f101f6e29f10dc728f9 ┆ dp3w ┆ [\"2012-06-20 23:04:42\", \"2012-… │\n",
       "│ …                        ┆ …    ┆ …                               │\n",
       "│ 4b8c641bf964a52069ce32e3 ┆ 6gkz ┆ [\"2012-04-27 07:28:22\", \"2012-… │\n",
       "│ 4dfe04d91f6e05048d8b2d43 ┆ swvs ┆ [\"2012-07-14 00:51:45\", \"2012-… │\n",
       "│ 4e3502d57d8b0c62b2d054ba ┆ sxk8 ┆ [\"2013-02-11 10:58:51\", \"2013-… │\n",
       "│ 4c6adbac9669e21e06a6a951 ┆ sxk9 ┆ [\"2012-04-19 09:40:09\", \"2012-… │\n",
       "│ 4b632514f964a5202d662ae3 ┆ 7pkd ┆ [\"2013-04-30 14:35:19\", \"2012-… │\n",
       "└──────────────────────────┴──────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_checkins  # with this we can *efficiently* build our POI-POI spatial-temporal graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UTC_to_weekslot(utc: str) -> int:\n",
    "    \"\"\"UTC_to_weekslot converts a UTC timestamp to a weekslot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    utc : str\n",
    "        A string representing a UTC timestamp.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        A weekslot in the range [0, 56).\n",
    "    \"\"\"\n",
    "\n",
    "    date = datetime.datetime.strptime(utc, \"%Y-%m-%d %H:%M:%S\")\n",
    "    week = date.weekday()\n",
    "    hour = date.hour\n",
    "\n",
    "    return week * 8 + hour // 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to encode all of our inputs for our neural networks, this could *probably* be done \n",
    "with polars magic, but it's too delicate and we prefer classic for-looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dict = {\n",
    "    \"users\": LabelEncoder(),\n",
    "    \"pois\": LabelEncoder(),\n",
    "    \"g2\": LabelEncoder(),\n",
    "    \"g3\": LabelEncoder(),\n",
    "    \"g4\": LabelEncoder(),\n",
    "    \"g5\": LabelEncoder(),\n",
    "    \"g6\": LabelEncoder(),\n",
    "}\n",
    "\n",
    "encoded_data = {\n",
    "    \"users\": [],\n",
    "    \"pois\": [],\n",
    "    \"g2\": [],\n",
    "    \"g3\": [],\n",
    "    \"g4\": [],\n",
    "    \"g5\": [],\n",
    "    \"g6\": [],\n",
    "}\n",
    "\n",
    "unique_data = {\n",
    "    \"users\": set(),\n",
    "    \"pois\": set(),\n",
    "    \"g2\": set(),\n",
    "    \"g3\": set(),\n",
    "    \"g4\": set(),\n",
    "    \"g5\": set(),\n",
    "    \"g6\": set(),\n",
    "}\n",
    "\n",
    "# quick and dirty encoding:\n",
    "# 1. put every unique symbol in a list\n",
    "# 2. fit the respective encoder\n",
    "# 3. transform the lists\n",
    "\n",
    "for i, row in enumerate(final_sorted.iter_rows()):\n",
    "\n",
    "    user, pois, geohashes, times_sorted, n_checkins = row\n",
    "\n",
    "    g2 = [geo[:2] for geo in geohashes]\n",
    "    g3 = [geo[:3] for geo in geohashes]\n",
    "    g4 = [geo[:4] for geo in geohashes]\n",
    "    g5 = [geo[:5] for geo in geohashes]\n",
    "    g6 = [geo[:6] for geo in geohashes]  # redundant, but I like symmetry\n",
    "\n",
    "    unique_data[\"users\"].add(user)\n",
    "    unique_data[\"pois\"].update(pois)\n",
    "    unique_data[\"g2\"].update(g2)\n",
    "    unique_data[\"g3\"].update(g3)\n",
    "    unique_data[\"g4\"].update(g4)\n",
    "    unique_data[\"g5\"].update(g5)\n",
    "    unique_data[\"g6\"].update(g6)\n",
    "\n",
    "for property, enc, data in zip(\n",
    "    encoder_dict.keys(), encoder_dict.values(), unique_data.values()\n",
    "):\n",
    "    enc.fit(list(data))\n",
    "    encoder_dict[property] = enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19862/19862 [03:05<00:00, 107.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# this could be optimized, right now it takes a while, at least we have a nice progress bar to look at\n",
    "\n",
    "ds_size = len(final_sorted)\n",
    "\n",
    "for i, row in tqdm(enumerate(final_sorted.iter_rows()), total=ds_size):\n",
    "\n",
    "    user, pois, geohashes, times_sorted, n_checkins = row\n",
    "\n",
    "    g2 = [geo[:2] for geo in geohashes]\n",
    "    g3 = [geo[:3] for geo in geohashes]\n",
    "    g4 = [geo[:4] for geo in geohashes]\n",
    "    g5 = [geo[:5] for geo in geohashes]\n",
    "    g6 = [geo[:6] for geo in geohashes]\n",
    "\n",
    "    encoded_data[\"users\"].append(encoder_dict[\"users\"].transform([user])[0])\n",
    "    encoded_data[\"pois\"].append(encoder_dict[\"pois\"].transform(pois))\n",
    "    encoded_data[\"g2\"].append(encoder_dict[\"g2\"].transform(g2))\n",
    "    encoded_data[\"g3\"].append(encoder_dict[\"g3\"].transform(g3))\n",
    "    encoded_data[\"g4\"].append(encoder_dict[\"g4\"].transform(g4))\n",
    "    encoded_data[\"g5\"].append(encoder_dict[\"g5\"].transform(g5))\n",
    "    encoded_data[\"g6\"].append(encoder_dict[\"g6\"].transform(g6))\n",
    "\n",
    "    # sum 1 to all values to avoid 0s\n",
    "    encoded_data[\"users\"][-1] += 1\n",
    "    encoded_data[\"pois\"][-1] += 1\n",
    "    encoded_data[\"g2\"][-1] += 1\n",
    "    encoded_data[\"g3\"][-1] += 1\n",
    "    encoded_data[\"g4\"][-1] += 1\n",
    "    encoded_data[\"g5\"][-1] += 1\n",
    "    encoded_data[\"g6\"][-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we left space for the padding token\n",
    "min((arr.min() for arr in encoded_data[\"pois\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4d078e032f96f04dd1642d54&quot;</td><td>&quot;gcpv&quot;</td><td>[&quot;2012-05-08 18:59:49&quot;, &quot;2012-05-23 18:28:28&quot;, … &quot;2013-02-04 10:49:54&quot;]</td></tr><tr><td>&quot;4b482acef964a5205b4926e3&quot;</td><td>&quot;qw8n&quot;</td><td>[&quot;2012-05-27 16:15:21&quot;, &quot;2012-05-27 18:35:08&quot;, … &quot;2012-11-16 23:43:03&quot;]</td></tr><tr><td>&quot;42bf4180f964a520b4251fe3&quot;</td><td>&quot;dr4e&quot;</td><td>[&quot;2012-04-28 13:58:17&quot;, &quot;2012-11-06 07:05:05&quot;, … &quot;2013-09-06 14:14:57&quot;]</td></tr><tr><td>&quot;4c0e41a2c700c9b69d87a3dd&quot;</td><td>&quot;u0j2&quot;</td><td>[&quot;2012-05-28 17:15:54&quot;, &quot;2012-06-10 16:46:00&quot;, … &quot;2012-07-03 19:37:11&quot;]</td></tr><tr><td>&quot;4e490f101f6e29f10dc728f9&quot;</td><td>&quot;dp3w&quot;</td><td>[&quot;2012-06-20 23:04:42&quot;, &quot;2012-06-20 23:05:27&quot;, … &quot;2013-07-24 16:31:38&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4b8c641bf964a52069ce32e3&quot;</td><td>&quot;6gkz&quot;</td><td>[&quot;2012-04-27 07:28:22&quot;, &quot;2012-05-01 13:39:52&quot;, … &quot;2012-12-27 15:11:06&quot;]</td></tr><tr><td>&quot;4dfe04d91f6e05048d8b2d43&quot;</td><td>&quot;swvs&quot;</td><td>[&quot;2012-07-14 00:51:45&quot;, &quot;2012-07-14 03:02:44&quot;, … &quot;2013-05-18 23:52:16&quot;]</td></tr><tr><td>&quot;4e3502d57d8b0c62b2d054ba&quot;</td><td>&quot;sxk8&quot;</td><td>[&quot;2013-02-11 10:58:51&quot;, &quot;2013-02-12 16:56:11&quot;, … &quot;2013-09-01 22:42:38&quot;]</td></tr><tr><td>&quot;4c6adbac9669e21e06a6a951&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-04-19 09:40:09&quot;, &quot;2012-05-03 19:22:43&quot;, … &quot;2013-05-10 15:21:57&quot;]</td></tr><tr><td>&quot;4b632514f964a5202d662ae3&quot;</td><td>&quot;7pkd&quot;</td><td>[&quot;2013-04-30 14:35:19&quot;, &quot;2012-05-21 21:38:15&quot;, … &quot;2013-01-04 18:46:54&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 3)\n",
       "┌──────────────────────────┬──────┬─────────────────────────────────┐\n",
       "│ pois                     ┆ g4   ┆ checkin_times                   │\n",
       "│ ---                      ┆ ---  ┆ ---                             │\n",
       "│ str                      ┆ str  ┆ list[str]                       │\n",
       "╞══════════════════════════╪══════╪═════════════════════════════════╡\n",
       "│ 4d078e032f96f04dd1642d54 ┆ gcpv ┆ [\"2012-05-08 18:59:49\", \"2012-… │\n",
       "│ 4b482acef964a5205b4926e3 ┆ qw8n ┆ [\"2012-05-27 16:15:21\", \"2012-… │\n",
       "│ 42bf4180f964a520b4251fe3 ┆ dr4e ┆ [\"2012-04-28 13:58:17\", \"2012-… │\n",
       "│ 4c0e41a2c700c9b69d87a3dd ┆ u0j2 ┆ [\"2012-05-28 17:15:54\", \"2012-… │\n",
       "│ 4e490f101f6e29f10dc728f9 ┆ dp3w ┆ [\"2012-06-20 23:04:42\", \"2012-… │\n",
       "│ …                        ┆ …    ┆ …                               │\n",
       "│ 4b8c641bf964a52069ce32e3 ┆ 6gkz ┆ [\"2012-04-27 07:28:22\", \"2012-… │\n",
       "│ 4dfe04d91f6e05048d8b2d43 ┆ swvs ┆ [\"2012-07-14 00:51:45\", \"2012-… │\n",
       "│ 4e3502d57d8b0c62b2d054ba ┆ sxk8 ┆ [\"2013-02-11 10:58:51\", \"2013-… │\n",
       "│ 4c6adbac9669e21e06a6a951 ┆ sxk9 ┆ [\"2012-04-19 09:40:09\", \"2012-… │\n",
       "│ 4b632514f964a5202d662ae3 ┆ 7pkd ┆ [\"2013-04-30 14:35:19\", \"2012-… │\n",
       "└──────────────────────────┴──────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also encode the graph dataframe so we can build the graphs\n",
    "\n",
    "pois_checkins = (\n",
    "    pois_checkins.lazy()\n",
    "    .with_columns(\n",
    "        [\n",
    "            rs.col(\"pois\").map_elements(\n",
    "                lambda s: encoder_dict[\"pois\"].transform([s])[0] + 1, rs.Int64\n",
    "            ),\n",
    "            rs.col(\"g4\").map_elements(\n",
    "                lambda s: encoder_dict[\"g4\"].transform([s])[0] + 1, rs.Int64\n",
    "            ),  # apply utc_to_weekslot to each timestamp in the list\n",
    "            rs.col(\"checkin_times\").map_elements(\n",
    "                lambda s: [UTC_to_weekslot(date) for date in s], rs.List(rs.Int64)\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    .sort(\"pois\")\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fictitious POI 0 to the graph, with nonexistent geohash and no timeslot, so we get a 0 row and column for the padding token\n",
    "fake_datapoint = rs.DataFrame(\n",
    "    {\n",
    "        \"pois\": [0],\n",
    "        \"g4\": [pois_checkins[\"g4\"].max() + 42],\n",
    "        \"checkin_times\": [[43]],\n",
    "    }\n",
    ")\n",
    "# this is a lot of work since polars dataframes are immutable by default, we have to run a query to change the 43 into an empty list\n",
    "# we NEED the 43 otherwise polars won't infer the datatype of the list\n",
    "\n",
    "fake_datapoint = fake_datapoint.with_columns(\n",
    "    [rs.col(\"checkin_times\").map_elements(lambda s: [], rs.List(rs.Int64))]\n",
    ")\n",
    "\n",
    "pois_checkins = fake_datapoint.vstack(pois_checkins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_row = np.array(pois_checkins[\"g4\"].to_list()).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer product using equality\n",
    "spatial_graph = (spatial_row == spatial_row.T).astype(np.int32)\n",
    "spatial_graph[0, 0] = (\n",
    "    0  # the fake g4 is still equal to itself, we suppress this equality\n",
    ")\n",
    "spatial_graph = torch.tensor(spatial_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_row = pois_checkins[\"checkin_times\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_graph = np.zeros((spatial_row.shape[0], spatial_row.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_sets = [np.array(list(set(row))) for row in temporal_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sets = torch.zeros((len(temporal_sets), 56), dtype=torch.int8)\n",
    "\n",
    "for i, r in enumerate(temporal_row):\n",
    "    indices = torch.tensor(r, dtype=torch.long)\n",
    "    time_sets[i, indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4456, 56])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND outer product\n",
    "\n",
    "intersection = time_sets @ time_sets.T\n",
    "union = time_sets.unsqueeze(1) | time_sets.unsqueeze(0)\n",
    "union = union.sum(dim=2)\n",
    "iou = intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_graph = iou >= 0.9\n",
    "# cast to int\n",
    "temporal_graph = temporal_graph.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_graph[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print information about the sparsity of the graphs, we note that \n",
    "the sparsity of the graphs is similar to that of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal sparsity: 97.05%\n",
      "Spatial sparsity: 96.99%\n"
     ]
    }
   ],
   "source": [
    "temporal_density = (\n",
    "    temporal_graph.sum() / (temporal_graph.shape[0] * temporal_graph.shape[1])\n",
    ").item()\n",
    "spatial_density = (\n",
    "    spatial_graph.sum() / (spatial_graph.shape[0] * spatial_graph.shape[1])\n",
    ").item()\n",
    "\n",
    "print(f\"Temporal sparsity: {(1 - temporal_density) * 100:.2f}%\")\n",
    "\n",
    "print(f\"Spatial sparsity: {(1 - spatial_density) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Datamodule\n",
    "\n",
    "We then define a pytorch dataset and a custom collation function that allows us to dynamically\n",
    "pad sequences to the longest one in the batch (as opposed to the longest one in the dataset)\n",
    "as they are loaded during training, this gives us an edge in performance by dramatically reducing the \n",
    "sparsity of our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def rnn_collation_fn(batch):\n",
    "\n",
    "    users = []\n",
    "    pois = []\n",
    "    g2 = []\n",
    "    g3 = []\n",
    "    g4 = []\n",
    "    g5 = []\n",
    "    g6 = []\n",
    "\n",
    "    for user, poi, geo2, geo3, geo4, geo5, geo6 in batch:\n",
    "        users.append(user)\n",
    "        pois.append(poi)\n",
    "        g2.append(geo2)\n",
    "        g3.append(geo3)\n",
    "        g4.append(geo4)\n",
    "        g5.append(geo5)\n",
    "        g6.append(geo6)\n",
    "    seq = (\n",
    "        torch.tensor(users, dtype=torch.long),\n",
    "        pad_sequence(pois, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g2, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g3, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g4, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g5, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g6, batch_first=True, padding_value=0),\n",
    "    )  # build a sequence\n",
    "\n",
    "    x = (\n",
    "        seq[0],\n",
    "        seq[1][:, :-1],\n",
    "        seq[2][:, :-1],\n",
    "        seq[3][:, :-1],\n",
    "        seq[4][:, :-1],\n",
    "        seq[5][:, :-1],\n",
    "        seq[6][:, :-1],\n",
    "    )  # omit the last one for sample\n",
    "\n",
    "    y = (\n",
    "        seq[0],\n",
    "        seq[1][:, 1:],\n",
    "        seq[2][:, 1:],\n",
    "        seq[3][:, 1:],\n",
    "        seq[4][:, 1:],\n",
    "        seq[5][:, 1:],\n",
    "        seq[6][:, 1:],\n",
    "    )  # omit the first one for ground truth\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class CheckinDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"users\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = (\n",
    "            torch.tensor(encoded_data[\"users\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"pois\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g2\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g3\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g4\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g5\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g6\"][idx], dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckinModule(pl.LightningDataModule):\n",
    "    def __init__(self, encoded_data, batch_size=32, workers=4):\n",
    "        super().__init__()\n",
    "        self.encoded_data = encoded_data\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.whole_dataset = CheckinDataset(self.encoded_data)\n",
    "\n",
    "        l = len(self.whole_dataset)\n",
    "\n",
    "        train_size = int(0.8 * l)\n",
    "        val_size = int(0.1 * l)\n",
    "        test_size = l - train_size - val_size\n",
    "\n",
    "        # generate train, val, test datasets by random split\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = (\n",
    "            torch.utils.data.random_split(\n",
    "                self.whole_dataset, [train_size, val_size, test_size]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def save(self, whole_path, train_path, val_path, test_path):\n",
    "        torch.save(self.whole_dataset, whole_path)\n",
    "        torch.save(self.train_dataset, train_path)\n",
    "        torch.save(self.val_dataset, val_path)\n",
    "        torch.save(self.test_dataset, test_path)\n",
    "\n",
    "    @staticmethod  # load without instantiating\n",
    "    def load(whole_path, train_path, val_path, test_path):\n",
    "        whole_dataset = torch.load(whole_path)\n",
    "        train_dataset = torch.load(train_path)\n",
    "        val_dataset = torch.load(val_path)\n",
    "        test_dataset = torch.load(test_path)\n",
    "        return whole_dataset, train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaselineDimensions:\n",
    "    nuser: int\n",
    "    npoi: int\n",
    "    g2len: int\n",
    "    g3len: int\n",
    "    g4len: int\n",
    "    g5len: int\n",
    "    g6len: int\n",
    "\n",
    "\n",
    "# HMT_RN (Hierarchical Multi-Task Recurrent Network)\n",
    "class HMT_RN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimensions: BaselineDimensions,\n",
    "        embedding_dim,\n",
    "        lstm_hidden_dim,\n",
    "        dropout_rate=0.9,  # 0.9 is a lot, but the paper says so.\n",
    "    ):\n",
    "        super(HMT_RN, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = lstm_hidden_dim\n",
    "        self.dims = dimensions\n",
    "\n",
    "        # Embedding layers one for user, one for poi and one for each G@P\n",
    "        self.user_embedding = nn.Embedding(\n",
    "            dimensions.nuser, embedding_dim, padding_idx=0\n",
    "        )\n",
    "        self.poi_embedding = nn.Embedding(dimensions.npoi, embedding_dim, padding_idx=0)\n",
    "        self.g2_embed = nn.Embedding(dimensions.g2len, embedding_dim, padding_idx=0)\n",
    "        self.g3_embed = nn.Embedding(dimensions.g3len, embedding_dim, padding_idx=0)\n",
    "        self.g4_embed = nn.Embedding(dimensions.g4len, embedding_dim, padding_idx=0)\n",
    "        self.g5_embed = nn.Embedding(dimensions.g5len, embedding_dim, padding_idx=0)\n",
    "        self.g6_embed = nn.Embedding(dimensions.g6len, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Dropout layer for embeddings\n",
    "        self.e_drop = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.user_poi_proj = nn.Linear(2 * embedding_dim, embedding_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=lstm_hidden_dim, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Linear layers for prediction tasks\n",
    "        self.linear_poi = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.npoi)\n",
    "        self.linear_g2 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g2len)\n",
    "        self.linear_g3 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g3len)\n",
    "        self.linear_g4 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g4len)\n",
    "        self.linear_g5 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g5len)\n",
    "        self.linear_g6 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g6len)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, w):\n",
    "\n",
    "        if type(w) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "        elif type(w) == nn.LSTM:\n",
    "            for name, param in w.named_parameters():\n",
    "                if \"bias\" in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "                elif \"weight\" in name:\n",
    "                    nn.init.kaiming_normal_(param)\n",
    "        elif type(w) == nn.Embedding:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.weight[0], 0)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"forward passes the batch through the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : `tuple[torch.Tensor]`\n",
    "            A tuple of tensors ordered as follows:\n",
    "            (users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6)\n",
    "        \"\"\"\n",
    "\n",
    "        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = batch\n",
    "\n",
    "        B, T = poi.shape\n",
    "\n",
    "        # make it so  that users are tiled T times\n",
    "        users = users.repeat(T, 1).T\n",
    "\n",
    "        e_user = self.e_drop(self.user_embedding(users))\n",
    "        e_poi = self.e_drop(self.poi_embedding(poi))\n",
    "        e_gap2 = self.e_drop(self.g2_embed(x_geoHash2))\n",
    "        e_gap3 = self.e_drop(self.g3_embed(x_geoHash3))\n",
    "        e_gap4 = self.e_drop(self.g4_embed(x_geoHash4))\n",
    "        e_gap5 = self.e_drop(self.g5_embed(x_geoHash5))\n",
    "        e_gap6 = self.e_drop(self.g6_embed(x_geoHash6))\n",
    "\n",
    "        visit = self.e_drop(self.user_poi_proj(torch.cat((e_user, e_poi), dim=2)))\n",
    "\n",
    "        h_t, c_t = self.lstm(visit)\n",
    "\n",
    "        # dense layers\n",
    "        next_poi = self.linear_poi(torch.cat((h_t, e_poi), dim=2))\n",
    "        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n",
    "        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n",
    "        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n",
    "        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n",
    "        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n",
    "\n",
    "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/loss_gap2\", loss_gap2)\n",
    "        self.log(\"train/loss_gap3\", loss_gap3)\n",
    "        self.log(\"train/loss_gap4\", loss_gap4)\n",
    "        self.log(\"train/loss_gap5\", loss_gap5)\n",
    "        self.log(\"train/loss_gap6\", loss_gap6)\n",
    "        self.log(\"train/loss_poi\", loss_poi)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "        self.log(\"val/loss_gap2\", loss_gap2)\n",
    "        self.log(\"val/loss_gap3\", loss_gap3)\n",
    "        self.log(\"val/loss_gap4\", loss_gap4)\n",
    "        self.log(\"val/loss_gap5\", loss_gap5)\n",
    "        self.log(\"val/loss_gap6\", loss_gap6)\n",
    "        self.log(\"val/loss_poi\", loss_poi)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer and scheduler\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Components\n",
    "\n",
    "\n",
    "class attn_LSTM(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super(attn_LSTM, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.U = nn.Linear(hidden_dim, 4 * hidden_dim)\n",
    "\n",
    "        self.s_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.t_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "\n",
    "    def forward(self, x, hidden, spatial, temporal, numTimeSteps):\n",
    "        h_t, c_t = hidden\n",
    "\n",
    "        previous_h_t = h_t\n",
    "        previous_c_t = c_t\n",
    "\n",
    "        allGates_preact = (\n",
    "            self.W(x) + self.U(previous_h_t) + self.s_W(spatial) + self.t_W(temporal)\n",
    "        )\n",
    "\n",
    "        input_g = allGates_preact[:, :, : self.hidden_dim].sigmoid()\n",
    "        forget_g = allGates_preact[\n",
    "            :, :, self.hidden_dim : 2 * self.hidden_dim\n",
    "        ].sigmoid()\n",
    "        output_g = allGates_preact[\n",
    "            :, :, 2 * self.hidden_dim : 3 * self.hidden_dim\n",
    "        ].sigmoid()\n",
    "        c_t_g = allGates_preact[:, :, 3 * self.hidden_dim :].tanh()\n",
    "\n",
    "        c_t = forget_g * previous_c_t + input_g * c_t_g\n",
    "        h_t = output_g * c_t.tanh()\n",
    "\n",
    "        batchSize = x.shape[0]\n",
    "        h_t = h_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
    "        c_t = c_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
    "\n",
    "        return h_t, c_t\n",
    "\n",
    "\n",
    "def get_neighbours(adj_matrix, poi):\n",
    "    neigh_indices_list = []\n",
    "    max_length = 0\n",
    "\n",
    "    for batch_poi in poi:\n",
    "        batch_indices = []\n",
    "        for single_poi in batch_poi:\n",
    "            poi_row = adj_matrix[single_poi]\n",
    "            neigh_indices = torch.where(poi_row == 1)[0]\n",
    "            batch_indices.append(neigh_indices)\n",
    "            max_length = max(max_length, len(neigh_indices))\n",
    "\n",
    "        neigh_indices_list.append(batch_indices)\n",
    "\n",
    "    padded_neigh_indices_list = []\n",
    "    for batch_indices in neigh_indices_list:\n",
    "        padded_batch_indices = pad_sequence(\n",
    "            batch_indices, batch_first=True, padding_value=0\n",
    "        )\n",
    "        padded_neigh_indices_list.append(padded_batch_indices)\n",
    "\n",
    "    padded_tensor = torch.stack(padded_neigh_indices_list)\n",
    "\n",
    "    return padded_tensor\n",
    "\n",
    "\n",
    "class GRNSelfAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, n_heads):\n",
    "\n",
    "        super(GRNSelfAttention, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.Wp = nn.Linear(hidden_dim, hidden_dim)  # embeddings to pre-concat\n",
    "        self.Wa = nn.Linear(2 * hidden_dim, hidden_dim)  # concatenation to pre-softmax\n",
    "\n",
    "        # total size = 3 * (hidden_dim) ** 2, quadratic in embedding size\n",
    "\n",
    "    def forward(self, poi, neighbors):\n",
    "        \"\"\"forward\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        poi: torch.Tensor\n",
    "            A batched tensor of embedded POI vectors, (B x H) where H is the\n",
    "            embedding dimension\n",
    "        neighbors: torch.Tensor\n",
    "            A batched tensor of sequences of embedded POI vectors that are extracted\n",
    "            from an adjacency matrix (temporal or spatial neighbors of POI),\n",
    "            (N x B x H), where N is the number of neighbours of POI, B is the\n",
    "            batch size, H is the embedding dimension, and must be the same as POI\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[torch.Tensor, torch.Tensor]\n",
    "          A tuple containing the self-attention weighted hadamard product of neighbour activations\n",
    "          in the first index, the attention weights in the second index.\n",
    "        \"\"\"\n",
    "        # assert len(poi.shape) == 2, f\"POI tensor must be 2D, got {poi.shape} instead\"\n",
    "        assert (\n",
    "            len(neighbors.shape) == 3\n",
    "        ), f\"Neighbour tensor must be 3D, got {neighbors.shape} instead\"\n",
    "\n",
    "        neighbors = neighbors.half()\n",
    "        poi = poi.half()\n",
    "        T, B, H = neighbors.shape\n",
    "\n",
    "        h_poi = self.Wp(poi)\n",
    "        h_n = self.Wp(neighbors)\n",
    "        h_cat = torch.cat([h_poi.expand(T, -1, -1), h_n], dim=2)\n",
    "        h_att = F.leaky_relu(self.Wa(h_cat))\n",
    "\n",
    "        alpha = torch.nn.functional.softmax(h_att, dim=1)\n",
    "\n",
    "        p = torch.sum(alpha * h_n, dim=0)\n",
    "        return p, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRN (Graph Recurrent Network)\n",
    "class GRN(pl.LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dims: BaselineDimensions,\n",
    "        spatial_graph,\n",
    "        temporal_graph,\n",
    "        hidden_dim,\n",
    "        n_heads,\n",
    "        dropout_rate=0.9,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super(GRN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dims = dims\n",
    "\n",
    "        self.spatial_graph = spatial_graph.to(device)\n",
    "        self.temporal_graph = temporal_graph.to(device)\n",
    "\n",
    "        self.spatial_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
    "        self.temporal_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
    "\n",
    "        self.lstm = attn_LSTM(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.user_embedding = nn.Embedding(dims.nuser, hidden_dim, padding_idx=0)\n",
    "        self.poi_embedding = nn.Embedding(dims.npoi, hidden_dim, padding_idx=0)\n",
    "        self.g2_embed = nn.Embedding(dims.g2len, hidden_dim, padding_idx=0)\n",
    "        self.g3_embed = nn.Embedding(dims.g3len, hidden_dim, padding_idx=0)\n",
    "        self.g4_embed = nn.Embedding(dims.g4len, hidden_dim, padding_idx=0)\n",
    "        self.g5_embed = nn.Embedding(dims.g5len, hidden_dim, padding_idx=0)\n",
    "        self.g6_embed = nn.Embedding(dims.g6len, hidden_dim, padding_idx=0)\n",
    "\n",
    "        self.linear_poi = nn.Linear(hidden_dim, dims.npoi)\n",
    "        self.linear_g2 = nn.Linear(hidden_dim, dims.g2len)\n",
    "        self.linear_g3 = nn.Linear(hidden_dim, dims.g3len)\n",
    "        self.linear_g4 = nn.Linear(hidden_dim, dims.g4len)\n",
    "        self.linear_g5 = nn.Linear(hidden_dim, dims.g5len)\n",
    "        self.linear_g6 = nn.Linear(hidden_dim, dims.g6len)\n",
    "\n",
    "        # extract indices from one-hot neighbor list\n",
    "        self.iota = torch.arange(self.dims.npoi, requires_grad=False, device=device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, w):\n",
    "        if type(w) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "        elif type(w) == nn.LSTM:\n",
    "            for name, param in w.named_parameters():\n",
    "                if \"bias\" in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "                elif \"weight\" in name:\n",
    "                    nn.init.kaiming_normal_(param)\n",
    "        elif type(w) == nn.Embedding:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.weight[0], 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = x\n",
    "\n",
    "        B, T = poi.shape\n",
    "\n",
    "        users = users.repeat(T, 1).T\n",
    "\n",
    "        neighbors_spatial = self.spatial_graph[poi]\n",
    "        neighbors_temporal = self.temporal_graph[poi]\n",
    "\n",
    "        e_user = self.dropout(self.user_embedding(users))\n",
    "        e_poi = self.dropout(self.poi_embedding(poi))\n",
    "        e_gap2 = self.dropout(self.g2_embed(x_geoHash2))\n",
    "        e_gap3 = self.dropout(self.g3_embed(x_geoHash3))\n",
    "        e_gap4 = self.dropout(self.g4_embed(x_geoHash4))\n",
    "        e_gap5 = self.dropout(self.g5_embed(x_geoHash5))\n",
    "        e_gap6 = self.dropout(self.g6_embed(x_geoHash6))\n",
    "\n",
    "        spatial_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
    "        temporal_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
    "\n",
    "        for b in range(B):\n",
    "            for t in range(T):\n",
    "\n",
    "                spatial_neigh = neighbors_spatial[t, b] * self.iota\n",
    "                temporal_neigh = neighbors_temporal[t, b] * self.iota\n",
    "\n",
    "                spatial_neigh = spatial_neigh[spatial_neigh != 0]\n",
    "                temporal_neigh = temporal_neigh[temporal_neigh != 0]\n",
    "\n",
    "                spatial_neigh = spatial_neigh.unsqueeze(0)\n",
    "                temporal_neigh = temporal_neigh.unsqueeze(0)\n",
    "\n",
    "                curr_poi = e_poi[b, t].unsqueeze(0)\n",
    "\n",
    "                spatial_p, _ = self.spatial_attn(curr_poi, e_poi[spatial_neigh])\n",
    "                temporal_p, _ = self.temporal_attn(curr_poi, e_poi[temporal_neigh])\n",
    "\n",
    "                spatial_atts[b, t] = spatial_p\n",
    "                temporal_atts[b, t] = temporal_p\n",
    "\n",
    "        # zero-init LSTM states\n",
    "        h_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
    "        c_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
    "\n",
    "        h_t, c_t = self.lstm(e_poi, (h_t, c_t), spatial_atts, temporal_atts, T)\n",
    "\n",
    "        next_poi = self.linear_poi(torch.cat((h_t, e_poi), dim=2))\n",
    "        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n",
    "        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n",
    "        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n",
    "        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n",
    "        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n",
    "\n",
    "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/loss_gap2\", loss_gap2)\n",
    "        self.log(\"train/loss_gap3\", loss_gap3)\n",
    "        self.log(\"train/loss_gap4\", loss_gap4)\n",
    "        self.log(\"train/loss_gap5\", loss_gap5)\n",
    "        self.log(\"train/loss_gap6\", loss_gap6)\n",
    "        self.log(\"train/loss_poi\", loss_poi)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "        self.log(\"val/loss_gap2\", loss_gap2)\n",
    "        self.log(\"val/loss_gap3\", loss_gap3)\n",
    "        self.log(\"val/loss_gap4\", loss_gap4)\n",
    "        self.log(\"val/loss_gap5\", loss_gap5)\n",
    "        self.log(\"val/loss_gap6\", loss_gap6)\n",
    "        self.log(\"val/loss_poi\", loss_poi)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer and scheduler\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = encoder_dict[\"users\"].classes_.shape[0]\n",
    "n_pois = encoder_dict[\"pois\"].classes_.shape[0]\n",
    "n_g2 = encoder_dict[\"g2\"].classes_.shape[0]\n",
    "n_g3 = encoder_dict[\"g3\"].classes_.shape[0]\n",
    "n_g4 = encoder_dict[\"g4\"].classes_.shape[0]\n",
    "n_g5 = encoder_dict[\"g5\"].classes_.shape[0]\n",
    "n_g6 = encoder_dict[\"g6\"].classes_.shape[0]\n",
    "\n",
    "\n",
    "# account for the padding token\n",
    "dims = BaselineDimensions(\n",
    "    n_users + 1, n_pois + 1, n_g2 + 1, n_g3 + 1, n_g4 + 1, n_g5 + 1, n_g6 + 1\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find dario_nb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mloi-1940849\u001b[0m (\u001b[33mpoi-dl-airo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dario/foursquare/wandb/run-20240509_235040-r4ibnph5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/r4ibnph5' target=\"_blank\">wobbly-shadow-163</a></strong> to <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/r4ibnph5' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/r4ibnph5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86246e1b4bcf4960ab0a609cee915a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.005 MB uploaded\\r'), FloatProgress(value=0.3233379364766226, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-shadow-163</strong> at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/r4ibnph5' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/r4ibnph5</a><br/> View project at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240509_235040-r4ibnph5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "TRAIN_BASELINE = False\n",
    "\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()\n",
    "# cargo-cult like stuff that is supposed to make you faster\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "ds = CheckinModule(encoded_data, batch_size=32, workers=4)\n",
    "\n",
    "wandb.init(project=\"trovailpoi\")\n",
    "\n",
    "classifier_baseline = HMT_RN(dims, embedding_dim=1024, lstm_hidden_dim=1024)\n",
    "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=40,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    log_every_n_steps=10,\n",
    "    logger=wandb_logger,\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        torchpl.callbacks.ModelCheckpoint(\n",
    "            monitor=\"val/loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            save_last=True,\n",
    "            filename=\"best_model\",\n",
    "        ),\n",
    "        torchpl.callbacks.EarlyStopping(\n",
    "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if TRAIN_BASELINE:\n",
    "    trainer.fit(model=classifier_baseline, datamodule=ds)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a01ce8f785a4d189083541c32f6e2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112100366638818, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dario/foursquare/wandb/run-20240509_175000-07zm5at8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/07zm5at8' target=\"_blank\">valiant-cherry-161</a></strong> to <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/07zm5at8' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/07zm5at8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dario/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name           | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0  | spatial_attn   | GRNSelfAttention | 3.1 M \n",
      "1  | temporal_attn  | GRNSelfAttention | 3.1 M \n",
      "2  | lstm           | attn_LSTM        | 16.8 M\n",
      "3  | dropout        | Dropout          | 0     \n",
      "4  | user_embedding | Embedding        | 20.3 M\n",
      "5  | poi_embedding  | Embedding        | 4.6 M \n",
      "6  | g2_embed       | Embedding        | 114 K \n",
      "7  | g3_embed       | Embedding        | 287 K \n",
      "8  | g4_embed       | Embedding        | 561 K \n",
      "9  | g5_embed       | Embedding        | 1.4 M \n",
      "10 | g6_embed       | Embedding        | 2.8 M \n",
      "11 | linear_poi     | Linear           | 4.6 M \n",
      "12 | linear_g2      | Linear           | 114 K \n",
      "13 | linear_g3      | Linear           | 288 K \n",
      "14 | linear_g4      | Linear           | 561 K \n",
      "15 | linear_g5      | Linear           | 1.4 M \n",
      "16 | linear_g6      | Linear           | 2.8 M \n",
      "17 | criterion      | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------------\n",
      "62.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "62.9 M    Total params\n",
      "251.676   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f443bc531d3b466fbb0de03a865928df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [0,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [1,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [2,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [3,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [4,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [5,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [6,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [7,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [8,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [9,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [10,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [11,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [12,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [13,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [14,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [15,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [16,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [17,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [18,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [19,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [20,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [21,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [22,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [23,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [24,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [25,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [26,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [27,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [28,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [29,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [30,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "../aten/src/ATen/native/cuda/IndexKernel.cu:92: operator(): block: [28,0,0], thread: [31,0,0] Assertion `-sizes[i] <= index && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[56], line 174\u001b[0m, in \u001b[0;36mGRN.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    166\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    167\u001b[0m (\n\u001b[1;32m    168\u001b[0m     poi_pred,\n\u001b[1;32m    169\u001b[0m     gap2_pred,\n\u001b[1;32m    170\u001b[0m     gap3_pred,\n\u001b[1;32m    171\u001b[0m     gap4_pred,\n\u001b[1;32m    172\u001b[0m     gap5_pred,\n\u001b[1;32m    173\u001b[0m     gap6_pred,\n\u001b[0;32m--> 174\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m loss_poi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(\n\u001b[1;32m    177\u001b[0m     poi_pred\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;241m.\u001b[39mnpoi), y[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    178\u001b[0m )\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[56], line 101\u001b[0m, in \u001b[0;36mGRN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m curr_poi \u001b[38;5;241m=\u001b[39m e_poi[b, t]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m spatial_p, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_poi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_poi\u001b[49m\u001b[43m[\u001b[49m\u001b[43mspatial_neigh\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m temporal_p, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_attn(curr_poi, e_poi[temporal_neigh])\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[55], line 107\u001b[0m, in \u001b[0;36mGRNSelfAttention.forward\u001b[0;34m(self, poi, neighbors)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# assert len(poi.shape) == 2, f\"POI tensor must be 2D, got {poi.shape} instead\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28mlen\u001b[39m(neighbors\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    108\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeighbour tensor must be 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mneighbors\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m neighbors \u001b[38;5;241m=\u001b[39m neighbors\u001b[38;5;241m.\u001b[39mhalf()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Neighbour tensor must be 3D, got torch.Size([1, 56, 26, 1024]) instead",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 45\u001b[0m\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     23\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,\n\u001b[1;32m     24\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     ],\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN_GNN:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_gnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:68\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[1;32m     67\u001b[0m     logger\u001b[38;5;241m.\u001b[39mfinalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[1;32m     70\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1010\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1011\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[1;32m   1012\u001b[0m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:537\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    536\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: moving model to CPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 537\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/lightning/fabric/utilities/device_dtype_mixin.py:82\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See :meth:`torch.nn.Module.cpu`.\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m _update_properties(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:964\u001b[0m, in \u001b[0;36mModule.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:964\u001b[0m, in \u001b[0;36mModule.cpu.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_GNN = True\n",
    "\n",
    "batch_size = 60\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()\n",
    "# cargo-cult like stuff that is supposed to make you faster\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "wandb.init(project=\"trovailpoi\")\n",
    "\n",
    "classifier_gnn = GRN(\n",
    "    dims,\n",
    "    spatial_graph,\n",
    "    temporal_graph,\n",
    "    hidden_dim=1024,\n",
    "    n_heads=1,\n",
    "    dropout_rate=0.9,\n",
    "    device=device,\n",
    ")\n",
    "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=40,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    log_every_n_steps=10,\n",
    "    logger=wandb_logger,\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        torchpl.callbacks.ModelCheckpoint(\n",
    "            monitor=\"val/loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            save_last=True,\n",
    "            filename=\"best_model\",\n",
    "        ),\n",
    "        torchpl.callbacks.EarlyStopping(\n",
    "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if TRAIN_GNN:\n",
    "    trainer.fit(model=classifier_gnn, datamodule=ds)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapbook for Experimentation\n",
    "\n",
    "Ignore all code below, it's just for quick prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gnn = GRN(\n",
    "    dims,\n",
    "    spatial_graph,\n",
    "    temporal_graph,\n",
    "    hidden_dim=1024,\n",
    "    n_heads=1,\n",
    "    dropout_rate=0.9,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(ds.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
