{"cells":[{"cell_type":"markdown","metadata":{"id":"SwkFEsEgCCyl"},"source":["# Foursquare dataset next-POI Recommendation System"]},{"cell_type":"markdown","metadata":{"id":"MZnW-ffHCCym"},"source":["First off we import all the necessary libraries:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ML-ffMMCCyn","outputId":"075952a5-3d41-4594-8495-97fba5697bcb"},"outputs":[],"source":[" %pip install lightning geohash2 wandb polars==0.20.25"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7nPgeM4CLmX","outputId":"b786e779-2bd5-4d98-fc0b-9d7a6769bdd0"},"outputs":[],"source":[" #from google.colab import drive\n","\n"," #drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8xK-4YqCCyn"},"outputs":[],"source":["import polars as rs\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import lightning as pl\n","import lightning.pytorch as torchpl\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from dataclasses import dataclass\n","import wandb\n","from rich import print"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FoCozR1YCCyo"},"outputs":[],"source":["import os\n","\n","# define WANDB_NOTEBOOK_NAME\n","os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train.ipynb\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yq1AScVfCCyo"},"outputs":[],"source":["import gc\n","\n","gc.collect()\n","# clean CUDA memory\n","torch.cuda.empty_cache()\n","\n","# sometimes jupyter notebook does not release memory, we leave this here so a run-all\n","# can *sometimes* fix leaks"]},{"cell_type":"markdown","metadata":{"id":"Z402h6bPCCyo"},"source":["Next, we load the data, we utilize `polars` since it is much more efficient than `pandas` and can handle large datasets with ease."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1F7L_QPkCCyo"},"outputs":[],"source":["columns = [\"user\", \"poi\", \"date\", \"TZ\"]\n","\n","DATASET_PATH = \"/kaggle/input/dataset-tist2015/dataset_TIST2015_Checkins.txt\"\n","\n","data = rs.read_csv(\n","    DATASET_PATH,\n","    has_header=False,\n","    low_memory=True,\n","    separator=\"\\t\",\n",")\n","data.columns = columns"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"LmYprUhOCCyo","outputId":"66033073-697a-4491-eb63-a1780ff90091"},"outputs":[],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"AE8Cxd2PCCyo"},"source":["Differently from what suggested by the professor, we utilize the full TIST2015 dataset, which has a far greater scale compared to the reduced NY one. However, by following the pruning steps detailed in the paper (http://dx.doi.org/10.1145/3477495.3531989, section 5.1), we obtain sequences that are much smaller in size, resulting in a dataset that is usable on Google Colab's free tier (as required by the assignment)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqLUIt0cCCyo"},"outputs":[],"source":["data_users = (\n","    data.lazy()\n","    .group_by(\"user\")\n","    .agg(\n","        [\n","            rs.col(\"poi\").n_unique().alias(\"n_pois\"),\n","            rs.col(\"poi\").count().alias(\"n_checkins\"),\n","            # turn the rest into a list\n","            rs.col(\"poi\").alias(\"pois\"),\n","            rs.col(\"date\").alias(\"dates\"),\n","            rs.col(\"TZ\").alias(\"TZs\"),\n","        ]\n","    )\n",").collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"HptthFauCCyo","outputId":"3e24da12-5c14-43c6-a990-118f72ce0637"},"outputs":[],"source":["data_users.describe()"]},{"cell_type":"markdown","metadata":{"id":"VqJjYuF1CCyp"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxCtvTymCCyp"},"outputs":[],"source":["data_culled = data_users.filter(\n","    (rs.col(\"n_checkins\") > 20) & (rs.col(\"n_checkins\") < 50)\n",").drop_nulls()"]},{"cell_type":"markdown","metadata":{"id":"rAqugUVTCCyp"},"source":["Since the original dataset is huge, we delete it and call the python garbage collector to free up memory. We then proceed with the second pruning step (frequency-based pruning) as detailed in the paper."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vc26KLj7CCyp","outputId":"33a0fb07-2a8d-4067-c8c7-0aed57160466"},"outputs":[],"source":["del data\n","del data_users\n","\n","import gc\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"mcWNAa-HaItt","outputId":"adb2acf1-40db-4fbf-f025-53d30a228009"},"outputs":[],"source":["# print lengths\n","\n","print(data_culled[\"pois\"].list.len().min(), data_culled[\"pois\"].list.len().max())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9jLArwDCCyp"},"outputs":[],"source":["# extract unique elements from each lists in data_culled[\"pois\"]\n","out = data_culled.with_columns(\n","    [\n","        rs.col(\"pois\").list.unique(),\n","        rs.col(\"pois\").list.unique().list.len().alias(\"n_unique_pois\"),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":565},"id":"xmWP2h6uCCyp","outputId":"679b33b6-5f50-413d-e681-2f6d55fa5911"},"outputs":[],"source":["out"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTYdomCBCCyp","outputId":"b2a65bb5-4032-4c09-cef2-d4fb8ce8bad8"},"outputs":[],"source":["l = out[\"pois\"][0].to_list()\n","len(set(l))  # print number of unique POIs in first sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ZvejeoKCCyp","outputId":"7208d743-35b8-4f3c-8d98-6189d1463d1e"},"outputs":[],"source":["l2 = data_culled[\"pois\"][0].to_list()\n","len(l2)  # print sequence length of first user"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8f24-SOxCCyp","outputId":"6b8b39d0-7172-4262-f2b4-728ab287d75d"},"outputs":[],"source":["len(set(l2))  # confirm that the two match"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i51vz46MCCyp"},"outputs":[],"source":["# run a Polars query to obtain all the frequent POIs, the ones expected to survive the filtering\n","unique_pois = out[\"pois\"]\n","frequent_pois = unique_pois.list.explode().value_counts().filter(rs.col(\"count\") >= 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"7aHVCPtcCCyp","outputId":"9f59d9c4-66fe-457b-cce9-2431c21dc506"},"outputs":[],"source":["frequent_pois"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"34H0_RIbCCyp"},"outputs":[],"source":["frequent_pois = frequent_pois[\"pois\"]\n","frequent_pois = set(frequent_pois.to_list())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"ib_qORq7CCyp","outputId":"fbc3d319-4cdc-418d-cb5e-a8741596d1d6"},"outputs":[],"source":["data_culled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n5IdbHrNCCyp"},"outputs":[],"source":["data_culled = data_culled.with_columns(\n","    [\n","        rs.col(\"pois\")\n","        .list.eval(\n","            rs.element().is_in(frequent_pois),\n","        )\n","        .alias(\"is_frequent\")\n","    ]\n",")  # prep mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rpFQCNJGCCyq"},"outputs":[],"source":["final_data = (\n","    data_culled.lazy()\n","    .explode(\n","        [\n","            \"pois\",\n","            \"dates\",\n","            \"TZs\",\n","            \"is_frequent\",\n","        ]\n","    )\n","    .group_by(\"user\")\n","    .agg(\n","        [\n","            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).alias(\"pois\"),\n","            rs.col(\"dates\").filter(rs.col(\"is_frequent\")).alias(\"dates\"),\n","            rs.col(\"TZs\").filter(rs.col(\"is_frequent\")).alias(\"TZs\"),\n","            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).n_unique().alias(\"n_pois\"),\n","            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).count().alias(\"n_checkins\"),\n","        ]\n","    )\n","    .filter(rs.col(\"n_checkins\") > 0)\n","    .filter(rs.col(\"n_pois\") > 0)\n","    .collect()\n",")  # filter out infrequent pois and users with no pois"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"CS0MglAhCCyq","outputId":"2d1e27dd-8820-4401-f408-990a711b0cea"},"outputs":[],"source":["final_data.describe()"]},{"cell_type":"markdown","metadata":{"id":"ItBEF5DFCCyq"},"source":["At this stage, culling is done, we can appreciate that `polars`'s SQL/functional-style API is different from Pandas, but it is very powerful and efficient."]},{"cell_type":"markdown","metadata":{"id":"HxS9E5bBCCyq"},"source":["The next step is geohashing the POIs, that is, we want to convert the latitude-longitude positions of the POIs into a grid-based geohash representation, which will form the basis for our network's embeddings."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5tSt9gYqCCyq"},"outputs":[],"source":["import geohash2 as gh\n","\n","POI_DATASET = \"/kaggle/input/dataset-tist2015/dataset_TIST2015_POIs.txt\"\n","\n","pois = rs.read_csv(\n","    POI_DATASET,\n","    has_header=False,\n","    low_memory=True,\n","    separator=\"\\t\",\n",")\n","pois.columns = [\"poi\", \"lat\", \"long\", \"category\", \"country\"]\n","pois = pois.drop(\"category\").drop(\"country\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa3YSEGrCCyq"},"outputs":[],"source":["pois = (\n","    pois.lazy()\n","    .filter(rs.col(\"poi\").is_in(frequent_pois))\n","    .select(\n","        [\n","            rs.col(\"poi\"),\n","            rs.struct(\n","                [\n","                    rs.col(\"lat\").cast(rs.Float32),\n","                    rs.col(\"long\").cast(rs.Float32),\n","                ]\n","            )\n","            .alias(\"location\")\n","            .map_elements(\n","                lambda s: gh.encode(s[\"lat\"], s[\"long\"], precision=6),\n","                return_dtype=rs.String,\n","            )\n","            .alias(\"geohash\"),\n","        ]\n","    )\n","    .collect()\n",")\n","poi_geo_dict = dict(zip(pois[\"poi\"], pois[\"geohash\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1GevNOtCCyq"},"outputs":[],"source":["# for each row in final_data, add the geohash of the pois by hitting the poi_geo_dict\n","\n","final_data = final_data.with_columns(\n","    [\n","        rs.col(\"pois\")\n","        .map_elements(\n","            lambda s: [poi_geo_dict[s] for s in s],\n","            return_dtype=rs.List(rs.String),\n","        )\n","        .alias(\"geohashes\")\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qaXNXfVfCCyq","outputId":"5beacffe-7ca1-44f0-887b-4db6f26569f5"},"outputs":[],"source":["final_data[\"dates\"][79].to_list()  # check out a temporal sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BenJc82OCCyq","outputId":"934d7234-d55c-4d0f-c322-47cfee96622b"},"outputs":[],"source":["final_data[\"TZs\"][79].to_list()  # ... and the corresponding timezones"]},{"cell_type":"markdown","metadata":{"id":"Vkv4I9FhCCyq"},"source":["The work *might* seem over, however, we still have timezones to account for, we want to normalize everything according to GMT, so we convert the timestamps accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ufyhRTJMCCyq"},"outputs":[],"source":["import datetime\n","\n","\n","def UTC_to_local(utc, tz):\n","\n","    date = datetime.datetime.strptime(utc, \"%a %b %d %H:%M:%S %z %Y\")\n","    date = date.replace(tzinfo=datetime.timezone.utc)\n","\n","    # shift by tz offset\n","    date = date.astimezone(datetime.timezone(datetime.timedelta(minutes=tz)))\n","\n","    date_s = datetime.datetime.strftime(date, \"%Y-%m-%d %H:%M:%S\")\n","    return date_s\n","\n","\n","def to_UNIX_time(date):\n","    return datetime.datetime.strptime(\n","        date, \"%Y-%m-%d %H:%M:%S\"\n","    ).timestamp()  # we use UNIX time as a key for sorting the POIs in our polars query"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"P1n-YGXLCCyq","outputId":"0020709b-a7c8-4667-f68e-b0c7e26d2047"},"outputs":[],"source":["UTC_to_local(\"Mon May 21 15:53:01 +0000 2012\", -420)  # example of usage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QJbyPkeCCyq"},"outputs":[],"source":["final_data = final_data.with_columns(\n","    [\n","        rs.struct([rs.col(\"dates\"), rs.col(\"TZs\")])\n","        .alias(\"times\")\n","        .map_elements(\n","            lambda struct: [\n","                UTC_to_local(date, tz)\n","                for date, tz in zip(struct[\"dates\"], struct[\"TZs\"])\n","            ],\n","            return_dtype=rs.List(rs.String),\n","        )\n","    ]\n",")  # This performs timezone conversion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mI9bmD3UCCyt"},"outputs":[],"source":["final_sorted = final_data.select(  # sort the times\n","    [\n","        rs.col(\"user\"),\n","        rs.struct(\n","            [\n","                rs.col(\"pois\"),\n","                rs.col(\"times\"),\n","            ]\n","        ).map_elements(\n","            lambda struct: [\n","                poi\n","                for poi, _ in sorted(\n","                    zip(  # here we sort the POIs struct by UNIX timestamps of the GMT times\n","                        struct[\"pois\"], [to_UNIX_time(date) for date in struct[\"times\"]]\n","                    ),\n","                    key=lambda s: s[1],\n","                )\n","            ],\n","            return_dtype=rs.List(rs.String),\n","        ),\n","        rs.struct(\n","            [\n","                rs.col(\"geohashes\"),\n","                rs.col(\"times\"),\n","            ]\n","        ).map_elements(\n","            lambda struct: [\n","                geo\n","                for geo, _ in sorted(\n","                    zip(\n","                        struct[\"geohashes\"],  # same thing goes on for geohashes\n","                        [to_UNIX_time(date) for date in struct[\"times\"]],\n","                    ),\n","                    key=lambda s: s[1],\n","                )\n","            ],\n","            return_dtype=rs.List(rs.String),\n","        ),\n","        rs.col(\"times\")\n","        .map_elements(\n","            lambda dates: sorted(dates, key=to_UNIX_time),\n","            return_dtype=rs.List(rs.String),\n","        )\n","        .alias(\"times_sorted\"),\n","        rs.col(\"n_checkins\"),\n","    ]\n",")\n","\n","# P.S, admittedly, it would have been more efficient to encode the geohashes *after* sorting the POIs,\n","# so that we could save on the sorting of the geohashes. Tough luck, you can't win 'em all."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8I9t4dirCCyt"},"outputs":[],"source":["final_sorted"]},{"cell_type":"markdown","metadata":{"id":"w-uFPvXPCCyt"},"source":["we now need to obtain a dataframe containing: each POI, it's geohash, and a set of all the check-ins it appears in\n","this is just one `polars` query away!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_nS1s8GECCyt"},"outputs":[],"source":["pois_checkins = final_sorted.explode([\"pois\", \"geohashes\"]).drop(\"n_checkins\")\n","\n","pois_checkins = (\n","    pois_checkins.with_columns(\n","        [\n","            rs.col(\"geohashes\").map_elements(lambda s: s[:4], rs.String).alias(\"g4\"),\n","        ]\n","    )\n","    .drop(\"geohashes\")\n","    .group_by([\"pois\", \"g4\"])\n","    .agg([rs.col(\"times_sorted\").flatten().alias(\"checkin_times\")])\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-2qN1sPCCyt"},"outputs":[],"source":["pois_checkins  # with this we can *efficiently* build our POI-POI spatial-temporal graphs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XY2TcDbXCCyt"},"outputs":[],"source":["def UTC_to_weekslot(utc: str) -> int:\n","    \"\"\"UTC_to_weekslot converts a UTC timestamp to a weekslot.\n","\n","    Parameters\n","    ----------\n","    utc : str\n","        A string representing a UTC timestamp.\n","\n","    Returns\n","    -------\n","    int\n","        A weekslot in the range [0, 56).\n","    \"\"\"\n","\n","    date = datetime.datetime.strptime(utc, \"%Y-%m-%d %H:%M:%S\")\n","    week = date.weekday()\n","    hour = date.hour\n","\n","    return week * 8 + hour // 3"]},{"cell_type":"markdown","metadata":{"id":"8fkRkLFgCCyt"},"source":["Next, we want to encode all of our inputs for our neural networks, this could *probably* be done\n","with polars magic, but it's too delicate and we prefer classic for-looping."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ItDfQyVUCCyt"},"outputs":[],"source":["encoder_dict = {\n","    \"users\": LabelEncoder(),\n","    \"pois\": LabelEncoder(),\n","    \"g2\": LabelEncoder(),\n","    \"g3\": LabelEncoder(),\n","    \"g4\": LabelEncoder(),\n","    \"g5\": LabelEncoder(),\n","    \"g6\": LabelEncoder(),\n","}\n","\n","encoded_data = {\n","    \"users\": [],\n","    \"pois\": [],\n","    \"g2\": [],\n","    \"g3\": [],\n","    \"g4\": [],\n","    \"g5\": [],\n","    \"g6\": [],\n","}\n","\n","unique_data = {\n","    \"users\": set(),\n","    \"pois\": set(),\n","    \"g2\": set(),\n","    \"g3\": set(),\n","    \"g4\": set(),\n","    \"g5\": set(),\n","    \"g6\": set(),\n","}\n","\n","# quick and dirty encoding:\n","# 1. put every unique symbol in a list\n","# 2. fit the respective encoder\n","# 3. transform the lists\n","\n","for i, row in enumerate(final_sorted.iter_rows()):\n","\n","    user, pois, geohashes, times_sorted, n_checkins = row\n","\n","    g2 = [geo[:2] for geo in geohashes]\n","    g3 = [geo[:3] for geo in geohashes]\n","    g4 = [geo[:4] for geo in geohashes]\n","    g5 = [geo[:5] for geo in geohashes]\n","    g6 = [geo[:6] for geo in geohashes]  # redundant, but I like symmetry\n","\n","    unique_data[\"users\"].add(user)\n","    unique_data[\"pois\"].update(pois)\n","    unique_data[\"g2\"].update(g2)\n","    unique_data[\"g3\"].update(g3)\n","    unique_data[\"g4\"].update(g4)\n","    unique_data[\"g5\"].update(g5)\n","    unique_data[\"g6\"].update(g6)\n","\n","for property, enc, data in zip(\n","    encoder_dict.keys(), encoder_dict.values(), unique_data.values()\n","):\n","    enc.fit(list(data))\n","    encoder_dict[property] = enc"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Il4AnsMUCCyt"},"outputs":[],"source":["# this could be optimized, right now it takes a while, at least we have a nice progress bar to look at\n","\n","ds_size = len(final_sorted)\n","\n","for i, row in tqdm(enumerate(final_sorted.iter_rows()), total=ds_size):\n","\n","    user, pois, geohashes, times_sorted, n_checkins = row\n","\n","    g2 = [geo[:2] for geo in geohashes]\n","    g3 = [geo[:3] for geo in geohashes]\n","    g4 = [geo[:4] for geo in geohashes]\n","    g5 = [geo[:5] for geo in geohashes]\n","    g6 = [geo[:6] for geo in geohashes]\n","\n","    encoded_data[\"users\"].append(encoder_dict[\"users\"].transform([user])[0])\n","    encoded_data[\"pois\"].append(encoder_dict[\"pois\"].transform(pois))\n","    encoded_data[\"g2\"].append(encoder_dict[\"g2\"].transform(g2))\n","    encoded_data[\"g3\"].append(encoder_dict[\"g3\"].transform(g3))\n","    encoded_data[\"g4\"].append(encoder_dict[\"g4\"].transform(g4))\n","    encoded_data[\"g5\"].append(encoder_dict[\"g5\"].transform(g5))\n","    encoded_data[\"g6\"].append(encoder_dict[\"g6\"].transform(g6))\n","\n","    # sum 1 to all values to avoid 0s\n","    encoded_data[\"users\"][-1] += 1\n","    encoded_data[\"pois\"][-1] += 1\n","    encoded_data[\"g2\"][-1] += 1\n","    encoded_data[\"g3\"][-1] += 1\n","    encoded_data[\"g4\"][-1] += 1\n","    encoded_data[\"g5\"][-1] += 1\n","    encoded_data[\"g6\"][-1] += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nN6GpNCFCCyu"},"outputs":[],"source":["# check that we left space for the padding token\n","min((arr.min() for arr in encoded_data[\"pois\"]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"enab_ljUCCyu"},"outputs":[],"source":["pois_checkins"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qyEXUwAcCCyu"},"outputs":[],"source":["# we also encode the graph dataframe so we can build the graphs\n","\n","pois_checkins = (\n","    pois_checkins.lazy()\n","    .with_columns(\n","        [\n","            rs.col(\"pois\").map_elements(\n","                lambda s: encoder_dict[\"pois\"].transform([s])[0] + 1, rs.Int64\n","            ),\n","            rs.col(\"g4\").map_elements(\n","                lambda s: encoder_dict[\"g4\"].transform([s])[0] + 1, rs.Int64\n","            ),  # apply utc_to_weekslot to each timestamp in the list\n","            rs.col(\"checkin_times\").map_elements(\n","                lambda s: [UTC_to_weekslot(date) for date in s], rs.List(rs.Int64)\n","            ),\n","        ]\n","    )\n","    .sort(\"pois\")\n","    .collect()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"w1-P4fDgCCyu"},"outputs":[],"source":["# add fictitious POI 0 to the graph, with nonexistent geohash and no timeslot, so we get a 0 row and column for the padding token\n","fake_datapoint = rs.DataFrame(\n","    {\n","        \"pois\": [0],\n","        \"g4\": [pois_checkins[\"g4\"].max() + 42],\n","        \"checkin_times\": [[43]],\n","    }\n",")\n","# this is a lot of work since polars dataframes are immutable by default, we have to run a query to change the 43 into an empty list\n","# we NEED the 43 otherwise polars won't infer the datatype of the list\n","\n","fake_datapoint = fake_datapoint.with_columns(\n","    [rs.col(\"checkin_times\").map_elements(lambda s: [], rs.List(rs.Int64))]\n",")\n","\n","pois_checkins = fake_datapoint.vstack(pois_checkins)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"i4zaRXGPCCyu"},"outputs":[],"source":["spatial_row = np.array(pois_checkins[\"g4\"].to_list()).reshape(-1, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rAL2xYaSCCyu"},"outputs":[],"source":["# outer product using equality\n","spatial_graph = (spatial_row == spatial_row.T).astype(np.int32)\n","spatial_graph[0, 0] = (\n","    0  # the fake g4 is still equal to itself, we suppress this equality\n",")\n","spatial_graph = torch.tensor(spatial_graph)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O5Glb5TaCCyu"},"outputs":[],"source":["temporal_row = pois_checkins[\"checkin_times\"].to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EKaTa7VNCCyu"},"outputs":[],"source":["temporal_graph = np.zeros((spatial_row.shape[0], spatial_row.shape[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sWGavlW5CCyu"},"outputs":[],"source":["temporal_sets = [np.array(list(set(row))) for row in temporal_row]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IAWEvt1mCCyu"},"outputs":[],"source":["time_sets = torch.zeros((len(temporal_sets), 56), dtype=torch.int8)\n","\n","for i, r in enumerate(temporal_row):\n","    indices = torch.tensor(r, dtype=torch.long)\n","    time_sets[i, indices] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"wGjJgRWaCCyu"},"outputs":[],"source":["time_sets.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ym-XXavSCCyu"},"outputs":[],"source":["# AND outer product\n","\n","intersection = time_sets @ time_sets.T\n","union = time_sets.unsqueeze(1) | time_sets.unsqueeze(0)\n","union = union.sum(dim=2)\n","iou = intersection / union"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uXE6xSDoCCyu"},"outputs":[],"source":["temporal_graph = iou >= 0.9\n","# cast to int\n","temporal_graph = temporal_graph.int()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"F_e6VXbgCCyu"},"outputs":[],"source":["temporal_graph[0, :].sum()"]},{"cell_type":"markdown","metadata":{"id":"NeCUaMGtCCyu"},"source":["We print information about the sparsity of the graphs, we note that\n","the sparsity of the graphs is similar to that of the paper."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-xX2oUeoCCyu"},"outputs":[],"source":["temporal_density = (\n","    temporal_graph.sum() / (temporal_graph.shape[0] * temporal_graph.shape[1])\n",").item()\n","spatial_density = (\n","    spatial_graph.sum() / (spatial_graph.shape[0] * spatial_graph.shape[1])\n",").item()\n","\n","print(f\"Temporal sparsity: {(1 - temporal_density) * 100:.2f}%\")\n","\n","print(f\"Spatial sparsity: {(1 - spatial_density) * 100:.2f}%\")"]},{"cell_type":"markdown","metadata":{"id":"6iiU7c42aItw"},"source":["## Train Test Split\n","\n","We now generate two dataframes from the `encoded_data` dataframe, one for training and one for testing.\n","\n","First, we have to drop every sequence that has less than 4 timestamps, as we wouldn't be able to get the minimum of two samples for each of the sets,\n","we then calculate the 80% of the sequences and split the data accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nNlKXjXbaItw"},"outputs":[],"source":["len(encoded_data[\"pois\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_tyiaen0aItw"},"outputs":[],"source":["total_data = rs.DataFrame(encoded_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"K67_I3DwaItw"},"outputs":[],"source":["total_data = total_data.with_columns(\n","    [\n","        rs.col(\"pois\").list.len().alias(\"length\"),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Vzaok7ZSaItw"},"outputs":[],"source":["total_data = total_data.with_columns(\n","    rs.col(\"length\")\n","    .map_elements(lambda s: int(0.8 * s) - 1, rs.Int64)\n","    .alias(\"train_end\")\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"hNmcZlX2aItw"},"outputs":[],"source":["# drop sequences that are too short\n","total_data = total_data.filter(\n","    (\n","        rs.col(\"train_end\") >= 1\n","    )  # at least 2 elements in the training set (1 is the index)\n","    & (\n","        rs.col(\"length\") - (rs.col(\"train_end\") + 1) >= 2\n","    )  # at least 2 elements in the validation set\n",")\n","print(total_data[\"length\"].mean())\n","print(total_data.count())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Mbl9-lbgaItx"},"outputs":[],"source":["total_data.sort(\"length\")  # check out the distribution of sequence lengths"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-fdFTxtRaItx"},"outputs":[],"source":["# Check if the shortest sequence is long enough\n","total_data.sort(\"length\")[\"pois\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bjuQpQN2aItx"},"outputs":[],"source":["# slice the two dataframes\n","train_data = total_data.select(\n","    [\n","        rs.col(\"users\"),\n","        rs.struct(\n","            [\n","                rs.col(\"pois\"),\n","                rs.col(\"g2\"),\n","                rs.col(\"g3\"),\n","                rs.col(\"g4\"),\n","                rs.col(\"g5\"),\n","                rs.col(\"g6\"),\n","                rs.col(\"train_end\"),\n","            ]\n","        )\n","        .map_elements(\n","            lambda struct: [\n","                struct[\"pois\"][: struct[\"train_end\"]],\n","                struct[\"g2\"][: struct[\"train_end\"]],\n","                struct[\"g3\"][: struct[\"train_end\"]],\n","                struct[\"g4\"][: struct[\"train_end\"]],\n","                struct[\"g5\"][: struct[\"train_end\"]],\n","                struct[\"g6\"][: struct[\"train_end\"]],\n","            ],\n","            return_dtype=rs.List(rs.List(rs.Int64)),\n","        )\n","        .alias(\"sequences\"),\n","    ]\n",")\n","\n","\n","test_data = total_data.select(\n","    [\n","        rs.col(\"users\"),\n","        rs.struct(\n","            [\n","                rs.col(\"pois\"),\n","                rs.col(\"g2\"),\n","                rs.col(\"g3\"),\n","                rs.col(\"g4\"),\n","                rs.col(\"g5\"),\n","                rs.col(\"g6\"),\n","                rs.col(\"train_end\"),\n","            ]\n","        )\n","        .map_elements(\n","            lambda struct: [\n","                struct[\"pois\"][struct[\"train_end\"] :],\n","                struct[\"g2\"][struct[\"train_end\"] :],\n","                struct[\"g3\"][struct[\"train_end\"] :],\n","                struct[\"g4\"][struct[\"train_end\"] :],\n","                struct[\"g5\"][struct[\"train_end\"] :],\n","                struct[\"g6\"][struct[\"train_end\"] :],\n","            ],\n","            return_dtype=rs.List(rs.List(rs.Int64)),\n","        )\n","        .alias(\"sequences\"),\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zuqr6FDiaItx"},"outputs":[],"source":["def explode_dict(d):\n","    \"\"\"explode_dict Convert packed polars dataframe into a neat python dict\n","\n","    Parameters\n","    ----------\n","    d : Polars.DataFrame\n","        A polars dataframe with a struct column\n","\n","    Returns\n","    -------\n","    dict\n","        A python dict with the same structure as the struct column\n","    \"\"\"\n","    ret = {\n","        \"users\": d[\"users\"].to_list(),\n","        \"pois\": [],\n","        \"g2\": [],\n","        \"g3\": [],\n","        \"g4\": [],\n","        \"g5\": [],\n","        \"g6\": [],\n","    }\n","\n","    for sample in d[\"sequences\"]:\n","        pois, g2, g3, g4, g5, g6 = sample\n","        ret[\"pois\"].append(pois.to_list())\n","        ret[\"g2\"].append(g2.to_list())\n","        ret[\"g3\"].append(g3.to_list())\n","        ret[\"g4\"].append(g4.to_list())\n","        ret[\"g5\"].append(g5.to_list())\n","        ret[\"g6\"].append(g6.to_list())\n","\n","    return ret"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HJYSRKeJaItx"},"outputs":[],"source":["encoded_data_train = explode_dict(train_data.to_dict())\n","encoded_data_test = explode_dict(test_data.to_dict())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6TsVcLgXZPM0"},"outputs":[],"source":["total_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"31OjFgF3ZPM0"},"outputs":[],"source":["encoded_data_train[\"pois\"][10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"lPdKaRW-ZPM0"},"outputs":[],"source":["encoded_data_test[\"pois\"][10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9KbV5-4TZPM0"},"outputs":[],"source":["total_data[\"pois\"][10].to_list()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6S2zqagAZPM0"},"outputs":[],"source":["min([len(l) for l in encoded_data_test[\"pois\"]])"]},{"cell_type":"markdown","metadata":{"id":"-PEXknqyCCyu"},"source":["## Metrics\n"]},{"cell_type":"markdown","metadata":{"id":"KxUt4jMGCCyu"},"source":["The paper utilizes metrics that check if the target is in the top-k recommendations, we implement them here."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4lW2sibnCCyv"},"outputs":[],"source":["class AccuracyAtK(nn.Module):\n","    def __init__(self, k: int):\n","        \"\"\"__init__ initializes the AccuracyAtK module.\n","\n","        Accuracy@k is the proportion of correct predictions in the top-k elements.\n","\n","        Parameters\n","        ----------\n","        k : int\n","            The number of top-k elements to consider.\n","\n","        \"\"\"\n","        super().__init__()\n","        self.k = k\n","\n","    def forward(\n","        self, logits: torch.Tensor, targets: torch.Tensor, padding_mask: torch.Tensor\n","    ) -> torch.Tensor:\n","        \"\"\"forward computes the accuracy at k between logits and targets.\n","\n","        Parameters\n","        ----------\n","        logits : torch.Tensor\n","            Class probability, either (B, C) or (B, T, C)\n","        targets : torch.Tensor\n","            Ground truth class indices, either (B,) or (B, T)\n","        padding_mask : torch.Tensor\n","            Padding mask, either (B,) or (B, T)\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","            The accuracy at k, a scalar-tensor.\n","        \"\"\"\n","\n","        \n","        predicted=logits.softmax(dim=-1)\n","        top_k=predicted.topk(self.k, dim=-1)[1]\n","        correct=(top_k==targets.unsqueeze(-1)).any(dim=-1).float()\n","        if padding_mask is not None:\n","            correct *= padding_mask.float()\n","            # Avoid division by zero by counting non-zero elements in the mask\n","            accuracy = correct.sum() / padding_mask.float().sum()\n","        else:\n","            accuracy = correct.mean()\n","        print(\"accuracy\",accuracy)\n","\n","        return accuracy\n","        '''\n","        \n","        # Gotta have at least one nasty python one-liner, in memory of the old\n","        # programming lab 1 bachelor course\n","        \n","        # P.S the one liner was bugged, the hubris of man...\n","        return (\n","            (\n","                logits.softmax(dim=-1)  # apply softmax\n","                .masked_fill(\n","                    padding_mask.unsqueeze(-1), -1e9\n","                )  # mask padding by imposing a very low probability (hacky)\n","                .topk(self.k, dim=-1)[1]  # extract top-k indices\n","                == targets.unsqueeze(-1)\n","            )\n","            .any(dim=-1)\n","            .float()\n","            .mean()\n","        )\n","        '''\n","\n","\n","class AccuracyAt1(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n","\n","        predicted = logits.argmax(dim=-1)\n","        correct = (predicted == targets).float()\n","        accuracy = correct.mean()\n","        return accuracy\n","\n","\n","class MeanReciprocalRank(nn.Module):\n","\n","    def __init__(self):\n","        \"\"\"__init__ initializes the MeanReciprocalRank module.\n","\n","        Mean reciprocal rank is the average of the reciprocal ranks of the top-k elements.\n","\n","        \"\"\"\n","        super().__init__()\n","\n","    def forward(\n","        self, logits: torch.Tensor, targets: torch.Tensor, padding_mask: torch.Tensor\n","    ) -> torch.Tensor:\n","        \"\"\"forward computes the mean reciprocal rank between logits and targets.\n","\n","        Parameters\n","        ----------\n","        logits : torch.Tensor\n","            Class probability\n","        targets : torch.Tensor\n","            Ground truth class indices\n","        padding_mask : torch.Tensor\n","            Padding mask\n","\n","        Returns\n","        -------\n","        torch.Tensor\n","            The mean reciprocal rank, a scalar-tensor.\n","        \"\"\"\n","        \n","        predicted = logits.softmax(dim=-1)\n","        top_k = predicted.topk(logits.size(-1), dim=-1)[1]\n","        ranks = (top_k == targets.unsqueeze(-1)).nonzero()[:, -1].float() + 1\n","        reciprocal_ranks = 1.0 / ranks\n","        if padding_mask is not None:\n","            reciprocal_ranks *= padding_mask.float()\n","            # Avoid division by zero by counting non-zero elements in the mask\n","            mrr = reciprocal_ranks.sum() / padding_mask.float().sum()\n","        else:\n","            mrr = reciprocal_ranks.mean()\n","        return mrr"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"J0Q9II4HCCyv"},"outputs":[],"source":["from torch.utils.data import Dataset\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","\n","\n","def rnn_collation_fn(batch):\n","\n","    users = []\n","    pois = []\n","    g2 = []\n","    g3 = []\n","    g4 = []\n","    g5 = []\n","    g6 = []\n","\n","\n","    for user, poi, geo2, geo3, geo4, geo5, geo6 in batch:\n","        users.append(user)\n","        pois.append(poi)\n","        g2.append(geo2)\n","        g3.append(geo3)\n","        g4.append(geo4)\n","        g5.append(geo5)\n","        g6.append(geo6)\n","\n","\n","    seq = (\n","        torch.tensor(users, dtype=torch.long),\n","        pad_sequence(pois, batch_first=True, padding_value=0),\n","        pad_sequence(g2, batch_first=True, padding_value=0),\n","        pad_sequence(g3, batch_first=True, padding_value=0),\n","        pad_sequence(g4, batch_first=True, padding_value=0),\n","        pad_sequence(g5, batch_first=True, padding_value=0),\n","        pad_sequence(g6, batch_first=True, padding_value=0),\n","    )  # build a sequence\n","\n","    x = (\n","        seq[0],\n","        seq[1][:, :-1],\n","        seq[2][:, :-1],\n","        seq[3][:, :-1],\n","        seq[4][:, :-1],\n","        seq[5][:, :-1],\n","        seq[6][:, :-1],\n","    )  # omit the last one for sample\n","\n","    y = (\n","        seq[0],\n","        seq[1][:, 1:],\n","        seq[2][:, 1:],\n","        seq[3][:, 1:],\n","        seq[4][:, 1:],\n","        seq[5][:, 1:],\n","        seq[6][:, 1:],\n","    )  # omit the first one for ground truth\n","\n","    # Take sequence lengths\n","    x_lengths = x[1].count_nonzero(dim=1)\n","    x_lengths = x_lengths.tolist()\n","\n","\n","    return x,y,x_lengths\n","\n","\n","class CheckinDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data[\"users\"])\n","\n","    def __getitem__(self, idx):\n","\n","        x = (\n","            torch.tensor(self.data[\"users\"][idx], dtype=torch.long),\n","            torch.tensor(self.data[\"pois\"][idx], dtype=torch.long),\n","            torch.tensor(self.data[\"g2\"][idx], dtype=torch.long),\n","            torch.tensor(self.data[\"g3\"][idx], dtype=torch.long),\n","            torch.tensor(self.data[\"g4\"][idx], dtype=torch.long),\n","            torch.tensor(self.data[\"g5\"][idx], dtype=torch.long),\n","            torch.tensor(self.data[\"g6\"][idx], dtype=torch.long),\n","        )\n","\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"y5gC9yrsCCyv"},"source":["## Dataset and Datamodule\n","\n","We then define a pytorch dataset and a custom collation function that allows us to dynamically\n","pad sequences to the longest one in the batch (as opposed to the longest one in the dataset)\n","as they are loaded during training, this gives us an edge in performance by dramatically reducing the\n","sparsity of our inputs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ncOgD2VxCCyv"},"outputs":[],"source":["class CheckinModule(pl.LightningDataModule):\n","    def __init__(self, encoded_data_train, encoded_data_test, batch_size=32, workers=4):\n","        \"\"\"__init__ initializes the CheckinModule.\n","\n","        Parameters\n","        ----------\n","        encoded_data_train : Union[dict, rs.DataFrame]\n","            The training data.\n","        encoded_data_test : Union[dict, rs.DataFrame]\n","            The testing data.\n","        batch_size : int, optional\n","            Size of the batches, by default 32\n","        workers : int, optional\n","            Number of worker processes, by default 4\n","        \"\"\"\n","        super().__init__()\n","        self.encoded_data_train = encoded_data_train\n","        self.encoded_data_test = encoded_data_test\n","        self.batch_size = batch_size\n","        self.workers = workers\n","\n","        assert isinstance(self.encoded_data_train, dict) or isinstance(\n","            self.encoded_data_train, rs.DataFrame\n","        ), \"encoded_data_train must be a dict or a polars DataFrame\"\n","        assert isinstance(self.encoded_data_test, dict) or isinstance(\n","            self.encoded_data_test, rs.DataFrame\n","        ), \"encoded_data_test must be a dict or a polars DataFrame\"\n","\n","        assert batch_size > 0, \"batch_size must be a positive integer\"\n","        assert workers >= 0, \"workers must be a non-negative integer\"\n","\n","    def setup(self, stage=None):\n","\n","        if (\n","            isinstance(self.encoded_data_train, dict)\n","            or isinstance(self.encoded_data_train, rs.DataFrame)\n","        ) and (\n","            isinstance(self.encoded_data_test, dict)\n","            or isinstance(self.encoded_data_test, rs.DataFrame)\n","        ):\n","            print(\"Loading data from dict/dataframe\")\n","            self.train_dataset = CheckinDataset(self.encoded_data_train)\n","            self.test_dataset = CheckinDataset(self.encoded_data_test)\n","\n","        elif isinstance(self.encoded_data_train, CheckinDataset) and isinstance(\n","            self.encoded_data_test, CheckinDataset\n","        ):\n","            print(\"Loading data from pre-instantiated datasets\")\n","            self.train_dataset = self.encoded_data_train\n","            self.test_dataset = self.encoded_data_test\n","        else:\n","            raise ValueError(\"Invalid data type\")\n","\n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            self.train_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=True,\n","            num_workers=self.workers,\n","            collate_fn=rnn_collation_fn,\n","        )\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            self.test_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.workers,\n","            collate_fn=rnn_collation_fn,\n","        )\n","\n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            self.test_dataset,\n","            batch_size=self.batch_size,\n","            shuffle=False,\n","            num_workers=self.workers,\n","            collate_fn=rnn_collation_fn,\n","        )\n","\n","    def save(self, whole_path, train_path, test_path):\n","\n","        torch.save(self.train_dataset, train_path)\n","        torch.save(self.test_dataset, test_path)\n","\n","    @staticmethod  # load without instantiating\n","    def load(train_path, test_path):\n","\n","        train_dataset = torch.load(train_path)\n","        test_dataset = torch.load(test_path)\n","\n","        return CheckinModule(train_dataset, test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"G_STfUGVCCyv"},"source":["## Baseline model: LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RcjMtxnFCCyv"},"outputs":[],"source":["@dataclass\n","class BaselineDimensions:\n","    nuser: int\n","    npoi: int\n","    g2len: int\n","    g3len: int\n","    g4len: int\n","    g5len: int\n","    g6len: int\n","\n","\n","# HMT_RN (Hierarchical Multi-Task Recurrent Network)\n","class HMT_RN(pl.LightningModule):\n","    def __init__(\n","        self,\n","        dimensions: BaselineDimensions,\n","        embedding_dim,\n","        lstm_hidden_dim,\n","        dropout_rate=0.9,\n","        lr=1e-4,\n","        # 0.9 is a lot, but the paper says so.\n","    ):\n","        super(HMT_RN, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = lstm_hidden_dim\n","        self.dims = dimensions\n","\n","        # Embedding layers one for user, one for poi and one for each G@P\n","        self.user_embedding = nn.Embedding(\n","            dimensions.nuser, embedding_dim, padding_idx=0\n","        )\n","        self.poi_embedding = nn.Embedding(dimensions.npoi, embedding_dim, padding_idx=0)\n","        self.g2_embed = nn.Embedding(dimensions.g2len, embedding_dim, padding_idx=0)\n","        self.g3_embed = nn.Embedding(dimensions.g3len, embedding_dim, padding_idx=0)\n","        self.g4_embed = nn.Embedding(dimensions.g4len, embedding_dim, padding_idx=0)\n","        self.g5_embed = nn.Embedding(dimensions.g5len, embedding_dim, padding_idx=0)\n","        self.g6_embed = nn.Embedding(dimensions.g6len, embedding_dim, padding_idx=0)\n","\n","        # Dropout layer for embeddings\n","        self.e_drop = nn.Dropout(p=dropout_rate)\n","\n","        # LSTM layer\n","        self.lstm = nn.LSTM(\n","            input_size=embedding_dim, hidden_size=lstm_hidden_dim, batch_first=True\n","        )\n","\n","        # Linear layers for prediction tasks\n","        self.linear_poi = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.npoi)\n","        self.linear_g2 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g2len)\n","        self.linear_g3 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g3len)\n","        self.linear_g4 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g4len)\n","        self.linear_g5 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g5len)\n","        self.linear_g6 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g6len)\n","\n","        # https://discuss.pytorch.org/t/ignore-padding-area-in-loss-computation/95804/6\n","        self.criterion = nn.CrossEntropyLoss(reduction=\"none\")\n","\n","        self.top1 = AccuracyAtK(1)\n","        self.top5 = AccuracyAtK(5)\n","        self.top10 = AccuracyAtK(10)\n","        self.top20 = AccuracyAtK(20)\n","        self.mrr = MeanReciprocalRank()\n","        \n","        self.lr = lr\n","\n","        self.apply(self.init_weights)\n","\n","    def init_weights(self, w):\n","\n","        if type(w) == nn.Linear:\n","            nn.init.kaiming_normal_(w.weight)\n","            nn.init.constant_(w.bias, 0)\n","        elif type(w) == nn.LSTM:\n","            for name, param in w.named_parameters():\n","                if \"bias\" in name:\n","                    nn.init.constant_(param, 0)\n","                elif \"weight\" in name:\n","                    nn.init.kaiming_normal_(param)\n","        elif type(w) == nn.Embedding:\n","            nn.init.kaiming_normal_(w.weight)\n","            nn.init.constant_(w.weight[0], 0)\n","\n","    def forward(self, batch, lengths):\n","        \"\"\"forward passes the batch through the model.\n","\n","        Parameters\n","        ----------\n","        batch : `tuple[torch.Tensor]`\n","            A tuple of tensors ordered as follows:\n","            (users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6)\n","        \"\"\"\n","\n","        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = batch\n","\n","        # unpack the packed sequences, retrieve the lengths, for the LSTM len_g2, etc... are ignored\n","#         poi, len_poi = pad_packed_sequence(poi, batch_first=True)\n","#         x_geoHash2, len_g2 = pad_packed_sequence(x_geoHash2, batch_first=True)\n","#         x_geoHash3, len_g3 = pad_packed_sequence(x_geoHash3, batch_first=True)\n","#         x_geoHash4, len_g4 = pad_packed_sequence(x_geoHash4, batch_first=True)\n","#         x_geoHash5, len_g5 = pad_packed_sequence(x_geoHash5, batch_first=True)\n","#         x_geoHash6, len_g6 = pad_packed_sequence(x_geoHash6, batch_first=True)\n","\n","        B, T = poi.shape\n","\n","        # make it so  that users are tiled T times\n","        users = users.repeat(T, 1).T\n","\n","        e_user = self.e_drop(self.user_embedding(users))\n","        e_poi = self.e_drop(self.poi_embedding(poi))\n","        e_gap2 = self.e_drop(self.g2_embed(x_geoHash2))\n","        e_gap3 = self.e_drop(self.g3_embed(x_geoHash3))\n","        e_gap4 = self.e_drop(self.g4_embed(x_geoHash4))\n","        e_gap5 = self.e_drop(self.g5_embed(x_geoHash5))\n","        e_gap6 = self.e_drop(self.g6_embed(x_geoHash6))\n","\n","        packed_poi = pack_padded_sequence(\n","            e_poi, lengths, batch_first=True, enforce_sorted=False\n","        )\n","        packed_output, (h_n, c_n) = self.lstm(packed_poi)\n","        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n","\n","        # dense layers\n","        next_poi = self.linear_poi(torch.cat((output, e_user), dim=2))\n","        next_g2 = self.linear_g2(torch.cat((output, e_gap2), dim=2))\n","        next_g3 = self.linear_g3(torch.cat((output, e_gap3), dim=2))\n","        next_g4 = self.linear_g4(torch.cat((output, e_gap4), dim=2))\n","        next_g5 = self.linear_g5(torch.cat((output, e_gap5), dim=2))\n","        next_g6 = self.linear_g6(torch.cat((output, e_gap6), dim=2))\n","\n","        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y, lenpoi = batch\n","\n","        (\n","            poi_pred,\n","            gap2_pred,\n","            gap3_pred,\n","            gap4_pred,\n","            gap5_pred,\n","            gap6_pred,\n","        ) = self(x, lenpoi)\n","\n","        loss_mask = (y[1] != 0).reshape(-1)\n","\n","        loss_poi = (self.criterion(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap2 = (self.criterion(\n","            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap3 = (self.criterion(\n","            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap4 = (self.criterion(\n","            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap5 = (self.criterion(\n","            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap6 = (self.criterion(\n","            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","\n","        loss = (\n","            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n","        ) / (loss_mask.sum() * 6)\n","        self.log(\"train/loss\", loss)\n","        self.log(\"train/loss_gap2\", loss_gap2)\n","        self.log(\"train/loss_gap3\", loss_gap3)\n","        self.log(\"train/loss_gap4\", loss_gap4)\n","        self.log(\"train/loss_gap5\", loss_gap5)\n","        self.log(\"train/loss_gap6\", loss_gap6)\n","        self.log(\"train/loss_poi\", loss_poi)\n","\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y, lenpoi = batch\n","        (\n","            poi_pred,\n","            gap2_pred,\n","            gap3_pred,\n","            gap4_pred,\n","            gap5_pred,\n","            gap6_pred,\n","        ) = self(x, lenpoi)\n","\n","        loss_mask = (y[1] != 0).reshape(-1)\n","\n","        loss_poi = (self.criterion(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap2 = (self.criterion(\n","            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap3 = (self.criterion(\n","            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap4 = (self.criterion(\n","            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap5 = (self.criterion(\n","            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap6 = (self.criterion(\n","            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","\n","        loss = (\n","            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n","        ) / (loss_mask.sum() * 6)\n","\n","\n","        top1_acc = self.top1(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top5_acc = self.top5(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top10_acc = self.top10(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top20_acc = self.top20(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        mrr = self.mrr(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","\n","        self.log(\"val/loss\", loss)\n","        self.log(\"val/loss_gap2\", loss_gap2)\n","        self.log(\"val/loss_gap3\", loss_gap3)\n","        self.log(\"val/loss_gap4\", loss_gap4)\n","        self.log(\"val/loss_gap5\", loss_gap5)\n","        self.log(\"val/loss_gap6\", loss_gap6)\n","        self.log(\"val/loss_poi\", loss_poi)\n","\n","        # log \"leaderboard\" metrics\n","\n","        self.log(\"val/top1\", top1_acc)\n","        self.log(\"val/top5\", top5_acc)\n","        self.log(\"val/top10\", top10_acc)\n","        self.log(\"val/top20\", top20_acc)\n","        self.log(\"val/mrr\", mrr)\n","\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        x, y, lenpoi = batch\n","        (\n","            poi_pred,\n","            gap2_pred,\n","            gap3_pred,\n","            gap4_pred,\n","            gap5_pred,\n","            gap6_pred,\n","        ) = self(x, lenpoi)\n","\n","        loss_mask = (y[1] != 0).reshape(-1)\n","\n","\n","        loss_poi = (self.criterion(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap2 = (self.criterion(\n","            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap3 = (self.criterion(\n","            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap4 = (self.criterion(\n","            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap5 = (self.criterion(\n","            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap6 = (self.criterion(\n","            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","\n","        loss = (\n","            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n","        ) / (loss_mask.sum() * 6)\n","\n","\n","        top1_acc = self.top1(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top5_acc = self.top5(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top10_acc = self.top10(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top20_acc = self.top20(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        mrr = self.mrr(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","\n","        self.log(\"test/loss\", loss)\n","        self.log(\"test/loss_gap2\", loss_gap2)\n","        self.log(\"test/loss_gap3\", loss_gap3)\n","        self.log(\"test/loss_gap4\", loss_gap4)\n","        self.log(\"test/loss_gap5\", loss_gap5)\n","        self.log(\"test/loss_gap6\", loss_gap6)\n","        self.log(\"test/loss_poi\", loss_poi)\n","\n","        # log \"leaderboard\" metrics\n","        self.log(\"test/top1\", top1_acc)\n","        self.log(\"test/top5\", top5_acc)\n","        self.log(\"test/top10\", top10_acc)\n","        self.log(\"test/top20\", top20_acc)\n","        self.log(\"test/mrr\", mrr)\n","\n","        return {\"loss\": loss}\n","    \n","\n","    def configure_optimizers(self):\n","        # Define optimizer and scheduler\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, amsgrad=True)\n","        \n","        sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            optimizer, T_0=10, T_mult=2\n","        )\n","        \n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": {\n","                \"scheduler\": sched,\n","                \"interval\": \"step\",\n","            },\n","        }"]},{"cell_type":"markdown","metadata":{"id":"aEkguqKVCCyv"},"source":["## Graph Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"BbiQDx04CCyv"},"outputs":[],"source":["# GNN Components\n","\n","\n","class attn_LSTM(pl.LightningModule):\n","\n","    def __init__(self, embedding_dim, hidden_dim):\n","        super(attn_LSTM, self).__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.W = nn.Linear(embedding_dim, 4 * hidden_dim)\n","        self.U = nn.Linear(hidden_dim, 4 * hidden_dim)\n","\n","        self.s_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n","        self.t_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n","\n","    def forward(self, x, hidden, spatial, temporal, numTimeSteps):\n","        x_unpacked,_ = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n","\n","        h_t, c_t = hidden\n","\n","        previous_h_t = h_t\n","        previous_c_t = c_t\n","\n","        allGates_preact = (\n","            self.W(x_unpacked) + self.U(previous_h_t) + self.s_W(spatial) + self.t_W(temporal)\n","        )\n","\n","        input_g = allGates_preact[:, :, : self.hidden_dim].sigmoid()\n","        forget_g = allGates_preact[\n","            :, :, self.hidden_dim : 2 * self.hidden_dim\n","        ].sigmoid()\n","        output_g = allGates_preact[\n","            :, :, 2 * self.hidden_dim : 3 * self.hidden_dim\n","        ].sigmoid()\n","        c_t_g = allGates_preact[:, :, 3 * self.hidden_dim :].tanh()\n","\n","        c_t = forget_g * previous_c_t + input_g * c_t_g\n","        h_t = output_g * c_t.tanh()\n","\n","        batchSize = x_unpacked.shape[0]\n","        h_t = h_t.view(batchSize, numTimeSteps, self.hidden_dim)\n","        c_t = c_t.view(batchSize, numTimeSteps, self.hidden_dim)\n","\n","        return x, (h_t, c_t)\n","\n","\n","def get_neighbours(adj_matrix, poi):\n","    neigh_indices_list = []\n","    max_length = 0\n","\n","    for batch_poi in poi:\n","        batch_indices = []\n","        for single_poi in batch_poi:\n","            poi_row = adj_matrix[single_poi]\n","            neigh_indices = torch.where(poi_row == 1)[0]\n","            batch_indices.append(neigh_indices)\n","            max_length = max(max_length, len(neigh_indices))\n","\n","        neigh_indices_list.append(batch_indices)\n","\n","    padded_neigh_indices_list = []\n","    for batch_indices in neigh_indices_list:\n","        padded_batch_indices = pad_sequence(\n","            batch_indices, batch_first=True, padding_value=0\n","        )\n","        padded_neigh_indices_list.append(padded_batch_indices)\n","\n","    padded_tensor = torch.stack(padded_neigh_indices_list)\n","\n","    return padded_tensor\n","\n","\n","class GRNSelfAttention(torch.nn.Module):\n","\n","    def __init__(self, hidden_dim, n_heads):\n","\n","        super(GRNSelfAttention, self).__init__()\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_heads = n_heads\n","\n","        self.Wp = nn.Linear(hidden_dim, hidden_dim)  # embeddings to pre-concat\n","        self.Wa = nn.Linear(2 * hidden_dim, hidden_dim)  # concatenation to pre-softmax\n","\n","        # total size = 3 * (hidden_dim) ** 2, quadratic in embedding size\n","\n","    def forward(self, poi, neighbors):\n","        \"\"\"forward\n","\n","        Parameters\n","        ----------\n","        poi: torch.Tensor\n","            A batched tensor of embedded POI vectors, (B x H) where H is the\n","            embedding dimension\n","        neighbors: torch.Tensor\n","            A batched tensor of sequences of embedded POI vectors that are extracted\n","            from an adjacency matrix (temporal or spatial neighbors of POI),\n","            (B x N x H), where N is the number of neighbours of POI, B is the\n","            batch size, H is the embedding dimension, and must be the same as POI\n","\n","        Returns\n","        -------\n","        tuple[torch.Tensor, torch.Tensor]\n","          A tuple containing the self-attention weighted hadamard product of neighbour activations\n","          in the first index, the attention weights in the second index.\n","        \"\"\"\n","        # assert len(poi.shape) == 2, f\"POI tensor must be 2D, got {poi.shape} instead\"\n","        assert (\n","            len(neighbors.shape) == 3\n","        ), f\"Neighbour tensor must be 3D, got {neighbors.shape} instead\"\n","\n","        B, N, H = neighbors.shape\n","\n","        h_poi = self.Wp(poi)\n","        h_n = self.Wp(neighbors)\n","        h_cat = torch.cat([h_poi.expand(B, N, -1), h_n], dim=2)\n","        h_att = F.leaky_relu(self.Wa(h_cat))\n","\n","        alpha = torch.nn.functional.softmax(h_att, dim=1)\n","\n","        p = torch.sum(alpha * h_n, dim=1)\n","        return p, alpha"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lpnLqpOSCCyv"},"outputs":[],"source":["# GRN (Graph Recurrent Network)\n","class GRN(pl.LightningModule):\n","\n","    def __init__(\n","        self,\n","        dims: BaselineDimensions,\n","        spatial_graph,\n","        temporal_graph,\n","        hidden_dim,\n","        n_heads,\n","        dropout_rate=0.9,\n","        device=\"cpu\",\n","        lr=1e-4,\n","    ):\n","        super(GRN, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.n_heads = n_heads\n","        self.dims = dims\n","\n","        self.spatial_graph = spatial_graph.to(device)\n","        self.temporal_graph = temporal_graph.to(device)\n","\n","        self.spatial_attn = GRNSelfAttention(hidden_dim, n_heads)\n","        self.temporal_attn = GRNSelfAttention(hidden_dim, n_heads)\n","\n","        self.lstm = attn_LSTM(hidden_dim, hidden_dim)\n","\n","        self.dropout = nn.Dropout(dropout_rate)\n","\n","        self.user_embedding = nn.Embedding(dims.nuser, hidden_dim, padding_idx=0)\n","        self.poi_embedding = nn.Embedding(dims.npoi, hidden_dim, padding_idx=0)\n","        self.g2_embed = nn.Embedding(dims.g2len, hidden_dim, padding_idx=0)\n","        self.g3_embed = nn.Embedding(dims.g3len, hidden_dim, padding_idx=0)\n","        self.g4_embed = nn.Embedding(dims.g4len, hidden_dim, padding_idx=0)\n","        self.g5_embed = nn.Embedding(dims.g5len, hidden_dim, padding_idx=0)\n","        self.g6_embed = nn.Embedding(dims.g6len, hidden_dim, padding_idx=0)\n","\n","        self.linear_poi = nn.Linear(2 * hidden_dim, dims.npoi)\n","        self.linear_g2 = nn.Linear(2 * hidden_dim, dims.g2len)\n","        self.linear_g3 = nn.Linear(2 * hidden_dim, dims.g3len)\n","        self.linear_g4 = nn.Linear(2 * hidden_dim, dims.g4len)\n","        self.linear_g5 = nn.Linear(2 * hidden_dim, dims.g5len)\n","        self.linear_g6 = nn.Linear(2 * hidden_dim, dims.g6len)\n","        self.top1 = AccuracyAtK(1)\n","        self.top5 = AccuracyAtK(5)\n","        self.top10 = AccuracyAtK(10)\n","        self.top20 = AccuracyAtK(20)\n","        self.mrr = MeanReciprocalRank()\n","\n","        # extract indices from one-hot neighbor list\n","        self.iota = torch.arange(self.dims.npoi, requires_grad=False, device=device)\n","\n","        self.criterion = nn.CrossEntropyLoss(reduction=\"none\")\n","        \n","        self.lr = lr\n","\n","        self.apply(self.init_weights)\n","\n","    def init_weights(self, w):\n","        if type(w) == nn.Linear:\n","            nn.init.kaiming_normal_(w.weight)\n","            nn.init.constant_(w.bias, 0)\n","        elif type(w) == nn.LSTM:\n","            for name, param in w.named_parameters():\n","                if \"bias\" in name:\n","                    nn.init.constant_(param, 0)\n","                elif \"weight\" in name:\n","                    nn.init.kaiming_normal_(param)\n","        elif type(w) == nn.Embedding:\n","            nn.init.kaiming_normal_(w.weight)\n","            nn.init.constant_(w.weight[0], 0)\n","\n","    def forward(self, x, lengths):\n","\n","        users, poi, x_g2, x_g3, x_g4, x_g5, x_g6 = x\n","        B, T = poi.shape\n","\n","        users = users.repeat(T, 1).T\n","\n","        neighbors_spatial = self.spatial_graph[poi]\n","        neighbors_temporal = self.temporal_graph[poi]\n","\n","        e_user = self.dropout(self.user_embedding(users))\n","        e_poi = self.dropout(self.poi_embedding(poi))\n","        e_gap2 = self.dropout(self.g2_embed(x_g2))\n","        e_gap3 = self.dropout(self.g3_embed(x_g3))\n","        e_gap4 = self.dropout(self.g4_embed(x_g4))\n","        e_gap5 = self.dropout(self.g5_embed(x_g5))\n","        e_gap6 = self.dropout(self.g6_embed(x_g6))\n","\n","        spatial_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n","        temporal_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n","\n","        for b in range(B):\n","            for t in range(T):\n","\n","                spatial_neigh = neighbors_spatial[b, t] * self.iota\n","                temporal_neigh = neighbors_temporal[b, t] * self.iota\n","\n","                spatial_neigh = spatial_neigh[spatial_neigh != 0]\n","                temporal_neigh = temporal_neigh[temporal_neigh != 0]\n","\n","                spatial_neigh = spatial_neigh.unsqueeze(0)\n","                temporal_neigh = temporal_neigh.unsqueeze(0)\n","\n","                e_spatial = self.dropout(self.poi_embedding(spatial_neigh))\n","                e_temporal = self.dropout(self.poi_embedding(temporal_neigh))\n","\n","                curr_poi = e_poi[b, t].unsqueeze(0)\n","\n","                spatial_p, _ = self.spatial_attn(curr_poi, e_spatial)\n","                temporal_p, _ = self.temporal_attn(curr_poi, e_temporal)\n","\n","                # we are not using the batch dimension, so we squeeze it\n","                spatial_atts[b, t] = spatial_p.squeeze()\n","                temporal_atts[b, t] = temporal_p.squeeze()\n","\n","        # zero-init LSTM states\n","        h_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n","        c_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n","\n","        packed_input = nn.utils.rnn.pack_padded_sequence(\n","            e_poi, lengths, batch_first=True, enforce_sorted=False\n","        )\n","        pack_out, (h_t, c_t) = self.lstm(\n","            packed_input, (h_t, c_t), spatial_atts, temporal_atts, T\n","        )\n","        output, _ = nn.utils.rnn.pad_packed_sequence(\n","            pack_out, batch_first=True\n","        )\n","\n","        # Note:the prediction of the poi depends on the embedding of the user\n","        next_poi = self.linear_poi(torch.cat((output, e_user), dim=2))\n","        next_g2 = self.linear_g2(torch.cat((output, e_gap2), dim=2))\n","        next_g3 = self.linear_g3(torch.cat((output, e_gap3), dim=2))\n","        next_g4 = self.linear_g4(torch.cat((output, e_gap4), dim=2))\n","        next_g5 = self.linear_g5(torch.cat((output, e_gap5), dim=2))\n","        next_g6 = self.linear_g6(torch.cat((output, e_gap6), dim=2))\n","\n","        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y, len_x = batch\n","        (\n","            poi_pred,\n","            gap2_pred,\n","            gap3_pred,\n","            gap4_pred,\n","            gap5_pred,\n","            gap6_pred,\n","        ) = self(x, len_x)\n","\n","        loss_mask = (y[1] != 0).reshape(-1)\n","        loss_poi = (\n","            self.criterion(poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap2 = (\n","            self.criterion(gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap3 = (\n","            self.criterion(gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap4 = (\n","            self.criterion(gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap5 = (\n","            self.criterion(gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap6 = (\n","            self.criterion(gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","\n","        loss = (\n","            (loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6)\n","            / loss_mask.sum()\n","            * 6\n","        )\n","\n","        self.log(\"train/loss\", loss)\n","        self.log(\"train/loss_gap2\", loss_gap2)\n","        self.log(\"train/loss_gap3\", loss_gap3)\n","        self.log(\"train/loss_gap4\", loss_gap4)\n","        self.log(\"train/loss_gap5\", loss_gap5)\n","        self.log(\"train/loss_gap6\", loss_gap6)\n","        self.log(\"train/loss_poi\", loss_poi)\n","\n","        return {\"loss\": loss}\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y, len_x = batch\n","\n","        (\n","            poi_pred,\n","            gap2_pred,\n","            gap3_pred,\n","            gap4_pred,\n","            gap5_pred,\n","            gap6_pred,\n","        ) = self(x, len_x)\n","\n","\n","        loss_mask = (y[1] != 0).reshape(-1)\n","        loss_poi = (\n","            self.criterion(poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap2 = (\n","            self.criterion(gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap3 = (\n","            self.criterion(gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap4 = (\n","            self.criterion(gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap5 = (\n","            self.criterion(gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap6 = (\n","            self.criterion(gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","\n","        loss = (\n","            (loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6)\n","            / loss_mask.sum()\n","            * 6\n","        )\n","\n","        top1_acc = self.top1(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top5_acc = self.top5(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top10_acc = self.top10(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top20_acc = self.top20(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        mrr = self.mrr(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","\n","        self.log(\"val/loss\", loss)\n","        self.log(\"val/loss_gap2\", loss_gap2)\n","        self.log(\"val/loss_gap3\", loss_gap3)\n","        self.log(\"val/loss_gap4\", loss_gap4)\n","        self.log(\"val/loss_gap5\", loss_gap5)\n","        self.log(\"val/loss_gap6\", loss_gap6)\n","        self.log(\"val/loss_poi\", loss_poi)\n","\n","        # log \"leaderboard\" metrics\n","        self.log(\"val/top1\", top1_acc)\n","        self.log(\"val/top5\", top5_acc)\n","        self.log(\"val/top10\", top10_acc)\n","        self.log(\"val/top20\", top20_acc)\n","        self.log(\"val/mrr\", mrr)\n","\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        x, y, len_x = batch\n","\n","\n","\n","        (\n","            poi_pred,\n","            gap2_pred,\n","            gap3_pred,\n","            gap4_pred,\n","            gap5_pred,\n","            gap6_pred,\n","        ) = self(x, len_x)\n","\n","\n","\n","        loss_mask = (y[1] != 0).reshape(-1)\n","\n","        loss_poi = (\n","            self.criterion(poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap2 = (\n","            self.criterion(gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap3 = (\n","            self.criterion(gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap4 = (\n","            self.criterion(gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap5 = (\n","            self.criterion(gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","        loss_gap6 = (\n","            self.criterion(gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n","            .where(loss_mask, torch.tensor(0.0))\n","            .sum()\n","        )\n","\n","        loss = (\n","            (loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6)\n","            / loss_mask.sum()\n","            * 6\n","        )\n","\n","        top1_acc = self.top1(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top5_acc = self.top5(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top10_acc = self.top10(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        top20_acc = self.top20(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        mrr = self.mrr(\n","            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n","        )\n","        self.log(\"test/loss\", loss)\n","        self.log(\"test/loss_gap2\", loss_gap2)\n","        self.log(\"test/loss_gap3\", loss_gap3)\n","        self.log(\"test/loss_gap4\", loss_gap4)\n","        self.log(\"test/loss_gap5\", loss_gap5)\n","        self.log(\"test/loss_gap6\", loss_gap6)\n","        self.log(\"test/loss_poi\", loss_poi)\n","\n","        # log \"leaderboard\" metrics\n","        self.log(\"test/top1\", top1_acc)\n","        self.log(\"test/top5\", top5_acc)\n","        self.log(\"test/top10\", top10_acc)\n","        self.log(\"test/top20\", top20_acc)\n","        self.log(\"test/mrr\", mrr)\n","\n","        return {\"loss\": loss}\n","\n","\n","    def configure_optimizers(self):\n","        # Define optimizer and scheduler\n","        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, amsgrad=True)\n","        \n","        sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","            optimizer, T_0=10, T_mult=2\n","        )\n","        \n","        return {\n","            \"optimizer\": optimizer,\n","            \"lr_scheduler\": {\n","                \"scheduler\": sched,\n","                \"interval\": \"step\",\n","            },\n","        }"]},{"cell_type":"markdown","metadata":{"id":"kRG9Fg0sCCyw"},"source":["## Training Loops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4B3gEpRhCCyw"},"outputs":[],"source":["n_users = encoder_dict[\"users\"].classes_.shape[0]\n","n_pois = encoder_dict[\"pois\"].classes_.shape[0]\n","n_g2 = encoder_dict[\"g2\"].classes_.shape[0]\n","n_g3 = encoder_dict[\"g3\"].classes_.shape[0]\n","n_g4 = encoder_dict[\"g4\"].classes_.shape[0]\n","n_g5 = encoder_dict[\"g5\"].classes_.shape[0]\n","n_g6 = encoder_dict[\"g6\"].classes_.shape[0]\n","\n","\n","# account for the padding token\n","dims = BaselineDimensions(\n","    n_users + 1, n_pois + 1, n_g2 + 1, n_g3 + 1, n_g4 + 1, n_g5 + 1, n_g6 + 1\n",")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJsxdOY5CCyw"},"outputs":[],"source":["from lightning.pytorch.loggers import WandbLogger\n","from lightning.pytorch import Trainer\n","from lightning.pytorch import Tuner\n","\n","TRAIN_BASELINE = True\n","\n","wandb.finish()\n","torch.cuda.empty_cache()\n","# cargo-cult like stuff that is supposed to make you faster\n","torch.set_float32_matmul_precision(\"medium\")\n","torch.backends.cudnn.benchmark = True\n","\n","ds = CheckinModule(encoded_data_train, encoded_data_test, batch_size=32, workers=4)\n","\n","\n","wandb.init(project=\"trovailpoi\")\n","\n","classifier_baseline = HMT_RN(dims, embedding_dim=1024, lstm_hidden_dim=1024)\n","wandb_logger = WandbLogger(project=\"trovailpoi\")\n","trainer = Trainer(\n","    max_epochs=200,\n","    accelerator=\"auto\",\n","    devices=[0],\n","    log_every_n_steps=10,\n","    logger=wandb_logger,\n","    strategy=\"auto\",\n","    callbacks=[\n","        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n","        torchpl.callbacks.ModelCheckpoint(\n","            monitor=\"val/loss\",\n","            mode=\"min\",\n","            save_top_k=1,\n","            save_last=True,\n","            filename=\"best_model\",\n","        ),\n","        torchpl.callbacks.EarlyStopping(\n","            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n","        ),\n","    ],\n",")\n","\n","tuner = Tuner(trainer)\n","\n","if TRAIN_BASELINE:\n","    \n","    tuner.scale_batch_size(classifier_baseline, mode=\"power\")\n","    tuner.lr_find(classifier_baseline)\n","    trainer.fit(model=classifier_baseline, datamodule=ds)\n","    \n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZltK8HPhCCyw"},"outputs":[],"source":["from lightning.pytorch.loggers import WandbLogger\n","from lightning.pytorch import Trainer\n","\n","TRAIN_GNN = True\n","\n","wandb.finish()\n","torch.cuda.empty_cache()\n","# cargo-cult like stuff that is supposed to make you faster\n","torch.set_float32_matmul_precision(\"medium\")\n","torch.backends.cudnn.benchmark = True\n","\n","ds = CheckinModule(encoded_data_train, encoded_data_test, batch_size=32, workers=4)\n","\n","\n","wandb.init(project=\"trovailpoi\")\n","\n","classifier_gnn = GRN(\n","    dims,\n","    spatial_graph,\n","    temporal_graph,\n","    hidden_dim=1024,\n","    n_heads=1,\n","    dropout_rate=0.9,\n","    device=device,\n",")\n","\n","wandb_logger = WandbLogger(project=\"trovailpoi\")\n","\n","trainer = Trainer(\n","    max_epochs=200,\n","    accelerator=\"auto\",\n","    devices=[0],\n","    log_every_n_steps=10,\n","    logger=wandb_logger,\n","    strategy=\"auto\",\n","    callbacks=[\n","        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n","        torchpl.callbacks.ModelCheckpoint(\n","            monitor=\"val/loss\",\n","            mode=\"min\",\n","            save_top_k=1,\n","            save_last=True,\n","            filename=\"best_model\",\n","        ),\n","        torchpl.callbacks.EarlyStopping(\n","            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n","        ),\n","    ],\n",")\n","\n","tuner = Tuner(trainer)\n","\n","if TRAIN_GNN:\n","    \n","    tuner.scale_batch_size(classifier_gnn, mode=\"power\")\n","    tuner.lr_find(classifier_gnn)\n","    trainer.fit(model=classifier_gnn, datamodule=ds)\n","    \n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abzS8kwAKPPu"},"outputs":[],"source":["checkpoint_path = \"/content/trovailpoi/dnpotgxc/checkpoints/best_model.ckpt\"\n","# Load the trained model from the checkpoint\n","trained_model = HMT_RN.load_from_checkpoint(\n","    checkpoint_path,\n","    dimensions=dims,\n","    embedding_dim=1024,  # Example embedding dimension\n","    lstm_hidden_dim=1024,  # Example LSTM hidden dimension\n","    dropout_rate=0.9,  # Example dropout rate\n",")\n","\n","# Create a test dataloader\n","# Assuming you have a method `test_dataloader` in your data module\n","test_loader = ds.test_dataloader()  # Replace `ds` with your actual data module instance\n","\n","# Instantiate the trainer\n","trainer = Trainer(accelerator=\"auto\", devices=[0])\n","\n","# Test the model\n","results = trainer.test(trained_model, test_loader)\n","\n","# Print the test results\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"ik7z0iyRCCyw"},"source":["## Scrapbook for Experimentation\n","\n","Ignore all code below, it's just for quick prototyping"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4985565,"sourceId":8383172,"sourceType":"datasetVersion"},{"datasetId":5026368,"sourceId":8438278,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
