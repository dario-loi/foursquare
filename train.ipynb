{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8383172,"sourceType":"datasetVersion","datasetId":4985565}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Foursquare dataset next-POI Recommendation System","metadata":{}},{"cell_type":"markdown","source":"First off we import all the necessary libraries:","metadata":{}},{"cell_type":"code","source":"%pip install lightning geohash2","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:16:39.908174Z","iopub.execute_input":"2024-05-12T17:16:39.908606Z","iopub.status.idle":"2024-05-12T17:16:55.475004Z","shell.execute_reply.started":"2024-05-12T17:16:39.908577Z","shell.execute_reply":"2024-05-12T17:16:55.473782Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Requirement already satisfied: lightning in /opt/conda/lib/python3.10/site-packages (2.2.4)\nCollecting geohash2\n  Downloading geohash2-1.1.tar.gz (15 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.1)\nRequirement already satisfied: fsspec<2025.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.0)\nRequirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.2)\nRequirement already satisfied: numpy<3.0,>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.26.4)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.1.2)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.3.2)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.9.0)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.2.2)\nRequirement already satisfied: docutils>=0.3 in /opt/conda/lib/python3.10/site-packages (from geohash2) (0.21.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (69.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=1.13.0->lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\nBuilding wheels for collected packages: geohash2\n  Building wheel for geohash2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for geohash2: filename=geohash2-1.1-py3-none-any.whl size=15543 sha256=bb500658b5569c6699056cd94a1dcb4764a4beeb9575463869afb672e3534fe0\n  Stored in directory: /root/.cache/pip/wheels/c0/21/8d/fe65503f4f439aef35193e5ec10a14adc945e20ff87eb35895\nSuccessfully built geohash2\nInstalling collected packages: geohash2\nSuccessfully installed geohash2-1.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import polars as rs\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport lightning as pl\nimport lightning.pytorch as torchpl\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom dataclasses import dataclass\nimport wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:11:52.593146Z","iopub.execute_input":"2024-05-12T17:11:52.593531Z","iopub.status.idle":"2024-05-12T17:12:00.776943Z","shell.execute_reply.started":"2024-05-12T17:11:52.593495Z","shell.execute_reply":"2024-05-12T17:12:00.775973Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\n\n# define WANDB_NOTEBOOK_NAME\nos.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train.ipynb\"","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:00.778167Z","iopub.execute_input":"2024-05-12T17:12:00.778505Z","iopub.status.idle":"2024-05-12T17:12:00.783184Z","shell.execute_reply.started":"2024-05-12T17:12:00.778481Z","shell.execute_reply":"2024-05-12T17:12:00.782051Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import gc\n\ngc.collect()\n# clean CUDA memory\ntorch.cuda.empty_cache()\n\n# sometimes jupyter notebook does not release memory, we leave this here so a run-all\n# can *sometimes* fix leaks","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:00.785546Z","iopub.execute_input":"2024-05-12T17:12:00.785872Z","iopub.status.idle":"2024-05-12T17:12:00.948990Z","shell.execute_reply.started":"2024-05-12T17:12:00.785839Z","shell.execute_reply":"2024-05-12T17:12:00.948059Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Next, we load the data, we utilize `polars` since it is much more efficient than `pandas` and can handle large datasets with ease.","metadata":{}},{"cell_type":"code","source":"columns = [\"user\", \"poi\", \"date\", \"TZ\"]\ndata = rs.read_csv(\n    \"/kaggle/input/dataset-tist2015/dataset_TIST2015_Checkins.txt\",\n    has_header=False,\n    low_memory=True,\n    separator=\"\\t\",\n)\ndata.columns = columns","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:00.950226Z","iopub.execute_input":"2024-05-12T17:12:00.950556Z","iopub.status.idle":"2024-05-12T17:12:12.364264Z","shell.execute_reply.started":"2024-05-12T17:12:00.950533Z","shell.execute_reply":"2024-05-12T17:12:12.363300Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:12.365564Z","iopub.execute_input":"2024-05-12T17:12:12.365861Z","iopub.status.idle":"2024-05-12T17:12:12.383574Z","shell.execute_reply.started":"2024-05-12T17:12:12.365837Z","shell.execute_reply":"2024-05-12T17:12:12.382591Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"shape: (33_263_633, 4)\n┌────────┬──────────────────────────┬────────────────────────────────┬──────┐\n│ user   ┆ poi                      ┆ date                           ┆ TZ   │\n│ ---    ┆ ---                      ┆ ---                            ┆ ---  │\n│ i64    ┆ str                      ┆ str                            ┆ i64  │\n╞════════╪══════════════════════════╪════════════════════════════════╪══════╡\n│ 50756  ┆ 4f5e3a72e4b053fd6a4313f6 ┆ Tue Apr 03 18:00:06 +0000 2012 ┆ 240  │\n│ 190571 ┆ 4b4b87b5f964a5204a9f26e3 ┆ Tue Apr 03 18:00:07 +0000 2012 ┆ 180  │\n│ 221021 ┆ 4a85b1b3f964a520eefe1fe3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -240 │\n│ 66981  ┆ 4b4606f2f964a520751426e3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -300 │\n│ 21010  ┆ 4c2b4e8a9a559c74832f0de2 ┆ Tue Apr 03 18:00:09 +0000 2012 ┆ 240  │\n│ …      ┆ …                        ┆ …                              ┆ …    │\n│ 16349  ┆ 4c957755c8a1bfb7e89024f3 ┆ Mon Sep 16 23:24:11 +0000 2013 ┆ -240 │\n│ 256757 ┆ 4c8bbb6d9ef0224bd2d6667b ┆ Mon Sep 16 23:24:13 +0000 2013 ┆ -180 │\n│ 66425  ┆ 513e82a5e4b0ed4f0f3bcf2d ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ -180 │\n│ 1830   ┆ 4b447865f964a5204cf525e3 ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ 120  │\n│ 22704  ┆ 50df4ee5e4b0c48b5a1c2968 ┆ Mon Sep 16 23:24:15 +0000 2013 ┆ 180  │\n└────────┴──────────────────────────┴────────────────────────────────┴──────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (33_263_633, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>poi</th><th>date</th><th>TZ</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>50756</td><td>&quot;4f5e3a72e4b053…</td><td>&quot;Tue Apr 03 18:…</td><td>240</td></tr><tr><td>190571</td><td>&quot;4b4b87b5f964a5…</td><td>&quot;Tue Apr 03 18:…</td><td>180</td></tr><tr><td>221021</td><td>&quot;4a85b1b3f964a5…</td><td>&quot;Tue Apr 03 18:…</td><td>-240</td></tr><tr><td>66981</td><td>&quot;4b4606f2f964a5…</td><td>&quot;Tue Apr 03 18:…</td><td>-300</td></tr><tr><td>21010</td><td>&quot;4c2b4e8a9a559c…</td><td>&quot;Tue Apr 03 18:…</td><td>240</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>16349</td><td>&quot;4c957755c8a1bf…</td><td>&quot;Mon Sep 16 23:…</td><td>-240</td></tr><tr><td>256757</td><td>&quot;4c8bbb6d9ef022…</td><td>&quot;Mon Sep 16 23:…</td><td>-180</td></tr><tr><td>66425</td><td>&quot;513e82a5e4b0ed…</td><td>&quot;Mon Sep 16 23:…</td><td>-180</td></tr><tr><td>1830</td><td>&quot;4b447865f964a5…</td><td>&quot;Mon Sep 16 23:…</td><td>120</td></tr><tr><td>22704</td><td>&quot;50df4ee5e4b0c4…</td><td>&quot;Mon Sep 16 23:…</td><td>180</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Differently from what suggested by the professor, we utilize the full TIST2015 dataset, which has a far greater scale compared to the reduced NY one. However, by following the pruning steps detailed in the paper (http://dx.doi.org/10.1145/3477495.3531989, section 5.1), we obtain sequences that are much smaller in size, resulting in a dataset that is usable on Google Colab's free tier (as required by the assignment).","metadata":{}},{"cell_type":"code","source":"data_users = (\n    data.lazy()\n    .group_by(\"user\")\n    .agg(\n        [\n            rs.col(\"poi\").n_unique().alias(\"n_pois\"),\n            rs.col(\"poi\").count().alias(\"n_checkins\"),\n            # turn the rest into a list\n            rs.col(\"poi\").alias(\"pois\"),\n            rs.col(\"date\").alias(\"dates\"),\n            rs.col(\"TZ\").alias(\"TZs\"),\n        ]\n    )\n).collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:12.384542Z","iopub.execute_input":"2024-05-12T17:12:12.384777Z","iopub.status.idle":"2024-05-12T17:12:21.993080Z","shell.execute_reply.started":"2024-05-12T17:12:12.384757Z","shell.execute_reply":"2024-05-12T17:12:21.992092Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_users.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:21.994369Z","iopub.execute_input":"2024-05-12T17:12:21.994756Z","iopub.status.idle":"2024-05-12T17:12:22.038877Z","shell.execute_reply.started":"2024-05-12T17:12:21.994720Z","shell.execute_reply":"2024-05-12T17:12:22.037873Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"shape: (9, 7)\n┌────────────┬──────────────┬───────────┬────────────┬──────────┬──────────┬──────────┐\n│ statistic  ┆ user         ┆ n_pois    ┆ n_checkins ┆ pois     ┆ dates    ┆ TZs      │\n│ ---        ┆ ---          ┆ ---       ┆ ---        ┆ ---      ┆ ---      ┆ ---      │\n│ str        ┆ f64          ┆ f64       ┆ f64        ┆ f64      ┆ f64      ┆ f64      │\n╞════════════╪══════════════╪═══════════╪════════════╪══════════╪══════════╪══════════╡\n│ count      ┆ 266909.0     ┆ 266909.0  ┆ 266909.0   ┆ 266909.0 ┆ 266909.0 ┆ 266909.0 │\n│ null_count ┆ 0.0          ┆ 0.0       ┆ 0.0        ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n│ mean       ┆ 133455.0     ┆ 56.477459 ┆ 124.62537  ┆ null     ┆ null     ┆ null     │\n│ std        ┆ 77050.135837 ┆ 45.968603 ┆ 140.692138 ┆ null     ┆ null     ┆ null     │\n│ min        ┆ 1.0          ┆ 1.0       ┆ 1.0        ┆ null     ┆ null     ┆ null     │\n│ 25%        ┆ 66728.0      ┆ 30.0      ┆ 61.0       ┆ null     ┆ null     ┆ null     │\n│ 50%        ┆ 133455.0     ┆ 49.0      ┆ 93.0       ┆ null     ┆ null     ┆ null     │\n│ 75%        ┆ 200182.0     ┆ 71.0      ┆ 148.0      ┆ null     ┆ null     ┆ null     │\n│ max        ┆ 266909.0     ┆ 1246.0    ┆ 5430.0     ┆ null     ┆ null     ┆ null     │\n└────────────┴──────────────┴───────────┴────────────┴──────────┴──────────┴──────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>133455.0</td><td>56.477459</td><td>124.62537</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>77050.135837</td><td>45.968603</td><td>140.692138</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>66728.0</td><td>30.0</td><td>61.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>133455.0</td><td>49.0</td><td>93.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>200182.0</td><td>71.0</td><td>148.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>1246.0</td><td>5430.0</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"data_culled = data_users.filter(\n    (rs.col(\"n_checkins\") > 20) & (rs.col(\"n_checkins\") < 50)\n).drop_nulls()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.040352Z","iopub.execute_input":"2024-05-12T17:12:22.040735Z","iopub.status.idle":"2024-05-12T17:12:22.137751Z","shell.execute_reply.started":"2024-05-12T17:12:22.040704Z","shell.execute_reply":"2024-05-12T17:12:22.136974Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Since the original dataset is huge, we delete it and call the python garbage collector to free up memory. We then proceed with the second pruning step (frequency-based pruning) as detailed in the paper.","metadata":{}},{"cell_type":"code","source":"del data\ndel data_users\n\nimport gc\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.142357Z","iopub.execute_input":"2024-05-12T17:12:22.142656Z","iopub.status.idle":"2024-05-12T17:12:22.509441Z","shell.execute_reply.started":"2024-05-12T17:12:22.142632Z","shell.execute_reply":"2024-05-12T17:12:22.508321Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"# extract unique elements from each lists in data_culled[\"pois\"]\nout = data_culled.with_columns(\n    [\n        rs.col(\"pois\").list.unique(),\n        rs.col(\"pois\").list.unique().list.len().alias(\"n_unique_pois\"),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.510796Z","iopub.execute_input":"2024-05-12T17:12:22.511463Z","iopub.status.idle":"2024-05-12T17:12:22.602419Z","shell.execute_reply.started":"2024-05-12T17:12:22.511426Z","shell.execute_reply":"2024-05-12T17:12:22.601642Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"out","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.603543Z","iopub.execute_input":"2024-05-12T17:12:22.603839Z","iopub.status.idle":"2024-05-12T17:12:22.612956Z","shell.execute_reply.started":"2024-05-12T17:12:22.603814Z","shell.execute_reply":"2024-05-12T17:12:22.611794Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"shape: (21_697, 7)\n┌────────┬────────┬────────────┬─────────────────┬────────────────┬────────────────┬───────────────┐\n│ user   ┆ n_pois ┆ n_checkins ┆ pois            ┆ dates          ┆ TZs            ┆ n_unique_pois │\n│ ---    ┆ ---    ┆ ---        ┆ ---             ┆ ---            ┆ ---            ┆ ---           │\n│ i64    ┆ u32    ┆ u32        ┆ list[str]       ┆ list[str]      ┆ list[i64]      ┆ u32           │\n╞════════╪════════╪════════════╪═════════════════╪════════════════╪════════════════╪═══════════════╡\n│ 132850 ┆ 31     ┆ 37         ┆ [\"4b5a9b91f964a ┆ [\"Sat Aug 11   ┆ [540, 540, …   ┆ 31            │\n│        ┆        ┆            ┆ 52087cd28e3\",   ┆ 03:55:59 +0000 ┆ 540]           ┆               │\n│        ┆        ┆            ┆ \"4e…            ┆ 2012…          ┆                ┆               │\n│ 213007 ┆ 11     ┆ 22         ┆ [\"50439ff6e4b07 ┆ [\"Sun Sep 09   ┆ [180, 180, …   ┆ 11            │\n│        ┆        ┆            ┆ 2dc96e9a554\",   ┆ 16:51:33 +0000 ┆ 240]           ┆               │\n│        ┆        ┆            ┆ \"4d…            ┆ 2012…          ┆                ┆               │\n│ 134696 ┆ 22     ┆ 23         ┆ [\"4b42f1d3f964a ┆ [\"Thu Jul 05   ┆ [-420, -300, … ┆ 22            │\n│        ┆        ┆            ┆ 52024db25e3\",   ┆ 22:34:13 +0000 ┆ -420]          ┆               │\n│        ┆        ┆            ┆ \"4c…            ┆ 2012…          ┆                ┆               │\n│ 142913 ┆ 35     ┆ 45         ┆ [\"4cccdbbb7c2ff ┆ [\"Wed Oct 24   ┆ [540, 540, …   ┆ 35            │\n│        ┆        ┆            ┆ 04d4d179c7e\",   ┆ 00:39:20 +0000 ┆ 540]           ┆               │\n│        ┆        ┆            ┆ \"4e…            ┆ 2012…          ┆                ┆               │\n│ 80691  ┆ 21     ┆ 21         ┆ [\"4c0e115bc700c ┆ [\"Sat May 19   ┆ [180, 180, …   ┆ 21            │\n│        ┆        ┆            ┆ 9b6ce42a3dd\",   ┆ 09:08:52 +0000 ┆ 180]           ┆               │\n│        ┆        ┆            ┆ \"4b…            ┆ 2012…          ┆                ┆               │\n│ …      ┆ …      ┆ …          ┆ …               ┆ …              ┆ …              ┆ …             │\n│ 189251 ┆ 28     ┆ 48         ┆ [\"4e39b273b61c0 ┆ [\"Sat Apr 28   ┆ [-420, -420, … ┆ 28            │\n│        ┆        ┆            ┆ 5fb6781423f\",   ┆ 04:42:33 +0000 ┆ 180]           ┆               │\n│        ┆        ┆            ┆ \"4a…            ┆ 2012…          ┆                ┆               │\n│ 176237 ┆ 35     ┆ 35         ┆ [\"4b0587d1f964a ┆ [\"Wed Mar 06   ┆ [-180, -180, … ┆ 35            │\n│        ┆        ┆            ┆ 520e2a222e3\",   ┆ 14:17:09 +0000 ┆ -180]          ┆               │\n│        ┆        ┆            ┆ \"4f…            ┆ 2013…          ┆                ┆               │\n│ 141132 ┆ 16     ┆ 36         ┆ [\"4fae6095e4b0d ┆ [\"Sun Aug 12   ┆ [180, 180, …   ┆ 16            │\n│        ┆        ┆            ┆ 39d5300b8d4\",   ┆ 16:15:20 +0000 ┆ 180]           ┆               │\n│        ┆        ┆            ┆ \"50…            ┆ 2012…          ┆                ┆               │\n│ 175365 ┆ 34     ┆ 43         ┆ [\"4bd72e080b779 ┆ [\"Sun May 27   ┆ [180, 180, …   ┆ 34            │\n│        ┆        ┆            ┆ c74bb9804a0\",   ┆ 16:12:47 +0000 ┆ 180]           ┆               │\n│        ┆        ┆            ┆ \"51…            ┆ 2012…          ┆                ┆               │\n│ 249958 ┆ 23     ┆ 30         ┆ [\"4bfeaac34e5d0 ┆ [\"Tue Jul 24   ┆ [240, 240, …   ┆ 23            │\n│        ┆        ┆            ┆ f477cf47c1f\",   ┆ 08:48:15 +0000 ┆ 240]           ┆               │\n│        ┆        ┆            ┆ \"4b…            ┆ 2012…          ┆                ┆               │\n└────────┴────────┴────────────┴─────────────────┴────────────────┴────────────────┴───────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (21_697, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th><th>n_unique_pois</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td><td>u32</td></tr></thead><tbody><tr><td>132850</td><td>31</td><td>37</td><td>[&quot;4b5a9b91f964a52087cd28e3&quot;, &quot;4edd7cb493ad464d2c35afa3&quot;, … &quot;4e54e79efa761d3de841cdbb&quot;]</td><td>[&quot;Sat Aug 11 03:55:59 +0000 2012&quot;, &quot;Sat Aug 11 04:37:03 +0000 2012&quot;, … &quot;Sun Sep 08 00:00:32 +0000 2013&quot;]</td><td>[540, 540, … 540]</td><td>31</td></tr><tr><td>213007</td><td>11</td><td>22</td><td>[&quot;50439ff6e4b072dc96e9a554&quot;, &quot;4d4daf82b887a1cd6dc7bea0&quot;, … &quot;4c2639c2f1272d7fd02286c5&quot;]</td><td>[&quot;Sun Sep 09 16:51:33 +0000 2012&quot;, &quot;Thu Sep 13 13:41:31 +0000 2012&quot;, … &quot;Thu Aug 08 21:34:50 +0000 2013&quot;]</td><td>[180, 180, … 240]</td><td>11</td></tr><tr><td>134696</td><td>22</td><td>23</td><td>[&quot;4b42f1d3f964a52024db25e3&quot;, &quot;4c8cd18ded3ab60c40d56a21&quot;, … &quot;4d7a8455e8b7a1cde1a2991f&quot;]</td><td>[&quot;Thu Jul 05 22:34:13 +0000 2012&quot;, &quot;Fri Jul 13 01:09:10 +0000 2012&quot;, … &quot;Wed Aug 14 07:17:39 +0000 2013&quot;]</td><td>[-420, -300, … -420]</td><td>22</td></tr><tr><td>142913</td><td>35</td><td>45</td><td>[&quot;4cccdbbb7c2ff04d4d179c7e&quot;, &quot;4e48e75745dd2955e5b74023&quot;, … &quot;4b6b937ef964a520d4102ce3&quot;]</td><td>[&quot;Wed Oct 24 00:39:20 +0000 2012&quot;, &quot;Mon Oct 29 05:38:02 +0000 2012&quot;, … &quot;Sun Sep 01 01:02:25 +0000 2013&quot;]</td><td>[540, 540, … 540]</td><td>35</td></tr><tr><td>80691</td><td>21</td><td>21</td><td>[&quot;4c0e115bc700c9b6ce42a3dd&quot;, &quot;4b8cf019f964a52079e132e3&quot;, … &quot;4cb32e59db32f04d265dd54d&quot;]</td><td>[&quot;Sat May 19 09:08:52 +0000 2012&quot;, &quot;Sat May 19 09:41:10 +0000 2012&quot;, … &quot;Fri Aug 02 18:27:24 +0000 2013&quot;]</td><td>[180, 180, … 180]</td><td>21</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>189251</td><td>28</td><td>48</td><td>[&quot;4e39b273b61c05fb6781423f&quot;, &quot;4a735cabf964a52043dc1fe3&quot;, … &quot;4e16047718a8addae8cf9047&quot;]</td><td>[&quot;Sat Apr 28 04:42:33 +0000 2012&quot;, &quot;Sat Apr 28 23:53:28 +0000 2012&quot;, … &quot;Wed Aug 21 18:55:11 +0000 2013&quot;]</td><td>[-420, -420, … 180]</td><td>28</td></tr><tr><td>176237</td><td>35</td><td>35</td><td>[&quot;4b0587d1f964a520e2a222e3&quot;, &quot;4fce3376e4b0409de3d1eadc&quot;, … &quot;4f88874e121d29fd93b03c92&quot;]</td><td>[&quot;Wed Mar 06 14:17:09 +0000 2013&quot;, &quot;Wed Mar 06 14:17:26 +0000 2013&quot;, … &quot;Thu Mar 07 16:57:52 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td><td>35</td></tr><tr><td>141132</td><td>16</td><td>36</td><td>[&quot;4fae6095e4b0d39d5300b8d4&quot;, &quot;5027843ae4b05db3aefaada4&quot;, … &quot;4bc8a4b815a7ef3b61897bda&quot;]</td><td>[&quot;Sun Aug 12 16:15:20 +0000 2012&quot;, &quot;Fri Aug 17 14:18:59 +0000 2012&quot;, … &quot;Tue Apr 30 11:03:23 +0000 2013&quot;]</td><td>[180, 180, … 180]</td><td>16</td></tr><tr><td>175365</td><td>34</td><td>43</td><td>[&quot;4bd72e080b779c74bb9804a0&quot;, &quot;514f6bb8e4b043eb8ed01da9&quot;, … &quot;5000a5e4e4b021927d359940&quot;]</td><td>[&quot;Sun May 27 16:12:47 +0000 2012&quot;, &quot;Fri Jul 06 19:03:04 +0000 2012&quot;, … &quot;Mon Sep 09 16:30:24 +0000 2013&quot;]</td><td>[180, 180, … 180]</td><td>34</td></tr><tr><td>249958</td><td>23</td><td>30</td><td>[&quot;4bfeaac34e5d0f477cf47c1f&quot;, &quot;4ba0da40f964a5204d8237e3&quot;, … &quot;5040accbe4b0379866e1ab6b&quot;]</td><td>[&quot;Tue Jul 24 08:48:15 +0000 2012&quot;, &quot;Thu Aug 09 16:47:57 +0000 2012&quot;, … &quot;Fri Sep 13 09:30:05 +0000 2013&quot;]</td><td>[240, 240, … 240]</td><td>23</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"code","source":"l = out[\"pois\"][0].to_list()\nlen(set(l))  # print number of unique POIs in first sequence","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.614052Z","iopub.execute_input":"2024-05-12T17:12:22.614367Z","iopub.status.idle":"2024-05-12T17:12:22.621169Z","shell.execute_reply.started":"2024-05-12T17:12:22.614335Z","shell.execute_reply":"2024-05-12T17:12:22.620302Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"31"},"metadata":{}}]},{"cell_type":"code","source":"l2 = data_culled[\"pois\"][0].to_list()\nlen(l2)  # print sequence length of first user","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.622287Z","iopub.execute_input":"2024-05-12T17:12:22.622564Z","iopub.status.idle":"2024-05-12T17:12:22.630088Z","shell.execute_reply.started":"2024-05-12T17:12:22.622541Z","shell.execute_reply":"2024-05-12T17:12:22.629290Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"37"},"metadata":{}}]},{"cell_type":"code","source":"len(set(l2))  # confirm that the two match","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.631284Z","iopub.execute_input":"2024-05-12T17:12:22.631631Z","iopub.status.idle":"2024-05-12T17:12:22.639494Z","shell.execute_reply.started":"2024-05-12T17:12:22.631608Z","shell.execute_reply":"2024-05-12T17:12:22.638585Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"31"},"metadata":{}}]},{"cell_type":"code","source":"# run a Polars query to obtain all the frequent POIs, the ones expected to survive the filtering\nunique_pois = out[\"pois\"]\nfrequent_pois = unique_pois.list.explode().value_counts().filter(rs.col(\"count\") >= 10)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.640570Z","iopub.execute_input":"2024-05-12T17:12:22.641194Z","iopub.status.idle":"2024-05-12T17:12:22.773755Z","shell.execute_reply.started":"2024-05-12T17:12:22.641158Z","shell.execute_reply":"2024-05-12T17:12:22.772767Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"frequent_pois","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.775281Z","iopub.execute_input":"2024-05-12T17:12:22.776125Z","iopub.status.idle":"2024-05-12T17:12:22.784050Z","shell.execute_reply.started":"2024-05-12T17:12:22.776087Z","shell.execute_reply":"2024-05-12T17:12:22.782959Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"shape: (4_455, 2)\n┌──────────────────────────┬───────┐\n│ pois                     ┆ count │\n│ ---                      ┆ ---   │\n│ str                      ┆ u32   │\n╞══════════════════════════╪═══════╡\n│ 4ba12c74f964a520eb9e37e3 ┆ 15    │\n│ 4c0f537ed64c0f474f9b295d ┆ 20    │\n│ 4bbb5abc935e95218a102990 ┆ 15    │\n│ 4af53ef1f964a520a8f821e3 ┆ 26    │\n│ 506964fae4b03ce13bbc8705 ┆ 62    │\n│ …                        ┆ …     │\n│ 4acbc3fbf964a52024c620e3 ┆ 11    │\n│ 4cade9aa8b57a1cdbae19b75 ┆ 15    │\n│ 4e7d9d98f5b9220118697893 ┆ 12    │\n│ 4ce9028af3bda143086bbde4 ┆ 11    │\n│ 4bec386f61aca593abfa8500 ┆ 39    │\n└──────────────────────────┴───────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (4_455, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;4ba12c74f964a5…</td><td>15</td></tr><tr><td>&quot;4c0f537ed64c0f…</td><td>20</td></tr><tr><td>&quot;4bbb5abc935e95…</td><td>15</td></tr><tr><td>&quot;4af53ef1f964a5…</td><td>26</td></tr><tr><td>&quot;506964fae4b03c…</td><td>62</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4acbc3fbf964a5…</td><td>11</td></tr><tr><td>&quot;4cade9aa8b57a1…</td><td>15</td></tr><tr><td>&quot;4e7d9d98f5b922…</td><td>12</td></tr><tr><td>&quot;4ce9028af3bda1…</td><td>11</td></tr><tr><td>&quot;4bec386f61aca5…</td><td>39</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"code","source":"frequent_pois = frequent_pois[\"pois\"]\nfrequent_pois = set(frequent_pois.to_list())","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.785377Z","iopub.execute_input":"2024-05-12T17:12:22.785752Z","iopub.status.idle":"2024-05-12T17:12:22.792338Z","shell.execute_reply.started":"2024-05-12T17:12:22.785720Z","shell.execute_reply":"2024-05-12T17:12:22.791439Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"data_culled","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.793598Z","iopub.execute_input":"2024-05-12T17:12:22.794221Z","iopub.status.idle":"2024-05-12T17:12:22.803753Z","shell.execute_reply.started":"2024-05-12T17:12:22.794188Z","shell.execute_reply":"2024-05-12T17:12:22.802740Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"shape: (21_697, 6)\n┌────────┬────────┬────────────┬─────────────────────────┬────────────────┬────────────────────────┐\n│ user   ┆ n_pois ┆ n_checkins ┆ pois                    ┆ dates          ┆ TZs                    │\n│ ---    ┆ ---    ┆ ---        ┆ ---                     ┆ ---            ┆ ---                    │\n│ i64    ┆ u32    ┆ u32        ┆ list[str]               ┆ list[str]      ┆ list[i64]              │\n╞════════╪════════╪════════════╪═════════════════════════╪════════════════╪════════════════════════╡\n│ 132850 ┆ 31     ┆ 37         ┆ [\"4b396b34f964a5204f5c2 ┆ [\"Sat Aug 11   ┆ [540, 540, … 540]      │\n│        ┆        ┆            ┆ 5e3\", \"4b…              ┆ 03:55:59 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ 213007 ┆ 11     ┆ 22         ┆ [\"4b69377ff964a520f59b2 ┆ [\"Sun Sep 09   ┆ [180, 180, … 240]      │\n│        ┆        ┆            ┆ be3\", \"4c…              ┆ 16:51:33 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ 134696 ┆ 22     ┆ 23         ┆ [\"4c2cdcd2ae6820a102041 ┆ [\"Thu Jul 05   ┆ [-420, -300, … -420]   │\n│        ┆        ┆            ┆ a43\", \"4b…              ┆ 22:34:13 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ 142913 ┆ 35     ┆ 45         ┆ [\"4b95a8b4f964a52036ae3 ┆ [\"Wed Oct 24   ┆ [540, 540, … 540]      │\n│        ┆        ┆            ┆ 4e3\", \"4b…              ┆ 00:39:20 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ 80691  ┆ 21     ┆ 21         ┆ [\"4d122dae7a8ba1433410c ┆ [\"Sat May 19   ┆ [180, 180, … 180]      │\n│        ┆        ┆            ┆ 769\", \"4c…              ┆ 09:08:52 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ …      ┆ …      ┆ …          ┆ …                       ┆ …              ┆ …                      │\n│ 189251 ┆ 28     ┆ 48         ┆ [\"4bfb3261d0382d7f8d6ec ┆ [\"Sat Apr 28   ┆ [-420, -420, … 180]    │\n│        ┆        ┆            ┆ 90a\", \"4a…              ┆ 04:42:33 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ 176237 ┆ 35     ┆ 35         ┆ [\"4b605cadf964a520c4e12 ┆ [\"Wed Mar 06   ┆ [-180, -180, … -180]   │\n│        ┆        ┆            ┆ 9e3\", \"50…              ┆ 14:17:09 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2013…          ┆                        │\n│ 141132 ┆ 16     ┆ 36         ┆ [\"5027843ae4b05db3aefaa ┆ [\"Sun Aug 12   ┆ [180, 180, … 180]      │\n│        ┆        ┆            ┆ da4\", \"4f…              ┆ 16:15:20 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ 175365 ┆ 34     ┆ 43         ┆ [\"4bb75bcd1344b713959d9 ┆ [\"Sun May 27   ┆ [180, 180, … 180]      │\n│        ┆        ┆            ┆ e04\", \"4c…              ┆ 16:12:47 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n│ 249958 ┆ 23     ┆ 30         ┆ [\"4beacea9415e20a12774e ┆ [\"Tue Jul 24   ┆ [240, 240, … 240]      │\n│        ┆        ┆            ┆ 5bb\", \"4b…              ┆ 08:48:15 +0000 ┆                        │\n│        ┆        ┆            ┆                         ┆ 2012…          ┆                        │\n└────────┴────────┴────────────┴─────────────────────────┴────────────────┴────────────────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (21_697, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td></tr></thead><tbody><tr><td>132850</td><td>31</td><td>37</td><td>[&quot;4b396b34f964a5204f5c25e3&quot;, &quot;4b4162b1f964a52016c625e3&quot;, … &quot;4b5ab7bff964a520eed128e3&quot;]</td><td>[&quot;Sat Aug 11 03:55:59 +0000 2012&quot;, &quot;Sat Aug 11 04:37:03 +0000 2012&quot;, … &quot;Sun Sep 08 00:00:32 +0000 2013&quot;]</td><td>[540, 540, … 540]</td></tr><tr><td>213007</td><td>11</td><td>22</td><td>[&quot;4b69377ff964a520f59b2be3&quot;, &quot;4c2639c2f1272d7fd02286c5&quot;, … &quot;4d4daf82b887a1cd6dc7bea0&quot;]</td><td>[&quot;Sun Sep 09 16:51:33 +0000 2012&quot;, &quot;Thu Sep 13 13:41:31 +0000 2012&quot;, … &quot;Thu Aug 08 21:34:50 +0000 2013&quot;]</td><td>[180, 180, … 240]</td></tr><tr><td>134696</td><td>22</td><td>23</td><td>[&quot;4c2cdcd2ae6820a102041a43&quot;, &quot;4b42f1d3f964a52024db25e3&quot;, … &quot;50065de8e4b00dc76c134f45&quot;]</td><td>[&quot;Thu Jul 05 22:34:13 +0000 2012&quot;, &quot;Fri Jul 13 01:09:10 +0000 2012&quot;, … &quot;Wed Aug 14 07:17:39 +0000 2013&quot;]</td><td>[-420, -300, … -420]</td></tr><tr><td>142913</td><td>35</td><td>45</td><td>[&quot;4b95a8b4f964a52036ae34e3&quot;, &quot;4b49ac6bf964a5205c7226e3&quot;, … &quot;4cbbd0574352a1cdf9039bf5&quot;]</td><td>[&quot;Wed Oct 24 00:39:20 +0000 2012&quot;, &quot;Mon Oct 29 05:38:02 +0000 2012&quot;, … &quot;Sun Sep 01 01:02:25 +0000 2013&quot;]</td><td>[540, 540, … 540]</td></tr><tr><td>80691</td><td>21</td><td>21</td><td>[&quot;4d122dae7a8ba1433410c769&quot;, &quot;4cbb569ebac937046d7af17c&quot;, … &quot;4d41bcd0915a37046104237f&quot;]</td><td>[&quot;Sat May 19 09:08:52 +0000 2012&quot;, &quot;Sat May 19 09:41:10 +0000 2012&quot;, … &quot;Fri Aug 02 18:27:24 +0000 2013&quot;]</td><td>[180, 180, … 180]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>189251</td><td>28</td><td>48</td><td>[&quot;4bfb3261d0382d7f8d6ec90a&quot;, &quot;4a735cabf964a52043dc1fe3&quot;, … &quot;5203e880498e9649d09ff652&quot;]</td><td>[&quot;Sat Apr 28 04:42:33 +0000 2012&quot;, &quot;Sat Apr 28 23:53:28 +0000 2012&quot;, … &quot;Wed Aug 21 18:55:11 +0000 2013&quot;]</td><td>[-420, -420, … 180]</td></tr><tr><td>176237</td><td>35</td><td>35</td><td>[&quot;4b605cadf964a520c4e129e3&quot;, &quot;50b93759e4b0073faaf993de&quot;, … &quot;4e21fcb77d8b71715bb13cde&quot;]</td><td>[&quot;Wed Mar 06 14:17:09 +0000 2013&quot;, &quot;Wed Mar 06 14:17:26 +0000 2013&quot;, … &quot;Thu Mar 07 16:57:52 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td></tr><tr><td>141132</td><td>16</td><td>36</td><td>[&quot;5027843ae4b05db3aefaada4&quot;, &quot;4fae6095e4b0d39d5300b8d4&quot;, … &quot;4e801da54690084c2eaf2291&quot;]</td><td>[&quot;Sun Aug 12 16:15:20 +0000 2012&quot;, &quot;Fri Aug 17 14:18:59 +0000 2012&quot;, … &quot;Tue Apr 30 11:03:23 +0000 2013&quot;]</td><td>[180, 180, … 180]</td></tr><tr><td>175365</td><td>34</td><td>43</td><td>[&quot;4bb75bcd1344b713959d9e04&quot;, &quot;4ca63308d971b1f763cefde0&quot;, … &quot;4c912ea9ae96a093194aa146&quot;]</td><td>[&quot;Sun May 27 16:12:47 +0000 2012&quot;, &quot;Fri Jul 06 19:03:04 +0000 2012&quot;, … &quot;Mon Sep 09 16:30:24 +0000 2013&quot;]</td><td>[180, 180, … 180]</td></tr><tr><td>249958</td><td>23</td><td>30</td><td>[&quot;4beacea9415e20a12774e5bb&quot;, &quot;4bc2f28174a9a5937ddbd3f6&quot;, … &quot;4c70fdc0b5a5236a4ce25152&quot;]</td><td>[&quot;Tue Jul 24 08:48:15 +0000 2012&quot;, &quot;Thu Aug 09 16:47:57 +0000 2012&quot;, … &quot;Fri Sep 13 09:30:05 +0000 2013&quot;]</td><td>[240, 240, … 240]</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"code","source":"data_culled = data_culled.with_columns(\n    [\n        rs.col(\"pois\")\n        .list.eval(\n            rs.element().is_in(frequent_pois),\n        )\n        .alias(\"is_frequent\")\n    ]\n)  # prep mask","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.804834Z","iopub.execute_input":"2024-05-12T17:12:22.805093Z","iopub.status.idle":"2024-05-12T17:12:22.846817Z","shell.execute_reply.started":"2024-05-12T17:12:22.805071Z","shell.execute_reply":"2024-05-12T17:12:22.846135Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"final_data = (\n    data_culled.lazy()\n    .with_row_index()\n    .explode(\n        [\n            \"pois\",\n            \"dates\",\n            \"TZs\",\n            \"is_frequent\",\n        ]\n    )\n    .group_by(\"user\")\n    .agg(\n        [\n            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).alias(\"pois\"),\n            rs.col(\"dates\").filter(rs.col(\"is_frequent\")).alias(\"dates\"),\n            rs.col(\"TZs\").filter(rs.col(\"is_frequent\")).alias(\"TZs\"),\n            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).n_unique().alias(\"n_pois\"),\n            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).count().alias(\"n_checkins\"),\n        ]\n    )\n    .filter(rs.col(\"n_checkins\") > 0)\n    .filter(rs.col(\"n_pois\") > 0)\n    .collect()\n)  # filter out infrequent pois and users with no pois","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.847680Z","iopub.execute_input":"2024-05-12T17:12:22.847923Z","iopub.status.idle":"2024-05-12T17:12:22.934379Z","shell.execute_reply.started":"2024-05-12T17:12:22.847901Z","shell.execute_reply":"2024-05-12T17:12:22.933537Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"final_data.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:12:22.935511Z","iopub.execute_input":"2024-05-12T17:12:22.935810Z","iopub.status.idle":"2024-05-12T17:12:22.946330Z","shell.execute_reply.started":"2024-05-12T17:12:22.935784Z","shell.execute_reply":"2024-05-12T17:12:22.945303Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"shape: (9, 7)\n┌────────────┬───────────────┬─────────┬─────────┬─────────┬──────────┬────────────┐\n│ statistic  ┆ user          ┆ pois    ┆ dates   ┆ TZs     ┆ n_pois   ┆ n_checkins │\n│ ---        ┆ ---           ┆ ---     ┆ ---     ┆ ---     ┆ ---      ┆ ---        │\n│ str        ┆ f64           ┆ f64     ┆ f64     ┆ f64     ┆ f64      ┆ f64        │\n╞════════════╪═══════════════╪═════════╪═════════╪═════════╪══════════╪════════════╡\n│ count      ┆ 19862.0       ┆ 19862.0 ┆ 19862.0 ┆ 19862.0 ┆ 19862.0  ┆ 19862.0    │\n│ null_count ┆ 0.0           ┆ 0.0     ┆ 0.0     ┆ 0.0     ┆ 0.0      ┆ 0.0        │\n│ mean       ┆ 156852.822274 ┆ null    ┆ null    ┆ null    ┆ 6.123452 ┆ 8.831437   │\n│ std        ┆ 76314.892884  ┆ null    ┆ null    ┆ null    ┆ 4.609024 ┆ 6.877662   │\n│ min        ┆ 49.0          ┆ null    ┆ null    ┆ null    ┆ 1.0      ┆ 1.0        │\n│ 25%        ┆ 95613.0       ┆ null    ┆ null    ┆ null    ┆ 3.0      ┆ 4.0        │\n│ 50%        ┆ 167846.0      ┆ null    ┆ null    ┆ null    ┆ 5.0      ┆ 7.0        │\n│ 75%        ┆ 224576.0      ┆ null    ┆ null    ┆ null    ┆ 8.0      ┆ 12.0       │\n│ max        ┆ 266909.0      ┆ null    ┆ null    ┆ null    ┆ 32.0     ┆ 46.0       │\n└────────────┴───────────────┴─────────┴─────────┴─────────┴──────────┴────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>pois</th><th>dates</th><th>TZs</th><th>n_pois</th><th>n_checkins</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>156852.822274</td><td>null</td><td>null</td><td>null</td><td>6.123452</td><td>8.831437</td></tr><tr><td>&quot;std&quot;</td><td>76314.892884</td><td>null</td><td>null</td><td>null</td><td>4.609024</td><td>6.877662</td></tr><tr><td>&quot;min&quot;</td><td>49.0</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>95613.0</td><td>null</td><td>null</td><td>null</td><td>3.0</td><td>4.0</td></tr><tr><td>&quot;50%&quot;</td><td>167846.0</td><td>null</td><td>null</td><td>null</td><td>5.0</td><td>7.0</td></tr><tr><td>&quot;75%&quot;</td><td>224576.0</td><td>null</td><td>null</td><td>null</td><td>8.0</td><td>12.0</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>null</td><td>null</td><td>null</td><td>32.0</td><td>46.0</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"At this stage, culling is done, we can appreciate that `polars`'s SQL/functional-style API is different from Pandas, but it is very powerful and efficient.","metadata":{}},{"cell_type":"markdown","source":"The next step is geohashing the POIs, that is, we want to convert the latitude-longitude positions of the POIs into a grid-based geohash representation, which will form the basis for our network's embeddings.","metadata":{}},{"cell_type":"code","source":"import geohash2 as gh\n\npois = rs.read_csv(\n    \"/kaggle/input/dataset-tist2015/dataset_TIST2015_POIs.txt\",\n    has_header=False,\n    low_memory=True,\n    separator=\"\\t\",\n)\npois.columns = [\"poi\", \"lat\", \"long\", \"category\", \"country\"]\npois = pois.drop(\"category\").drop(\"country\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:00.174715Z","iopub.execute_input":"2024-05-12T17:18:00.175077Z","iopub.status.idle":"2024-05-12T17:18:01.319600Z","shell.execute_reply.started":"2024-05-12T17:18:00.175050Z","shell.execute_reply":"2024-05-12T17:18:01.318631Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"pois = (\n    pois.lazy()\n    .filter(rs.col(\"poi\").is_in(frequent_pois))\n    .select(\n        [\n            rs.col(\"poi\"),\n            rs.struct(\n                [\n                    rs.col(\"lat\").cast(rs.Float32),\n                    rs.col(\"long\").cast(rs.Float32),\n                ]\n            )\n            .alias(\"location\")\n            .map_elements(\n                lambda s: gh.encode(s[\"lat\"], s[\"long\"], precision=6),\n                return_dtype=rs.String,\n            )\n            .alias(\"geohash\"),\n        ]\n    )\n    .collect()\n)\npoi_geo_dict = dict(zip(pois[\"poi\"], pois[\"geohash\"]))","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:01.321836Z","iopub.execute_input":"2024-05-12T17:18:01.322687Z","iopub.status.idle":"2024-05-12T17:18:01.597070Z","shell.execute_reply.started":"2024-05-12T17:18:01.322647Z","shell.execute_reply":"2024-05-12T17:18:01.595862Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# for each row in final_data, add the geohash of the pois by hitting the poi_geo_dict\n\nfinal_data = final_data.with_columns(\n    [\n        rs.col(\"pois\")\n        .map_elements(\n            lambda s: [poi_geo_dict[s] for s in s],\n            return_dtype=rs.List(rs.String),\n        )\n        .alias(\"geohashes\")\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:01.598605Z","iopub.execute_input":"2024-05-12T17:18:01.598983Z","iopub.status.idle":"2024-05-12T17:18:02.170923Z","shell.execute_reply.started":"2024-05-12T17:18:01.598957Z","shell.execute_reply":"2024-05-12T17:18:02.169900Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"final_data[\"dates\"][79].to_list()  # check out a temporal sequence","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:02.173973Z","iopub.execute_input":"2024-05-12T17:18:02.174390Z","iopub.status.idle":"2024-05-12T17:18:02.182127Z","shell.execute_reply.started":"2024-05-12T17:18:02.174356Z","shell.execute_reply":"2024-05-12T17:18:02.180999Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"['Mon Mar 04 16:46:12 +0000 2013',\n 'Fri Mar 08 15:44:35 +0000 2013',\n 'Tue Mar 19 16:53:01 +0000 2013',\n 'Fri Mar 22 10:10:18 +0000 2013',\n 'Fri Apr 19 15:41:56 +0000 2013',\n 'Mon Apr 22 13:11:07 +0000 2013',\n 'Mon May 06 11:40:38 +0000 2013',\n 'Sat Jun 01 12:55:04 +0000 2013',\n 'Wed Jul 10 10:04:08 +0000 2013',\n 'Sun Jul 14 09:16:57 +0000 2013',\n 'Sun Aug 11 19:00:35 +0000 2013',\n 'Tue Aug 13 12:46:54 +0000 2013',\n 'Tue Aug 13 13:13:21 +0000 2013',\n 'Wed Aug 14 09:55:38 +0000 2013']"},"metadata":{}}]},{"cell_type":"code","source":"final_data[\"TZs\"][79].to_list()  # ... and the corresponding timezones","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:02.184032Z","iopub.execute_input":"2024-05-12T17:18:02.184619Z","iopub.status.idle":"2024-05-12T17:18:02.191487Z","shell.execute_reply.started":"2024-05-12T17:18:02.184588Z","shell.execute_reply":"2024-05-12T17:18:02.190500Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[120, 120, 120, 120, 180, 180, 180, 180, 180, 180, 180, 180, 180, 180]"},"metadata":{}}]},{"cell_type":"markdown","source":"The work *might* seem over, however, we still have timezones to account for, we want to normalize everything according to GMT, so we convert the timestamps accordingly.","metadata":{}},{"cell_type":"code","source":"import datetime\n\n\ndef UTC_to_local(utc, tz):\n\n    date = datetime.datetime.strptime(utc, \"%a %b %d %H:%M:%S %z %Y\")\n    date = date.replace(tzinfo=datetime.timezone.utc)\n\n    # shift by tz offset\n    date = date.astimezone(datetime.timezone(datetime.timedelta(minutes=tz)))\n\n    date_s = datetime.datetime.strftime(date, \"%Y-%m-%d %H:%M:%S\")\n    return date_s\n\n\ndef to_UNIX_time(date):\n    return datetime.datetime.strptime(\n        date, \"%Y-%m-%d %H:%M:%S\"\n    ).timestamp()  # we use UNIX time as a key for sorting the POIs in our polars query","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:02.192847Z","iopub.execute_input":"2024-05-12T17:18:02.193152Z","iopub.status.idle":"2024-05-12T17:18:02.204933Z","shell.execute_reply.started":"2024-05-12T17:18:02.193129Z","shell.execute_reply":"2024-05-12T17:18:02.204002Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"UTC_to_local(\"Mon May 21 15:53:01 +0000 2012\", -420)  # example of usage","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:02.206440Z","iopub.execute_input":"2024-05-12T17:18:02.206754Z","iopub.status.idle":"2024-05-12T17:18:02.222110Z","shell.execute_reply.started":"2024-05-12T17:18:02.206727Z","shell.execute_reply":"2024-05-12T17:18:02.221175Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'2012-05-21 08:53:01'"},"metadata":{}}]},{"cell_type":"code","source":"final_data = final_data.with_columns(\n    [\n        rs.struct([rs.col(\"dates\"), rs.col(\"TZs\")])\n        .alias(\"times\")\n        .map_elements(\n            lambda struct: [\n                UTC_to_local(date, tz)\n                for date, tz in zip(struct[\"dates\"], struct[\"TZs\"])\n            ],\n            return_dtype=rs.List(rs.String),\n        )\n    ]\n)  # This performs timezone conversion","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:02.223253Z","iopub.execute_input":"2024-05-12T17:18:02.223852Z","iopub.status.idle":"2024-05-12T17:18:08.520959Z","shell.execute_reply.started":"2024-05-12T17:18:02.223821Z","shell.execute_reply":"2024-05-12T17:18:08.519893Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"final_sorted = final_data.select(  # sort the times\n    [\n        rs.col(\"user\"),\n        rs.struct(\n            [\n                rs.col(\"pois\"),\n                rs.col(\"times\"),\n            ]\n        ).map_elements(\n            lambda struct: [\n                poi\n                for poi, _ in sorted(\n                    zip(  # here we sort the POIs struct by UNIX timestamps of the GMT times\n                        struct[\"pois\"], [to_UNIX_time(date) for date in struct[\"times\"]]\n                    ),\n                    key=lambda s: s[1],\n                )\n            ],\n            return_dtype=rs.List(rs.String),\n        ),\n        rs.struct(\n            [\n                rs.col(\"geohashes\"),\n                rs.col(\"times\"),\n            ]\n        ).map_elements(\n            lambda struct: [\n                geo\n                for geo, _ in sorted(\n                    zip(\n                        struct[\"geohashes\"],  # same thing goes on for geohashes\n                        [to_UNIX_time(date) for date in struct[\"times\"]],\n                    ),\n                    key=lambda s: s[1],\n                )\n            ],\n            return_dtype=rs.List(rs.String),\n        ),\n        rs.col(\"times\")\n        .map_elements(\n            lambda dates: sorted(dates, key=to_UNIX_time),\n            return_dtype=rs.List(rs.String),\n        )\n        .alias(\"times_sorted\"),\n        rs.col(\"n_checkins\"),\n    ]\n)\n\n# P.S, admittedly, it would have been more efficient to encode the geohashes *after* sorting the POIs,\n# so that we could save on the sorting of the geohashes. Tough luck, you can't win 'em all.","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:08.522207Z","iopub.execute_input":"2024-05-12T17:18:08.523541Z","iopub.status.idle":"2024-05-12T17:18:33.031224Z","shell.execute_reply.started":"2024-05-12T17:18:08.523508Z","shell.execute_reply":"2024-05-12T17:18:33.030091Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"final_sorted","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:33.035660Z","iopub.execute_input":"2024-05-12T17:18:33.036029Z","iopub.status.idle":"2024-05-12T17:18:33.045341Z","shell.execute_reply.started":"2024-05-12T17:18:33.035999Z","shell.execute_reply":"2024-05-12T17:18:33.044302Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"shape: (19_862, 5)\n┌────────┬─────────────────────────┬─────────────────────────┬────────────────────────┬────────────┐\n│ user   ┆ pois                    ┆ geohashes               ┆ times_sorted           ┆ n_checkins │\n│ ---    ┆ ---                     ┆ ---                     ┆ ---                    ┆ ---        │\n│ i64    ┆ list[str]               ┆ list[str]               ┆ list[str]              ┆ u32        │\n╞════════╪═════════════════════════╪═════════════════════════╪════════════════════════╪════════════╡\n│ 170995 ┆ [\"4fc7c357e4b026df79ac7 ┆ [\"ucftph\", \"ucfv2c\", …  ┆ [\"2012-06-01           ┆ 8          │\n│        ┆ b72\", \"4b…              ┆ \"ucfv2c\"]               ┆ 12:52:49\", \"2012-06…   ┆            │\n│ 216178 ┆ [\"4bc09456461576b090507 ┆ [\"swtccd\", \"swtcfd\", …  ┆ [\"2012-04-14           ┆ 12         │\n│        ┆ a32\", \"4c…              ┆ \"sy89km\"]               ┆ 15:19:44\", \"2012-04…   ┆            │\n│ 253183 ┆ [\"4af53ef1f964a520a8f82 ┆ [\"u09tvn\"]              ┆ [\"2012-05-07           ┆ 1          │\n│        ┆ 1e3\"]                   ┆                         ┆ 16:37:14\"]             ┆            │\n│ 178066 ┆ [\"4c6bdfaa69b4ef3ba18d4 ┆ [\"7nyywt\", \"7nyyyy\", …  ┆ [\"2012-10-17           ┆ 6          │\n│        ┆ 74e\", \"4d…              ┆ \"7nyyyy\"]               ┆ 07:35:16\", \"2012-12…   ┆            │\n│ 199029 ┆ [\"4a5920b8f964a520bfb81 ┆ [\"9vg4vz\", \"9vg4vz\", …  ┆ [\"2012-04-07           ┆ 21         │\n│        ┆ fe3\", \"4a…              ┆ \"dp3wq6\"]               ┆ 16:33:46\", \"2012-04…   ┆            │\n│ …      ┆ …                       ┆ …                       ┆ …                      ┆ …          │\n│ 246013 ┆ [\"4b57d346f964a520e2422 ┆ [\"9v4p2j\", \"9v4p2j\", …  ┆ [\"2012-11-05           ┆ 5          │\n│        ┆ 8e3\", \"4b…              ┆ \"9x225b\"]               ┆ 19:25:48\", \"2013-01…   ┆            │\n│ 221358 ┆ [\"4b617741f964a52082142 ┆ [\"qquj02\", \"qquj03\", …  ┆ [\"2013-04-12           ┆ 6          │\n│        ┆ ae3\", \"4b…              ┆ \"qqgvnn\"]               ┆ 15:35:15\", \"2013-04…   ┆            │\n│ 201577 ┆ [\"4b469e61f964a520aa252 ┆ [\"9zmk3r\", \"9mudgk\", …  ┆ [\"2012-05-18           ┆ 6          │\n│        ┆ 6e3\", \"4b…              ┆ \"9zmk3r\"]               ┆ 19:29:08\", \"2012-08…   ┆            │\n│ 198096 ┆ [\"4b8669acf964a5201a893 ┆ [\"sxk9eg\", \"sxk9s2\", …  ┆ [\"2013-01-16           ┆ 15         │\n│        ┆ 1e3\", \"4d…              ┆ \"sxk9j3\"]               ┆ 17:09:34\", \"2013-01…   ┆            │\n│ 111871 ┆ [\"4a6e5d0df964a52093d41 ┆ [\"9q5fh5\", \"9tbq5q\"]    ┆ [\"2013-01-21           ┆ 2          │\n│        ┆ fe3\", \"44…              ┆                         ┆ 14:02:55\", \"2013-08…   ┆            │\n└────────┴─────────────────────────┴─────────────────────────┴────────────────────────┴────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (19_862, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>pois</th><th>geohashes</th><th>times_sorted</th><th>n_checkins</th></tr><tr><td>i64</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>u32</td></tr></thead><tbody><tr><td>170995</td><td>[&quot;4fc7c357e4b026df79ac7b72&quot;, &quot;4bc4f2f80191c9b6c7e0eab1&quot;, … &quot;4bc4f2f80191c9b6c7e0eab1&quot;]</td><td>[&quot;ucftph&quot;, &quot;ucfv2c&quot;, … &quot;ucfv2c&quot;]</td><td>[&quot;2012-06-01 12:52:49&quot;, &quot;2012-06-07 14:47:23&quot;, … &quot;2013-04-15 14:11:22&quot;]</td><td>8</td></tr><tr><td>216178</td><td>[&quot;4bc09456461576b090507a32&quot;, &quot;4c45f30dcd5ca5930962ff86&quot;, … &quot;4c03550b187ec9283a97b57b&quot;]</td><td>[&quot;swtccd&quot;, &quot;swtcfd&quot;, … &quot;sy89km&quot;]</td><td>[&quot;2012-04-14 15:19:44&quot;, &quot;2012-04-14 20:04:43&quot;, … &quot;2012-07-06 14:10:03&quot;]</td><td>12</td></tr><tr><td>253183</td><td>[&quot;4af53ef1f964a520a8f821e3&quot;]</td><td>[&quot;u09tvn&quot;]</td><td>[&quot;2012-05-07 16:37:14&quot;]</td><td>1</td></tr><tr><td>178066</td><td>[&quot;4c6bdfaa69b4ef3ba18d474e&quot;, &quot;4db059288154905aadac64ba&quot;, … &quot;4b490ccef964a520aa6326e3&quot;]</td><td>[&quot;7nyywt&quot;, &quot;7nyyyy&quot;, … &quot;7nyyyy&quot;]</td><td>[&quot;2012-10-17 07:35:16&quot;, &quot;2012-12-18 12:48:52&quot;, … &quot;2013-08-26 13:43:01&quot;]</td><td>6</td></tr><tr><td>199029</td><td>[&quot;4a5920b8f964a520bfb81fe3&quot;, &quot;4a5920b8f964a520bfb81fe3&quot;, … &quot;45840abff964a520913f1fe3&quot;]</td><td>[&quot;9vg4vz&quot;, &quot;9vg4vz&quot;, … &quot;dp3wq6&quot;]</td><td>[&quot;2012-04-07 16:33:46&quot;, &quot;2012-04-19 16:11:55&quot;, … &quot;2013-06-22 14:49:30&quot;]</td><td>21</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>246013</td><td>[&quot;4b57d346f964a520e24228e3&quot;, &quot;4b57d346f964a520e24228e3&quot;, … &quot;4a5d7fa0f964a520a9bd1fe3&quot;]</td><td>[&quot;9v4p2j&quot;, &quot;9v4p2j&quot;, … &quot;9x225b&quot;]</td><td>[&quot;2012-11-05 19:25:48&quot;, &quot;2013-01-16 19:33:32&quot;, … &quot;2013-08-04 16:33:55&quot;]</td><td>5</td></tr><tr><td>221358</td><td>[&quot;4b617741f964a52082142ae3&quot;, &quot;4b6ea53df964a52065c52ce3&quot;, … &quot;4bc2b4e1461576b0e5c77d32&quot;]</td><td>[&quot;qquj02&quot;, &quot;qquj03&quot;, … &quot;qqgvnn&quot;]</td><td>[&quot;2013-04-12 15:35:15&quot;, &quot;2013-04-25 16:08:46&quot;, … &quot;2013-06-06 15:39:17&quot;]</td><td>6</td></tr><tr><td>201577</td><td>[&quot;4b469e61f964a520aa2526e3&quot;, &quot;4b9bae23f964a5208d1936e3&quot;, … &quot;4b469e61f964a520aa2526e3&quot;]</td><td>[&quot;9zmk3r&quot;, &quot;9mudgk&quot;, … &quot;9zmk3r&quot;]</td><td>[&quot;2012-05-18 19:29:08&quot;, &quot;2012-08-14 16:11:37&quot;, … &quot;2012-11-23 02:50:52&quot;]</td><td>6</td></tr><tr><td>198096</td><td>[&quot;4b8669acf964a5201a8931e3&quot;, &quot;4d57ae2e92326ea8bfd65ec0&quot;, … &quot;4b718d38f964a520ee4c2de3&quot;]</td><td>[&quot;sxk9eg&quot;, &quot;sxk9s2&quot;, … &quot;sxk9j3&quot;]</td><td>[&quot;2013-01-16 17:09:34&quot;, &quot;2013-01-16 18:01:47&quot;, … &quot;2013-04-21 19:44:38&quot;]</td><td>15</td></tr><tr><td>111871</td><td>[&quot;4a6e5d0df964a52093d41fe3&quot;, &quot;449e9fb9f964a520c0341fe3&quot;]</td><td>[&quot;9q5fh5&quot;, &quot;9tbq5q&quot;]</td><td>[&quot;2013-01-21 14:02:55&quot;, &quot;2013-08-17 15:55:46&quot;]</td><td>2</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"we now need to obtain a dataframe containing: each POI, it's geohash, and a set of all the check-ins it appears in\nthis is just one `polars` query away!","metadata":{}},{"cell_type":"code","source":"pois_checkins = final_sorted.explode([\"pois\", \"geohashes\"]).drop(\"n_checkins\")\n\npois_checkins = (\n    pois_checkins.with_columns(\n        [\n            rs.col(\"geohashes\").map_elements(lambda s: s[:4], rs.String).alias(\"g4\"),\n        ]\n    )\n    .drop(\"geohashes\")\n    .group_by([\"pois\", \"g4\"])\n    .agg([rs.col(\"times_sorted\").flatten().alias(\"checkin_times\")])\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:33.046986Z","iopub.execute_input":"2024-05-12T17:18:33.047616Z","iopub.status.idle":"2024-05-12T17:18:33.678728Z","shell.execute_reply.started":"2024-05-12T17:18:33.047583Z","shell.execute_reply":"2024-05-12T17:18:33.677717Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"pois_checkins  # with this we can *efficiently* build our POI-POI spatial-temporal graphs","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:33.680539Z","iopub.execute_input":"2024-05-12T17:18:33.681250Z","iopub.status.idle":"2024-05-12T17:18:33.689142Z","shell.execute_reply.started":"2024-05-12T17:18:33.681201Z","shell.execute_reply":"2024-05-12T17:18:33.688082Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"shape: (4_455, 3)\n┌──────────────────────────┬──────┬───────────────────────────────────┐\n│ pois                     ┆ g4   ┆ checkin_times                     │\n│ ---                      ┆ ---  ┆ ---                               │\n│ str                      ┆ str  ┆ list[str]                         │\n╞══════════════════════════╪══════╪═══════════════════════════════════╡\n│ 4ad8f6f2f964a520821621e3 ┆ dppn ┆ [\"2012-04-07 14:54:35\", \"2012-04… │\n│ 4a9aea62f964a520933320e3 ┆ dqcj ┆ [\"2012-04-04 20:17:27\", \"2012-04… │\n│ 4d92b679b053b60c78857fcb ┆ sxk9 ┆ [\"2012-04-04 10:17:00\", \"2012-04… │\n│ 4e5a143618388cd5cbac0130 ┆ qqgu ┆ [\"2012-09-05 18:59:37\", \"2012-09… │\n│ 4c2cdff977cfe21e0fb8b6f1 ┆ sxk9 ┆ [\"2012-04-09 22:39:08\", \"2012-04… │\n│ …                        ┆ …    ┆ …                                 │\n│ 4b55d164f964a5205af127e3 ┆ sxft ┆ [\"2012-05-19 18:00:48\", \"2012-11… │\n│ 4a4c0b94f964a52000ad1fe3 ┆ dpsb ┆ [\"2012-04-07 16:05:49\", \"2012-04… │\n│ 4b5a80a4f964a52078c828e3 ┆ xn77 ┆ [\"2012-05-04 21:09:08\", \"2012-05… │\n│ 4c6be5443e72b713d7ef6589 ┆ w4rg ┆ [\"2012-05-27 13:31:16\", \"2012-06… │\n│ 4b058884f964a52067cb22e3 ┆ u0nd ┆ [\"2012-05-02 14:00:06\", \"2012-05… │\n└──────────────────────────┴──────┴───────────────────────────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4ad8f6f2f964a5…</td><td>&quot;dppn&quot;</td><td>[&quot;2012-04-07 14:54:35&quot;, &quot;2012-04-07 18:13:18&quot;, … &quot;2012-12-30 18:57:21&quot;]</td></tr><tr><td>&quot;4a9aea62f964a5…</td><td>&quot;dqcj&quot;</td><td>[&quot;2012-04-04 20:17:27&quot;, &quot;2012-04-07 18:10:40&quot;, … &quot;2013-09-10 16:47:33&quot;]</td></tr><tr><td>&quot;4d92b679b053b6…</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-04-04 10:17:00&quot;, &quot;2012-04-05 14:10:53&quot;, … &quot;2013-08-13 22:26:47&quot;]</td></tr><tr><td>&quot;4e5a143618388c…</td><td>&quot;qqgu&quot;</td><td>[&quot;2012-09-05 18:59:37&quot;, &quot;2012-09-13 17:59:58&quot;, … &quot;2012-07-08 20:11:16&quot;]</td></tr><tr><td>&quot;4c2cdff977cfe2…</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-04-09 22:39:08&quot;, &quot;2012-04-11 09:36:16&quot;, … &quot;2013-08-21 22:40:59&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4b55d164f964a5…</td><td>&quot;sxft&quot;</td><td>[&quot;2012-05-19 18:00:48&quot;, &quot;2012-11-06 18:58:43&quot;, … &quot;2013-08-24 08:53:36&quot;]</td></tr><tr><td>&quot;4a4c0b94f964a5…</td><td>&quot;dpsb&quot;</td><td>[&quot;2012-04-07 16:05:49&quot;, &quot;2012-04-14 19:15:52&quot;, … &quot;2013-04-24 13:56:23&quot;]</td></tr><tr><td>&quot;4b5a80a4f964a5…</td><td>&quot;xn77&quot;</td><td>[&quot;2012-05-04 21:09:08&quot;, &quot;2012-05-04 21:09:23&quot;, … &quot;2013-08-21 18:41:30&quot;]</td></tr><tr><td>&quot;4c6be5443e72b7…</td><td>&quot;w4rg&quot;</td><td>[&quot;2012-05-27 13:31:16&quot;, &quot;2012-06-04 17:46:32&quot;, … &quot;2012-08-10 13:19:26&quot;]</td></tr><tr><td>&quot;4b058884f964a5…</td><td>&quot;u0nd&quot;</td><td>[&quot;2012-05-02 14:00:06&quot;, &quot;2012-05-14 09:00:58&quot;, … &quot;2012-12-13 08:43:18&quot;]</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"code","source":"def UTC_to_weekslot(utc: str) -> int:\n    \"\"\"UTC_to_weekslot converts a UTC timestamp to a weekslot.\n\n    Parameters\n    ----------\n    utc : str\n        A string representing a UTC timestamp.\n\n    Returns\n    -------\n    int\n        A weekslot in the range [0, 56).\n    \"\"\"\n\n    date = datetime.datetime.strptime(utc, \"%Y-%m-%d %H:%M:%S\")\n    week = date.weekday()\n    hour = date.hour\n\n    return week * 8 + hour // 3","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:33.690305Z","iopub.execute_input":"2024-05-12T17:18:33.691028Z","iopub.status.idle":"2024-05-12T17:18:33.702976Z","shell.execute_reply.started":"2024-05-12T17:18:33.691004Z","shell.execute_reply":"2024-05-12T17:18:33.701995Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"Next, we want to encode all of our inputs for our neural networks, this could *probably* be done \nwith polars magic, but it's too delicate and we prefer classic for-looping.","metadata":{}},{"cell_type":"code","source":"encoder_dict = {\n    \"users\": LabelEncoder(),\n    \"pois\": LabelEncoder(),\n    \"g2\": LabelEncoder(),\n    \"g3\": LabelEncoder(),\n    \"g4\": LabelEncoder(),\n    \"g5\": LabelEncoder(),\n    \"g6\": LabelEncoder(),\n}\n\nencoded_data = {\n    \"users\": [],\n    \"pois\": [],\n    \"g2\": [],\n    \"g3\": [],\n    \"g4\": [],\n    \"g5\": [],\n    \"g6\": [],\n}\n\nunique_data = {\n    \"users\": set(),\n    \"pois\": set(),\n    \"g2\": set(),\n    \"g3\": set(),\n    \"g4\": set(),\n    \"g5\": set(),\n    \"g6\": set(),\n}\n\n# quick and dirty encoding:\n# 1. put every unique symbol in a list\n# 2. fit the respective encoder\n# 3. transform the lists\n\nfor i, row in enumerate(final_sorted.iter_rows()):\n\n    user, pois, geohashes, times_sorted, n_checkins = row\n\n    g2 = [geo[:2] for geo in geohashes]\n    g3 = [geo[:3] for geo in geohashes]\n    g4 = [geo[:4] for geo in geohashes]\n    g5 = [geo[:5] for geo in geohashes]\n    g6 = [geo[:6] for geo in geohashes]  # redundant, but I like symmetry\n\n    unique_data[\"users\"].add(user)\n    unique_data[\"pois\"].update(pois)\n    unique_data[\"g2\"].update(g2)\n    unique_data[\"g3\"].update(g3)\n    unique_data[\"g4\"].update(g4)\n    unique_data[\"g5\"].update(g5)\n    unique_data[\"g6\"].update(g6)\n\nfor property, enc, data in zip(\n    encoder_dict.keys(), encoder_dict.values(), unique_data.values()\n):\n    enc.fit(list(data))\n    encoder_dict[property] = enc","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:33.704221Z","iopub.execute_input":"2024-05-12T17:18:33.704998Z","iopub.status.idle":"2024-05-12T17:18:34.088484Z","shell.execute_reply.started":"2024-05-12T17:18:33.704965Z","shell.execute_reply":"2024-05-12T17:18:34.087664Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# this could be optimized, right now it takes a while, at least we have a nice progress bar to look at\n\nds_size = len(final_sorted)\n\nfor i, row in tqdm(enumerate(final_sorted.iter_rows()), total=ds_size):\n\n    user, pois, geohashes, times_sorted, n_checkins = row\n\n    g2 = [geo[:2] for geo in geohashes]\n    g3 = [geo[:3] for geo in geohashes]\n    g4 = [geo[:4] for geo in geohashes]\n    g5 = [geo[:5] for geo in geohashes]\n    g6 = [geo[:6] for geo in geohashes]\n\n    encoded_data[\"users\"].append(encoder_dict[\"users\"].transform([user])[0])\n    encoded_data[\"pois\"].append(encoder_dict[\"pois\"].transform(pois))\n    encoded_data[\"g2\"].append(encoder_dict[\"g2\"].transform(g2))\n    encoded_data[\"g3\"].append(encoder_dict[\"g3\"].transform(g3))\n    encoded_data[\"g4\"].append(encoder_dict[\"g4\"].transform(g4))\n    encoded_data[\"g5\"].append(encoder_dict[\"g5\"].transform(g5))\n    encoded_data[\"g6\"].append(encoder_dict[\"g6\"].transform(g6))\n\n    # sum 1 to all values to avoid 0s\n    encoded_data[\"users\"][-1] += 1\n    encoded_data[\"pois\"][-1] += 1\n    encoded_data[\"g2\"][-1] += 1\n    encoded_data[\"g3\"][-1] += 1\n    encoded_data[\"g4\"][-1] += 1\n    encoded_data[\"g5\"][-1] += 1\n    encoded_data[\"g6\"][-1] += 1","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:18:34.089730Z","iopub.execute_input":"2024-05-12T17:18:34.089994Z","iopub.status.idle":"2024-05-12T17:22:58.097446Z","shell.execute_reply.started":"2024-05-12T17:18:34.089972Z","shell.execute_reply":"2024-05-12T17:22:58.096536Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"100%|██████████| 19862/19862 [04:23<00:00, 75.24it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# check that we left space for the padding token\nmin((arr.min() for arr in encoded_data[\"pois\"]))","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:22:58.098663Z","iopub.execute_input":"2024-05-12T17:22:58.098951Z","iopub.status.idle":"2024-05-12T17:22:58.158205Z","shell.execute_reply.started":"2024-05-12T17:22:58.098927Z","shell.execute_reply":"2024-05-12T17:22:58.157305Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"code","source":"pois_checkins","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:22:58.159379Z","iopub.execute_input":"2024-05-12T17:22:58.159644Z","iopub.status.idle":"2024-05-12T17:22:58.172245Z","shell.execute_reply.started":"2024-05-12T17:22:58.159621Z","shell.execute_reply":"2024-05-12T17:22:58.170940Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"shape: (4_455, 3)\n┌──────────────────────────┬──────┬───────────────────────────────────┐\n│ pois                     ┆ g4   ┆ checkin_times                     │\n│ ---                      ┆ ---  ┆ ---                               │\n│ str                      ┆ str  ┆ list[str]                         │\n╞══════════════════════════╪══════╪═══════════════════════════════════╡\n│ 4ad8f6f2f964a520821621e3 ┆ dppn ┆ [\"2012-04-07 14:54:35\", \"2012-04… │\n│ 4a9aea62f964a520933320e3 ┆ dqcj ┆ [\"2012-04-04 20:17:27\", \"2012-04… │\n│ 4d92b679b053b60c78857fcb ┆ sxk9 ┆ [\"2012-04-04 10:17:00\", \"2012-04… │\n│ 4e5a143618388cd5cbac0130 ┆ qqgu ┆ [\"2012-09-05 18:59:37\", \"2012-09… │\n│ 4c2cdff977cfe21e0fb8b6f1 ┆ sxk9 ┆ [\"2012-04-09 22:39:08\", \"2012-04… │\n│ …                        ┆ …    ┆ …                                 │\n│ 4b55d164f964a5205af127e3 ┆ sxft ┆ [\"2012-05-19 18:00:48\", \"2012-11… │\n│ 4a4c0b94f964a52000ad1fe3 ┆ dpsb ┆ [\"2012-04-07 16:05:49\", \"2012-04… │\n│ 4b5a80a4f964a52078c828e3 ┆ xn77 ┆ [\"2012-05-04 21:09:08\", \"2012-05… │\n│ 4c6be5443e72b713d7ef6589 ┆ w4rg ┆ [\"2012-05-27 13:31:16\", \"2012-06… │\n│ 4b058884f964a52067cb22e3 ┆ u0nd ┆ [\"2012-05-02 14:00:06\", \"2012-05… │\n└──────────────────────────┴──────┴───────────────────────────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4ad8f6f2f964a5…</td><td>&quot;dppn&quot;</td><td>[&quot;2012-04-07 14:54:35&quot;, &quot;2012-04-07 18:13:18&quot;, … &quot;2012-12-30 18:57:21&quot;]</td></tr><tr><td>&quot;4a9aea62f964a5…</td><td>&quot;dqcj&quot;</td><td>[&quot;2012-04-04 20:17:27&quot;, &quot;2012-04-07 18:10:40&quot;, … &quot;2013-09-10 16:47:33&quot;]</td></tr><tr><td>&quot;4d92b679b053b6…</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-04-04 10:17:00&quot;, &quot;2012-04-05 14:10:53&quot;, … &quot;2013-08-13 22:26:47&quot;]</td></tr><tr><td>&quot;4e5a143618388c…</td><td>&quot;qqgu&quot;</td><td>[&quot;2012-09-05 18:59:37&quot;, &quot;2012-09-13 17:59:58&quot;, … &quot;2012-07-08 20:11:16&quot;]</td></tr><tr><td>&quot;4c2cdff977cfe2…</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-04-09 22:39:08&quot;, &quot;2012-04-11 09:36:16&quot;, … &quot;2013-08-21 22:40:59&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4b55d164f964a5…</td><td>&quot;sxft&quot;</td><td>[&quot;2012-05-19 18:00:48&quot;, &quot;2012-11-06 18:58:43&quot;, … &quot;2013-08-24 08:53:36&quot;]</td></tr><tr><td>&quot;4a4c0b94f964a5…</td><td>&quot;dpsb&quot;</td><td>[&quot;2012-04-07 16:05:49&quot;, &quot;2012-04-14 19:15:52&quot;, … &quot;2013-04-24 13:56:23&quot;]</td></tr><tr><td>&quot;4b5a80a4f964a5…</td><td>&quot;xn77&quot;</td><td>[&quot;2012-05-04 21:09:08&quot;, &quot;2012-05-04 21:09:23&quot;, … &quot;2013-08-21 18:41:30&quot;]</td></tr><tr><td>&quot;4c6be5443e72b7…</td><td>&quot;w4rg&quot;</td><td>[&quot;2012-05-27 13:31:16&quot;, &quot;2012-06-04 17:46:32&quot;, … &quot;2012-08-10 13:19:26&quot;]</td></tr><tr><td>&quot;4b058884f964a5…</td><td>&quot;u0nd&quot;</td><td>[&quot;2012-05-02 14:00:06&quot;, &quot;2012-05-14 09:00:58&quot;, … &quot;2012-12-13 08:43:18&quot;]</td></tr></tbody></table></div>"},"metadata":{}}]},{"cell_type":"code","source":"# we also encode the graph dataframe so we can build the graphs\n\npois_checkins = (\n    pois_checkins.lazy()\n    .with_columns(\n        [\n            rs.col(\"pois\").map_elements(\n                lambda s: encoder_dict[\"pois\"].transform([s])[0] + 1, rs.Int64\n            ),\n            rs.col(\"g4\").map_elements(\n                lambda s: encoder_dict[\"g4\"].transform([s])[0] + 1, rs.Int64\n            ),  # apply utc_to_weekslot to each timestamp in the list\n            rs.col(\"checkin_times\").map_elements(\n                lambda s: [UTC_to_weekslot(date) for date in s], rs.List(rs.Int64)\n            ),\n        ]\n    )\n    .sort(\"pois\")\n    .collect()\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:22:58.175049Z","iopub.execute_input":"2024-05-12T17:22:58.175390Z","iopub.status.idle":"2024-05-12T17:24:05.319129Z","shell.execute_reply.started":"2024-05-12T17:22:58.175357Z","shell.execute_reply":"2024-05-12T17:24:05.318286Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# add fictitious POI 0 to the graph, with nonexistent geohash and no timeslot, so we get a 0 row and column for the padding token\nfake_datapoint = rs.DataFrame(\n    {\n        \"pois\": [0],\n        \"g4\": [pois_checkins[\"g4\"].max() + 42],\n        \"checkin_times\": [[43]],\n    }\n)\n# this is a lot of work since polars dataframes are immutable by default, we have to run a query to change the 43 into an empty list\n# we NEED the 43 otherwise polars won't infer the datatype of the list\n\nfake_datapoint = fake_datapoint.with_columns(\n    [rs.col(\"checkin_times\").map_elements(lambda s: [], rs.List(rs.Int64))]\n)\n\npois_checkins = fake_datapoint.vstack(pois_checkins)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.320204Z","iopub.execute_input":"2024-05-12T17:24:05.320557Z","iopub.status.idle":"2024-05-12T17:24:05.942800Z","shell.execute_reply.started":"2024-05-12T17:24:05.320531Z","shell.execute_reply":"2024-05-12T17:24:05.940593Z"},"trusted":true},"execution_count":51,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSchemaError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m fake_datapoint \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m      3\u001b[0m     {\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpois\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     }\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# this is a lot of work since polars dataframes are immutable by default, we have to run a query to change the 43 into an empty list\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# we NEED the 43 otherwise polars won't infer the datatype of the list\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m fake_datapoint \u001b[38;5;241m=\u001b[39m \u001b[43mfake_datapoint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcheckin_times\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInt64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m pois_checkins \u001b[38;5;241m=\u001b[39m fake_datapoint\u001b[38;5;241m.\u001b[39mvstack(pois_checkins)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/dataframe/frame.py:7874\u001b[0m, in \u001b[0;36mDataFrame.with_columns\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   7728\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_columns\u001b[39m(\n\u001b[1;32m   7729\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   7730\u001b[0m     \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr],\n\u001b[1;32m   7731\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr,\n\u001b[1;32m   7732\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   7733\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7734\u001b[0m \u001b[38;5;124;03m    Add columns to this DataFrame.\u001b[39;00m\n\u001b[1;32m   7735\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7872\u001b[0m \u001b[38;5;124;03m    └─────┴──────┴─────────────┘\u001b[39;00m\n\u001b[1;32m   7873\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 7874\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/polars/lazyframe/frame.py:1708\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager)\u001b[0m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m background:\n\u001b[1;32m   1706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InProcessQuery(ldf\u001b[38;5;241m.\u001b[39mcollect_concurrently())\n\u001b[0;32m-> 1708\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mSchemaError\u001b[0m: expected output type 'List(Int64)', got 'List(Null)'; set `return_dtype` to the proper datatype"],"ename":"SchemaError","evalue":"expected output type 'List(Int64)', got 'List(Null)'; set `return_dtype` to the proper datatype","output_type":"error"}]},{"cell_type":"code","source":"spatial_row = np.array(pois_checkins[\"g4\"].to_list()).reshape(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.943611Z","iopub.status.idle":"2024-05-12T17:24:05.943968Z","shell.execute_reply.started":"2024-05-12T17:24:05.943793Z","shell.execute_reply":"2024-05-12T17:24:05.943808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# outer product using equality\nspatial_graph = (spatial_row == spatial_row.T).astype(np.int32)\nspatial_graph[0, 0] = (\n    0  # the fake g4 is still equal to itself, we suppress this equality\n)\nspatial_graph = torch.tensor(spatial_graph)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.945592Z","iopub.status.idle":"2024-05-12T17:24:05.945908Z","shell.execute_reply.started":"2024-05-12T17:24:05.945754Z","shell.execute_reply":"2024-05-12T17:24:05.945767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temporal_row = pois_checkins[\"checkin_times\"].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.947573Z","iopub.status.idle":"2024-05-12T17:24:05.947885Z","shell.execute_reply.started":"2024-05-12T17:24:05.947733Z","shell.execute_reply":"2024-05-12T17:24:05.947745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temporal_graph = np.zeros((spatial_row.shape[0], spatial_row.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.948862Z","iopub.status.idle":"2024-05-12T17:24:05.949163Z","shell.execute_reply.started":"2024-05-12T17:24:05.949010Z","shell.execute_reply":"2024-05-12T17:24:05.949023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temporal_sets = [np.array(list(set(row))) for row in temporal_row]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.950134Z","iopub.status.idle":"2024-05-12T17:24:05.950472Z","shell.execute_reply.started":"2024-05-12T17:24:05.950304Z","shell.execute_reply":"2024-05-12T17:24:05.950318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_sets = torch.zeros((len(temporal_sets), 56), dtype=torch.int8)\n\nfor i, r in enumerate(temporal_row):\n    indices = torch.tensor(r, dtype=torch.long)\n    time_sets[i, indices] = 1","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.951598Z","iopub.status.idle":"2024-05-12T17:24:05.951933Z","shell.execute_reply.started":"2024-05-12T17:24:05.951769Z","shell.execute_reply":"2024-05-12T17:24:05.951783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_sets.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.953273Z","iopub.status.idle":"2024-05-12T17:24:05.953611Z","shell.execute_reply.started":"2024-05-12T17:24:05.953450Z","shell.execute_reply":"2024-05-12T17:24:05.953464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# AND outer product\n\nintersection = time_sets @ time_sets.T\nunion = time_sets.unsqueeze(1) | time_sets.unsqueeze(0)\nunion = union.sum(dim=2)\niou = intersection / union","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.954704Z","iopub.status.idle":"2024-05-12T17:24:05.955047Z","shell.execute_reply.started":"2024-05-12T17:24:05.954878Z","shell.execute_reply":"2024-05-12T17:24:05.954893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temporal_graph = iou >= 0.9\n# cast to int\ntemporal_graph = temporal_graph.int()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.956260Z","iopub.status.idle":"2024-05-12T17:24:05.956602Z","shell.execute_reply.started":"2024-05-12T17:24:05.956440Z","shell.execute_reply":"2024-05-12T17:24:05.956454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temporal_graph[0, :].sum()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.958162Z","iopub.status.idle":"2024-05-12T17:24:05.958505Z","shell.execute_reply.started":"2024-05-12T17:24:05.958345Z","shell.execute_reply":"2024-05-12T17:24:05.958359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We print information about the sparsity of the graphs, we note that \nthe sparsity of the graphs is similar to that of the paper.","metadata":{}},{"cell_type":"code","source":"temporal_density = (\n    temporal_graph.sum() / (temporal_graph.shape[0] * temporal_graph.shape[1])\n).item()\nspatial_density = (\n    spatial_graph.sum() / (spatial_graph.shape[0] * spatial_graph.shape[1])\n).item()\n\nprint(f\"Temporal sparsity: {(1 - temporal_density) * 100:.2f}%\")\n\nprint(f\"Spatial sparsity: {(1 - spatial_density) * 100:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.960356Z","iopub.status.idle":"2024-05-12T17:24:05.960817Z","shell.execute_reply.started":"2024-05-12T17:24:05.960570Z","shell.execute_reply":"2024-05-12T17:24:05.960589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics\n","metadata":{}},{"cell_type":"markdown","source":"The paper utilizes metrics that check if the target is in the top-k recommendations, we implement them here.","metadata":{}},{"cell_type":"code","source":"class AccuracyAtK(nn.Module):\n    def __init__(self, k: int):\n        \"\"\"__init__ initializes the AccuracyAtK module.\n\n        Accuracy@k is the proportion of correct predictions in the top-k elements.\n\n        Parameters\n        ----------\n        k : int\n            The number of top-k elements to consider.\n\n        \"\"\"\n        super().__init__()\n        self.k = k\n\n    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n        \"\"\"forward computes the accuracy at k between logits and targets.\n\n        Parameters\n        ----------\n        logits : torch.Tensor\n            Class probability, either (B, C) or (B, T, C)\n        targets : torch.Tensor\n            Ground truth class indices, either (B,) or (B, T)\n\n        Returns\n        -------\n        torch.Tensor\n            The accuracy at k, a scalar-tensor.\n        \"\"\"\n\n        # Gotta have at least one nasty python one-liner, in memory of the old\n        # programming lab 1 bachelor course\n        return (\n            (logits.topk(self.k, dim=-1)[1] == targets.unsqueeze(-1))\n            .any(dim=-1)\n            .float()\n            .mean()\n        )\n\n\nclass MeanReciprocalRank(nn.Module):\n\n    def __init__(self):\n        \"\"\"__init__ initializes the MeanReciprocalRank module.\n\n        Mean reciprocal rank is the average of the reciprocal ranks of the top-k elements.\n\n        \"\"\"\n        super().__init__()\n\n    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n        \"\"\"forward computes the mean reciprocal rank between logits and targets.\n\n        Parameters\n        ----------\n        logits : torch.Tensor\n            Class probability\n        targets : torch.Tensor\n            Ground truth class indices\n\n        Returns\n        -------\n        torch.Tensor\n            The mean reciprocal rank, a scalar-tensor.\n        \"\"\"\n\n        _, indices = logits.topk(logits.shape[-1], dim=-1)\n        ranks = (indices == targets.unsqueeze(-1)).nonzero()[:, -1].float() + 1\n        return (1.0 / ranks).mean()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.962191Z","iopub.status.idle":"2024-05-12T17:24:05.962666Z","shell.execute_reply.started":"2024-05-12T17:24:05.962437Z","shell.execute_reply":"2024-05-12T17:24:05.962456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and Datamodule\n\nWe then define a pytorch dataset and a custom collation function that allows us to dynamically\npad sequences to the longest one in the batch (as opposed to the longest one in the dataset)\nas they are loaded during training, this gives us an edge in performance by dramatically reducing the \nsparsity of our inputs.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.nn.utils.rnn import pad_sequence\n\n\ndef rnn_collation_fn(batch):\n\n    users = []\n    pois = []\n    g2 = []\n    g3 = []\n    g4 = []\n    g5 = []\n    g6 = []\n\n    for user, poi, geo2, geo3, geo4, geo5, geo6 in batch:\n        users.append(user)\n        pois.append(poi)\n        g2.append(geo2)\n        g3.append(geo3)\n        g4.append(geo4)\n        g5.append(geo5)\n        g6.append(geo6)\n    seq = (\n        torch.tensor(users, dtype=torch.long),\n        pad_sequence(pois, batch_first=True, padding_value=0),\n        pad_sequence(g2, batch_first=True, padding_value=0),\n        pad_sequence(g3, batch_first=True, padding_value=0),\n        pad_sequence(g4, batch_first=True, padding_value=0),\n        pad_sequence(g5, batch_first=True, padding_value=0),\n        pad_sequence(g6, batch_first=True, padding_value=0),\n    )  # build a sequence\n\n    x = (\n        seq[0],\n        seq[1][:, :-1],\n        seq[2][:, :-1],\n        seq[3][:, :-1],\n        seq[4][:, :-1],\n        seq[5][:, :-1],\n        seq[6][:, :-1],\n    )  # omit the last one for sample\n\n    y = (\n        seq[0],\n        seq[1][:, 1:],\n        seq[2][:, 1:],\n        seq[3][:, 1:],\n        seq[4][:, 1:],\n        seq[5][:, 1:],\n        seq[6][:, 1:],\n    )  # omit the first one for ground truth\n\n    return x, y\n\n\nclass CheckinDataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data[\"users\"])\n\n    def __getitem__(self, idx):\n\n        x = (\n            torch.tensor(encoded_data[\"users\"][idx], dtype=torch.long),\n            torch.tensor(encoded_data[\"pois\"][idx], dtype=torch.long),\n            torch.tensor(encoded_data[\"g2\"][idx], dtype=torch.long),\n            torch.tensor(encoded_data[\"g3\"][idx], dtype=torch.long),\n            torch.tensor(encoded_data[\"g4\"][idx], dtype=torch.long),\n            torch.tensor(encoded_data[\"g5\"][idx], dtype=torch.long),\n            torch.tensor(encoded_data[\"g6\"][idx], dtype=torch.long),\n        )\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.963957Z","iopub.status.idle":"2024-05-12T17:24:05.964417Z","shell.execute_reply.started":"2024-05-12T17:24:05.964169Z","shell.execute_reply":"2024-05-12T17:24:05.964187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CheckinModule(pl.LightningDataModule):\n    def __init__(self, encoded_data, batch_size=32, workers=4):\n        super().__init__()\n        self.encoded_data = encoded_data\n        self.batch_size = batch_size\n        self.workers = workers\n\n    def setup(self, stage=None):\n        self.whole_dataset = CheckinDataset(self.encoded_data)\n\n        l = len(self.whole_dataset)\n\n        train_size = int(0.8 * l)\n        val_size = int(0.1 * l)\n        test_size = l - train_size - val_size\n\n        # generate train, val, test datasets by random split\n        self.train_dataset, self.val_dataset, self.test_dataset = (\n            torch.utils.data.random_split(\n                self.whole_dataset, [train_size, val_size, test_size]\n            )\n        )\n\n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=self.workers,\n            collate_fn=rnn_collation_fn,\n        )\n\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=self.workers,\n            collate_fn=rnn_collation_fn,\n        )\n\n    def test_dataloader(self):\n        return torch.utils.data.DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=self.workers,\n            collate_fn=rnn_collation_fn,\n        )\n\n    def save(self, whole_path, train_path, val_path, test_path):\n        torch.save(self.whole_dataset, whole_path)\n        torch.save(self.train_dataset, train_path)\n        torch.save(self.val_dataset, val_path)\n        torch.save(self.test_dataset, test_path)\n\n    @staticmethod  # load without instantiating\n    def load(whole_path, train_path, val_path, test_path):\n        whole_dataset = torch.load(whole_path)\n        train_dataset = torch.load(train_path)\n        val_dataset = torch.load(val_path)\n        test_dataset = torch.load(test_path)\n        return whole_dataset, train_dataset, val_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.966199Z","iopub.status.idle":"2024-05-12T17:24:05.966662Z","shell.execute_reply.started":"2024-05-12T17:24:05.966434Z","shell.execute_reply":"2024-05-12T17:24:05.966453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline model: LSTM","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass BaselineDimensions:\n    nuser: int\n    npoi: int\n    g2len: int\n    g3len: int\n    g4len: int\n    g5len: int\n    g6len: int\n\n\n# HMT_RN (Hierarchical Multi-Task Recurrent Network)\nclass HMT_RN(pl.LightningModule):\n    def __init__(\n        self,\n        dimensions: BaselineDimensions,\n        embedding_dim,\n        lstm_hidden_dim,\n        dropout_rate=0.9,  # 0.9 is a lot, but the paper says so.\n    ):\n        super(HMT_RN, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = lstm_hidden_dim\n        self.dims = dimensions\n\n        # Embedding layers one for user, one for poi and one for each G@P\n        self.user_embedding = nn.Embedding(dims.nuser, hidden_dim, padding_idx=0)\n        self.poi_embedding = nn.Embedding(dimensions.npoi, embedding_dim, padding_idx=0)\n        self.g2_embed = nn.Embedding(dimensions.g2len, embedding_dim, padding_idx=0)\n        self.g3_embed = nn.Embedding(dimensions.g3len, embedding_dim, padding_idx=0)\n        self.g4_embed = nn.Embedding(dimensions.g4len, embedding_dim, padding_idx=0)\n        self.g5_embed = nn.Embedding(dimensions.g5len, embedding_dim, padding_idx=0)\n        self.g6_embed = nn.Embedding(dimensions.g6len, embedding_dim, padding_idx=0)\n\n        # Dropout layer for embeddings\n        self.e_drop = nn.Dropout(p=dropout_rate)\n\n        # LSTM layer\n        self.lstm = nn.LSTM(\n            input_size=embedding_dim, hidden_size=lstm_hidden_dim, batch_first=True\n        )\n\n        # Linear layers for prediction tasks\n        self.linear_poi = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.npoi)\n        self.linear_g2 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g2len)\n        self.linear_g3 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g3len)\n        self.linear_g4 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g4len)\n        self.linear_g5 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g5len)\n        self.linear_g6 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g6len)\n\n        self.criterion = nn.CrossEntropyLoss()\n\n        self.top1 = AccuracyAtK(1)\n        self.top5 = AccuracyAtK(5)\n        self.top10 = AccuracyAtK(10)\n        self.top20 = AccuracyAtK(20)\n        self.mrr = MeanReciprocalRank()\n\n        self.apply(self.init_weights)\n\n    def init_weights(self, w):\n\n        if type(w) == nn.Linear:\n            nn.init.kaiming_normal_(w.weight)\n            nn.init.constant_(w.bias, 0)\n        elif type(w) == nn.LSTM:\n            for name, param in w.named_parameters():\n                if \"bias\" in name:\n                    nn.init.constant_(param, 0)\n                elif \"weight\" in name:\n                    nn.init.kaiming_normal_(param)\n        elif type(w) == nn.Embedding:\n            nn.init.kaiming_normal_(w.weight)\n            nn.init.constant_(w.weight[0], 0)\n\n    def forward(self, batch):\n        \"\"\"forward passes the batch through the model.\n\n        Parameters\n        ----------\n        batch : `tuple[torch.Tensor]`\n            A tuple of tensors ordered as follows:\n            (users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6)\n        \"\"\"\n\n        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = batch\n\n        B, T = poi.shape\n\n        # make it so  that users are tiled T times\n        users = users.repeat(T, 1).T\n        \n        e_user = self.e_drop(self.user_embedding(users))\n        e_poi = self.e_drop(self.poi_embedding(poi))\n        e_gap2 = self.e_drop(self.g2_embed(x_geoHash2))\n        e_gap3 = self.e_drop(self.g3_embed(x_geoHash3))\n        e_gap4 = self.e_drop(self.g4_embed(x_geoHash4))\n        e_gap5 = self.e_drop(self.g5_embed(x_geoHash5))\n        e_gap6 = self.e_drop(self.g6_embed(x_geoHash6))\n\n        h_t, c_t = self.lstm(e_poi)\n\n        # dense layers\n        next_poi = self.linear_poi(torch.cat((h_t, e_user), dim=2))\n        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n\n        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        (\n            poi_pred,\n            gap2_pred,\n            gap3_pred,\n            gap4_pred,\n            gap5_pred,\n            gap6_pred,\n        ) = self(x)\n\n        loss_poi = self.criterion(\n            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n        )\n        loss_gap2 = self.criterion(\n            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n        )\n        loss_gap3 = self.criterion(\n            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n        )\n        loss_gap4 = self.criterion(\n            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n        )\n        loss_gap5 = self.criterion(\n            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n        )\n        loss_gap6 = self.criterion(\n            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n        )\n\n        loss = (\n            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n        ) / 6\n        self.log(\"train/loss\", loss)\n        self.log(\"train/loss_gap2\", loss_gap2)\n        self.log(\"train/loss_gap3\", loss_gap3)\n        self.log(\"train/loss_gap4\", loss_gap4)\n        self.log(\"train/loss_gap5\", loss_gap5)\n        self.log(\"train/loss_gap6\", loss_gap6)\n        self.log(\"train/loss_poi\", loss_poi)\n\n        return {\"loss\": loss}\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        (\n            poi_pred,\n            gap2_pred,\n            gap3_pred,\n            gap4_pred,\n            gap5_pred,\n            gap6_pred,\n        ) = self(x)\n\n        loss_poi = self.criterion(\n            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n        )\n        loss_gap2 = self.criterion(\n            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n        )\n        loss_gap3 = self.criterion(\n            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n        )\n        loss_gap4 = self.criterion(\n            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n        )\n        loss_gap5 = self.criterion(\n            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n        )\n        loss_gap6 = self.criterion(\n            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n        )\n\n        loss = (\n            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n        ) / 6\n\n        top1_acc = self.top1(poi_pred, y[1])\n        top5_acc = self.top5(poi_pred, y[1])\n        top10_acc = self.top10(poi_pred, y[1])\n        top20_acc = self.top20(poi_pred, y[1])\n        mrr = self.mrr(poi_pred, y[1])\n\n        self.log(\"val/loss\", loss)\n        self.log(\"val/loss_gap2\", loss_gap2)\n        self.log(\"val/loss_gap3\", loss_gap3)\n        self.log(\"val/loss_gap4\", loss_gap4)\n        self.log(\"val/loss_gap5\", loss_gap5)\n        self.log(\"val/loss_gap6\", loss_gap6)\n        self.log(\"val/loss_poi\", loss_poi)\n\n        # log \"leaderboard\" metrics\n        self.log(\"val/top1\", top1_acc)\n        self.log(\"val/top5\", top5_acc)\n        self.log(\"val/top10\", top10_acc)\n        self.log(\"val/top20\", top20_acc)\n        self.log(\"val/mrr\", mrr)\n\n        return loss\n\n    def configure_optimizers(self):\n        # Define optimizer and scheduler\n        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.967942Z","iopub.status.idle":"2024-05-12T17:24:05.968403Z","shell.execute_reply.started":"2024-05-12T17:24:05.968154Z","shell.execute_reply":"2024-05-12T17:24:05.968172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Graph Neural Network","metadata":{}},{"cell_type":"code","source":"# GNN Components\n\n\nclass attn_LSTM(pl.LightningModule):\n\n    def __init__(self, embedding_dim, hidden_dim):\n        super(attn_LSTM, self).__init__()\n        self.embedding_dim = embedding_dim\n        self.hidden_dim = hidden_dim\n        self.W = nn.Linear(embedding_dim, 4 * hidden_dim)\n        self.U = nn.Linear(hidden_dim, 4 * hidden_dim)\n\n        self.s_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n        self.t_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n\n    def forward(self, x, hidden, spatial, temporal, numTimeSteps):\n        h_t, c_t = hidden\n\n        previous_h_t = h_t\n        previous_c_t = c_t\n\n        allGates_preact = (\n            self.W(x) + self.U(previous_h_t) + self.s_W(spatial) + self.t_W(temporal)\n        )\n\n        input_g = allGates_preact[:, :, : self.hidden_dim].sigmoid()\n        forget_g = allGates_preact[\n            :, :, self.hidden_dim : 2 * self.hidden_dim\n        ].sigmoid()\n        output_g = allGates_preact[\n            :, :, 2 * self.hidden_dim : 3 * self.hidden_dim\n        ].sigmoid()\n        c_t_g = allGates_preact[:, :, 3 * self.hidden_dim :].tanh()\n\n        c_t = forget_g * previous_c_t + input_g * c_t_g\n        h_t = output_g * c_t.tanh()\n\n        batchSize = x.shape[0]\n        h_t = h_t.view(batchSize, numTimeSteps, self.hidden_dim)\n        c_t = c_t.view(batchSize, numTimeSteps, self.hidden_dim)\n\n        return h_t, c_t\n\n\ndef get_neighbours(adj_matrix, poi):\n    neigh_indices_list = []\n    max_length = 0\n\n    for batch_poi in poi:\n        batch_indices = []\n        for single_poi in batch_poi:\n            poi_row = adj_matrix[single_poi]\n            neigh_indices = torch.where(poi_row == 1)[0]\n            batch_indices.append(neigh_indices)\n            max_length = max(max_length, len(neigh_indices))\n\n        neigh_indices_list.append(batch_indices)\n\n    padded_neigh_indices_list = []\n    for batch_indices in neigh_indices_list:\n        padded_batch_indices = pad_sequence(\n            batch_indices, batch_first=True, padding_value=0\n        )\n        padded_neigh_indices_list.append(padded_batch_indices)\n\n    padded_tensor = torch.stack(padded_neigh_indices_list)\n\n    return padded_tensor\n\n\nclass GRNSelfAttention(torch.nn.Module):\n\n    def __init__(self, hidden_dim, n_heads):\n\n        super(GRNSelfAttention, self).__init__()\n\n        self.hidden_dim = hidden_dim\n        self.n_heads = n_heads\n\n        self.Wp = nn.Linear(hidden_dim, hidden_dim)  # embeddings to pre-concat\n        self.Wa = nn.Linear(2 * hidden_dim, hidden_dim)  # concatenation to pre-softmax\n\n        # total size = 3 * (hidden_dim) ** 2, quadratic in embedding size\n\n    def forward(self, poi, neighbors):\n        \"\"\"forward\n\n        Parameters\n        ----------\n        poi: torch.Tensor\n            A batched tensor of embedded POI vectors, (B x H) where H is the\n            embedding dimension\n        neighbors: torch.Tensor\n            A batched tensor of sequences of embedded POI vectors that are extracted\n            from an adjacency matrix (temporal or spatial neighbors of POI),\n            (B x N x H), where N is the number of neighbours of POI, B is the\n            batch size, H is the embedding dimension, and must be the same as POI\n\n        Returns\n        -------\n        tuple[torch.Tensor, torch.Tensor]\n          A tuple containing the self-attention weighted hadamard product of neighbour activations\n          in the first index, the attention weights in the second index.\n        \"\"\"\n        # assert len(poi.shape) == 2, f\"POI tensor must be 2D, got {poi.shape} instead\"\n        assert (\n            len(neighbors.shape) == 3\n        ), f\"Neighbour tensor must be 3D, got {neighbors.shape} instead\"\n\n        B, N, H = neighbors.shape\n\n        h_poi = self.Wp(poi)\n        h_n = self.Wp(neighbors)\n        h_cat = torch.cat([h_poi.expand(B, N, -1), h_n], dim=2)\n        h_att = F.leaky_relu(self.Wa(h_cat))\n\n        alpha = torch.nn.functional.softmax(h_att, dim=1)\n\n        p = torch.sum(alpha * h_n, dim=1)\n        return p, alpha","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.970176Z","iopub.status.idle":"2024-05-12T17:24:05.970671Z","shell.execute_reply.started":"2024-05-12T17:24:05.970427Z","shell.execute_reply":"2024-05-12T17:24:05.970447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GRN (Graph Recurrent Network)\nclass GRN(pl.LightningModule):\n\n    def __init__(\n        self,\n        dims: BaselineDimensions,\n        spatial_graph,\n        temporal_graph,\n        hidden_dim,\n        n_heads,\n        dropout_rate=0.9,\n        device=\"cpu\",\n    ):\n        super(GRN, self).__init__()\n        self.hidden_dim = hidden_dim\n        self.n_heads = n_heads\n        self.dims = dims\n\n        self.spatial_graph = spatial_graph.to(device)\n        self.temporal_graph = temporal_graph.to(device)\n\n        self.spatial_attn = GRNSelfAttention(hidden_dim, n_heads)\n        self.temporal_attn = GRNSelfAttention(hidden_dim, n_heads)\n\n        self.lstm = attn_LSTM(hidden_dim, hidden_dim)\n\n        self.dropout = nn.Dropout(dropout_rate)\n\n        self.user_embedding = nn.Embedding(dims.nuser, hidden_dim, padding_idx=0)\n        self.poi_embedding = nn.Embedding(dims.npoi, hidden_dim, padding_idx=0)\n        self.g2_embed = nn.Embedding(dims.g2len, hidden_dim, padding_idx=0)\n        self.g3_embed = nn.Embedding(dims.g3len, hidden_dim, padding_idx=0)\n        self.g4_embed = nn.Embedding(dims.g4len, hidden_dim, padding_idx=0)\n        self.g5_embed = nn.Embedding(dims.g5len, hidden_dim, padding_idx=0)\n        self.g6_embed = nn.Embedding(dims.g6len, hidden_dim, padding_idx=0)\n\n        self.linear_poi = nn.Linear(2 * hidden_dim, dims.npoi)\n        self.linear_g2 = nn.Linear(2 * hidden_dim, dims.g2len)\n        self.linear_g3 = nn.Linear(2 * hidden_dim, dims.g3len)\n        self.linear_g4 = nn.Linear(2 * hidden_dim, dims.g4len)\n        self.linear_g5 = nn.Linear(2 * hidden_dim, dims.g5len)\n        self.linear_g6 = nn.Linear(2 * hidden_dim, dims.g6len)\n\n        # extract indices from one-hot neighbor list\n        self.iota = torch.arange(self.dims.npoi, requires_grad=False, device=device)\n\n        self.criterion = nn.CrossEntropyLoss()\n\n        self.apply(self.init_weights)\n\n    def init_weights(self, w):\n        if type(w) == nn.Linear:\n            nn.init.kaiming_normal_(w.weight)\n            nn.init.constant_(w.bias, 0)\n        elif type(w) == nn.LSTM:\n            for name, param in w.named_parameters():\n                if \"bias\" in name:\n                    nn.init.constant_(param, 0)\n                elif \"weight\" in name:\n                    nn.init.kaiming_normal_(param)\n        elif type(w) == nn.Embedding:\n            nn.init.kaiming_normal_(w.weight)\n            nn.init.constant_(w.weight[0], 0)\n\n    def forward(self, x):\n\n        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = x\n\n        B, T = poi.shape\n\n        users = users.repeat(T, 1).T\n\n        neighbors_spatial = self.spatial_graph[poi]\n        neighbors_temporal = self.temporal_graph[poi]\n\n        e_user = self.dropout(self.user_embedding(users))\n        e_poi = self.dropout(self.poi_embedding(poi))\n        e_gap2 = self.dropout(self.g2_embed(x_geoHash2))\n        e_gap3 = self.dropout(self.g3_embed(x_geoHash3))\n        e_gap4 = self.dropout(self.g4_embed(x_geoHash4))\n        e_gap5 = self.dropout(self.g5_embed(x_geoHash5))\n        e_gap6 = self.dropout(self.g6_embed(x_geoHash6))\n\n        spatial_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n        temporal_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n\n        for b in range(B):\n            for t in range(T):\n\n                print(b, t)\n\n                spatial_neigh = neighbors_spatial[b, t] * self.iota\n                temporal_neigh = neighbors_temporal[b, t] * self.iota\n\n                spatial_neigh = spatial_neigh[spatial_neigh != 0]\n                temporal_neigh = temporal_neigh[temporal_neigh != 0]\n\n                spatial_neigh = spatial_neigh.unsqueeze(0)\n                temporal_neigh = temporal_neigh.unsqueeze(0)\n\n                e_spatial = self.dropout(self.poi_embedding(spatial_neigh))\n                e_temporal = self.dropout(self.poi_embedding(temporal_neigh))\n\n                curr_poi = e_poi[b, t].unsqueeze(0)\n\n                spatial_p, _ = self.spatial_attn(curr_poi, e_spatial)\n                temporal_p, _ = self.temporal_attn(curr_poi, e_temporal)\n\n                # we are not using the batch dimension, so we squeeze it\n                spatial_atts[b, t] = spatial_p.squeeze()\n                temporal_atts[b, t] = temporal_p.squeeze()\n\n        # zero-init LSTM states\n        h_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n        c_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n\n        h_t, c_t = self.lstm(e_poi, (h_t, c_t), spatial_atts, temporal_atts, T)\n        \n        #Note:the prediction of the poi depends on the embedding o the user\n        next_poi = self.linear_poi(torch.cat((h_t, e_user), dim=2))\n        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n\n        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        (\n            poi_pred,\n            gap2_pred,\n            gap3_pred,\n            gap4_pred,\n            gap5_pred,\n            gap6_pred,\n        ) = self(x)\n\n        loss_poi = self.criterion(\n            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n        )\n        loss_gap2 = self.criterion(\n            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n        )\n        loss_gap3 = self.criterion(\n            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n        )\n        loss_gap4 = self.criterion(\n            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n        )\n        loss_gap5 = self.criterion(\n            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n        )\n        loss_gap6 = self.criterion(\n            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n        )\n\n        loss = (\n            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n        ) / 6\n        self.log(\"train/loss\", loss)\n        self.log(\"train/loss_gap2\", loss_gap2)\n        self.log(\"train/loss_gap3\", loss_gap3)\n        self.log(\"train/loss_gap4\", loss_gap4)\n        self.log(\"train/loss_gap5\", loss_gap5)\n        self.log(\"train/loss_gap6\", loss_gap6)\n        self.log(\"train/loss_poi\", loss_poi)\n\n        return {\"loss\": loss}\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        (\n            poi_pred,\n            gap2_pred,\n            gap3_pred,\n            gap4_pred,\n            gap5_pred,\n            gap6_pred,\n        ) = self(x)\n\n        loss_poi = self.criterion(\n            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n        )\n        loss_gap2 = self.criterion(\n            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n        )\n        loss_gap3 = self.criterion(\n            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n        )\n        loss_gap4 = self.criterion(\n            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n        )\n        loss_gap5 = self.criterion(\n            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n        )\n        loss_gap6 = self.criterion(\n            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n        )\n\n        loss = (\n            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n        ) / 6\n\n        self.log(\"val/loss\", loss)\n        self.log(\"val/loss_gap2\", loss_gap2)\n        self.log(\"val/loss_gap3\", loss_gap3)\n        self.log(\"val/loss_gap4\", loss_gap4)\n        self.log(\"val/loss_gap5\", loss_gap5)\n        self.log(\"val/loss_gap6\", loss_gap6)\n        self.log(\"val/loss_poi\", loss_poi)\n\n        return loss\n\n    def configure_optimizers(self):\n        # Define optimizer and scheduler\n        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.972508Z","iopub.status.idle":"2024-05-12T17:24:05.972959Z","shell.execute_reply.started":"2024-05-12T17:24:05.972722Z","shell.execute_reply":"2024-05-12T17:24:05.972741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Loops","metadata":{}},{"cell_type":"code","source":"n_users = encoder_dict[\"users\"].classes_.shape[0]\nn_pois = encoder_dict[\"pois\"].classes_.shape[0]\nn_g2 = encoder_dict[\"g2\"].classes_.shape[0]\nn_g3 = encoder_dict[\"g3\"].classes_.shape[0]\nn_g4 = encoder_dict[\"g4\"].classes_.shape[0]\nn_g5 = encoder_dict[\"g5\"].classes_.shape[0]\nn_g6 = encoder_dict[\"g6\"].classes_.shape[0]\n\n\n# account for the padding token\ndims = BaselineDimensions(\n    n_users + 1, n_pois + 1, n_g2 + 1, n_g3 + 1, n_g4 + 1, n_g5 + 1, n_g6 + 1\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.974293Z","iopub.status.idle":"2024-05-12T17:24:05.974729Z","shell.execute_reply.started":"2024-05-12T17:24:05.974505Z","shell.execute_reply":"2024-05-12T17:24:05.974523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from lightning.pytorch.loggers import WandbLogger\nfrom lightning.pytorch import Trainer\n\nTRAIN_BASELINE = True\n\nwandb.finish()\ntorch.cuda.empty_cache()\n# cargo-cult like stuff that is supposed to make you faster\ntorch.set_float32_matmul_precision(\"medium\")\ntorch.backends.cudnn.benchmark = True\n\nds = CheckinModule(encoded_data, batch_size=32, workers=4)\n\nwandb.init(project=\"trovailpoi\")\n\nclassifier_baseline = HMT_RN(dims, embedding_dim=1024, lstm_hidden_dim=1024)\nwandb_logger = WandbLogger(project=\"trovailpoi\")\ntrainer = Trainer(\n    max_epochs=40,\n    accelerator=\"auto\",\n    devices=[0],\n    log_every_n_steps=10,\n    logger=wandb_logger,\n    strategy=\"auto\",\n    callbacks=[\n        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n        torchpl.callbacks.ModelCheckpoint(\n            monitor=\"val/loss\",\n            mode=\"min\",\n            save_top_k=1,\n            save_last=True,\n            filename=\"best_model\",\n        ),\n        torchpl.callbacks.EarlyStopping(\n            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n        ),\n    ],\n)\n\nif TRAIN_BASELINE:\n    trainer.fit(model=classifier_baseline, datamodule=ds)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.976446Z","iopub.status.idle":"2024-05-12T17:24:05.976757Z","shell.execute_reply.started":"2024-05-12T17:24:05.976604Z","shell.execute_reply":"2024-05-12T17:24:05.976617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_GNN = False\n\nbatch_size = 60\nwandb.finish()\ntorch.cuda.empty_cache()\n# cargo-cult like stuff that is supposed to make you faster\ntorch.set_float32_matmul_precision(\"medium\")\ntorch.backends.cudnn.benchmark = True\n\nwandb.init(project=\"trovailpoi\")\n\nclassifier_gnn = GRN(\n    dims,\n    spatial_graph,\n    temporal_graph,\n    hidden_dim=1024,\n    n_heads=1,\n    dropout_rate=0.9,\n    device=device,\n)\nwandb_logger = WandbLogger(project=\"trovailpoi\")\ntrainer = Trainer(\n    max_epochs=40,\n    accelerator=\"auto\",\n    devices=[0],\n    log_every_n_steps=10,\n    logger=wandb_logger,\n    strategy=\"auto\",\n    callbacks=[\n        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n        torchpl.callbacks.ModelCheckpoint(\n            monitor=\"val/loss\",\n            mode=\"min\",\n            save_top_k=1,\n            save_last=True,\n            filename=\"best_model\",\n        ),\n        torchpl.callbacks.EarlyStopping(\n            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n        ),\n    ],\n)\n\nif TRAIN_GNN:\n    trainer.fit(model=classifier_gnn, datamodule=ds)\nwandb.finish()","metadata":{"execution":{"iopub.status.busy":"2024-05-12T17:24:05.977696Z","iopub.status.idle":"2024-05-12T17:24:05.978051Z","shell.execute_reply.started":"2024-05-12T17:24:05.977878Z","shell.execute_reply":"2024-05-12T17:24:05.977893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scrapbook for Experimentation\n\nIgnore all code below, it's just for quick prototyping","metadata":{}}]}