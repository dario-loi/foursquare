{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8383172,
          "sourceType": "datasetVersion",
          "datasetId": 4985565
        },
        {
          "sourceId": 8438278,
          "sourceType": "datasetVersion",
          "datasetId": 5026368
        },
        {
          "sourceId": 8477386,
          "sourceType": "datasetVersion",
          "datasetId": 5055834
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Foursquare dataset next-POI Recommendation System"
      ],
      "metadata": {
        "id": "SwkFEsEgCCyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First off we import all the necessary libraries:"
      ],
      "metadata": {
        "id": "MZnW-ffHCCym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " %pip install lightning geohash2 wandb folium shapely geopandas polars==0.20.25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ML-ffMMCCyn",
        "outputId": "c97a86e6-e034-47f2-f488-6e6d542f70fd",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:20:06.693793Z",
          "iopub.execute_input": "2024-05-26T11:20:06.694506Z",
          "iopub.status.idle": "2024-05-26T11:20:37.773009Z",
          "shell.execute_reply.started": "2024-05-26T11:20:06.694474Z",
          "shell.execute_reply": "2024-05-26T11:20:37.771897Z"
        },
        "trusted": true
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightning in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: geohash2 in /usr/local/lib/python3.10/dist-packages (1.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.4)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: polars==0.20.25 in /usr/local/lib/python3.10/dist-packages (0.20.25)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.11.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.25.2)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.0)\n",
            "Requirement already satisfied: torch<4.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.4.0.post0)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.11.0)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.2.5)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.10/dist-packages (from geohash2) (0.18.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.3.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from folium) (0.7.2)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from folium) (3.1.4)\n",
            "Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from geopandas) (1.9.6)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from geopandas) (2.0.3)\n",
            "Requirement already satisfied: pyproj>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from geopandas) (3.6.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (2024.2.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (1.1.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->geopandas) (0.7.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9->folium) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->geopandas) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=1.13.0->lightning) (12.5.40)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api= 'AIzaSyBd9ZVFElqGM4rC1ea2NvaulY29Wco8LZs'\n",
        "\n",
        "!wget -O  dataset_TIST2015_Checkins.txt \"https://www.googleapis.com/drive/v3/files/1ENaKCJH5pg8HKZmhytD6trJQVWzGTGdJ?alt=media&key=AIzaSyBd9ZVFElqGM4rC1ea2NvaulY29Wco8LZs\"\n",
        "\n",
        "!wget -O  dataset_TIST2015_POIs.txt \"https://www.googleapis.com/drive/v3/files/1-ETaa09-WeRal0xhCELNCNLSyupO7DQt?alt=media&key=AIzaSyBd9ZVFElqGM4rC1ea2NvaulY29Wco8LZs\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddXySLCetol-",
        "outputId": "37157470-127e-471d-f684-10d5317356b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-27 08:15:27--  https://www.googleapis.com/drive/v3/files/1ENaKCJH5pg8HKZmhytD6trJQVWzGTGdJ?alt=media&key=AIzaSyBd9ZVFElqGM4rC1ea2NvaulY29Wco8LZs\n",
            "Resolving www.googleapis.com (www.googleapis.com)... 74.125.68.95, 64.233.170.95, 142.251.175.95, ...\n",
            "Connecting to www.googleapis.com (www.googleapis.com)|74.125.68.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2211496762 (2.1G) [text/plain]\n",
            "Saving to: ‘dataset_TIST2015_Checkins.txt’\n",
            "\n",
            "                     50%[=========>          ]   1.03G   140MB/s    eta 9s     "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import polars as rs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import lightning as pl\n",
        "import lightning.pytorch as torchpl\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from dataclasses import dataclass\n",
        "import wandb\n",
        "from rich import print"
      ],
      "metadata": {
        "id": "Z8xK-4YqCCyn",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:20:46.158952Z",
          "iopub.execute_input": "2024-05-26T11:20:46.159274Z",
          "iopub.status.idle": "2024-05-26T11:20:54.236523Z",
          "shell.execute_reply.started": "2024-05-26T11:20:46.159227Z",
          "shell.execute_reply": "2024-05-26T11:20:54.235309Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# define WANDB_NOTEBOOK_NAME\n",
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train.ipynb\""
      ],
      "metadata": {
        "id": "FoCozR1YCCyo",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:20:54.238313Z",
          "iopub.execute_input": "2024-05-26T11:20:54.238648Z",
          "iopub.status.idle": "2024-05-26T11:20:54.243226Z",
          "shell.execute_reply.started": "2024-05-26T11:20:54.238609Z",
          "shell.execute_reply": "2024-05-26T11:20:54.242388Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "# clean CUDA memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# sometimes jupyter notebook does not release memory, we leave this here so a run-all\n",
        "# can *sometimes* fix leaks"
      ],
      "metadata": {
        "id": "Yq1AScVfCCyo",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:20:54.244475Z",
          "iopub.execute_input": "2024-05-26T11:20:54.244834Z",
          "iopub.status.idle": "2024-05-26T11:20:54.514546Z",
          "shell.execute_reply.started": "2024-05-26T11:20:54.244801Z",
          "shell.execute_reply": "2024-05-26T11:20:54.513494Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we load the data, we utilize `polars` since it is much more efficient than `pandas` and can handle large datasets with ease."
      ],
      "metadata": {
        "id": "Z402h6bPCCyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"user\", \"poi\", \"date\", \"TZ\"]\n",
        "\n",
        "DATASET_PATH = \"/content/dataset_TIST2015_Checkins.txt\"\n",
        "\n",
        "data = rs.read_csv(\n",
        "    DATASET_PATH,\n",
        "    has_header=False,\n",
        "    low_memory=True,\n",
        "    separator=\"\\t\",\n",
        ")\n",
        "data.columns = columns"
      ],
      "metadata": {
        "id": "1F7L_QPkCCyo",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:20:57.392323Z",
          "iopub.execute_input": "2024-05-26T11:20:57.393187Z",
          "iopub.status.idle": "2024-05-26T11:21:10.272010Z",
          "shell.execute_reply.started": "2024-05-26T11:20:57.393153Z",
          "shell.execute_reply": "2024-05-26T11:21:10.271118Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "9M6JBXPwBOma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differently from what suggested by the professor, we utilize the full TIST2015 dataset, which has a far greater scale compared to the reduced NY one. However, by following the pruning steps detailed in the paper (http://dx.doi.org/10.1145/3477495.3531989, section 5.1), we obtain sequences that are much smaller in size, resulting in a dataset that is usable on Google Colab's free tier (as required by the assignment)."
      ],
      "metadata": {
        "id": "AE8Cxd2PCCyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_users = (\n",
        "    data.lazy()\n",
        "    .group_by(\"user\")\n",
        "    .agg(\n",
        "        [\n",
        "            rs.col(\"poi\").n_unique().alias(\"n_pois\"),\n",
        "            rs.col(\"poi\").count().alias(\"n_checkins\"),\n",
        "            # turn the rest into a list\n",
        "            rs.col(\"poi\").alias(\"pois\"),\n",
        "            rs.col(\"date\").alias(\"dates\"),\n",
        "            rs.col(\"TZ\").alias(\"TZs\"),\n",
        "        ]\n",
        "    )\n",
        ").collect()"
      ],
      "metadata": {
        "id": "YqLUIt0cCCyo",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:21:13.241577Z",
          "iopub.execute_input": "2024-05-26T11:21:13.242225Z",
          "iopub.status.idle": "2024-05-26T11:21:18.315387Z",
          "shell.execute_reply.started": "2024-05-26T11:21:13.242195Z",
          "shell.execute_reply": "2024-05-26T11:21:18.314370Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_users.describe()"
      ],
      "metadata": {
        "id": "HptthFauCCyo",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:21:18.317134Z",
          "iopub.execute_input": "2024-05-26T11:21:18.317522Z",
          "iopub.status.idle": "2024-05-26T11:21:18.345373Z",
          "shell.execute_reply.started": "2024-05-26T11:21:18.317489Z",
          "shell.execute_reply": "2024-05-26T11:21:18.344312Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "VqJjYuF1CCyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_culled = data_users.filter(\n",
        "    (rs.col(\"n_checkins\") > 20) & (rs.col(\"n_checkins\") < 50)\n",
        ").drop_nulls()"
      ],
      "metadata": {
        "id": "SxCtvTymCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:02.888818Z",
          "iopub.execute_input": "2024-05-26T11:22:02.889204Z",
          "iopub.status.idle": "2024-05-26T11:22:02.909057Z",
          "shell.execute_reply.started": "2024-05-26T11:22:02.889173Z",
          "shell.execute_reply": "2024-05-26T11:22:02.908298Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the original dataset is huge, we delete it and call the python garbage collector to free up memory. We then proceed with the second pruning step (frequency-based pruning) as detailed in the paper."
      ],
      "metadata": {
        "id": "rAqugUVTCCyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del data\n",
        "del data_users\n",
        "\n",
        "import gc\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Vc26KLj7CCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:03.494929Z",
          "iopub.execute_input": "2024-05-26T11:22:03.495264Z",
          "iopub.status.idle": "2024-05-26T11:22:03.751152Z",
          "shell.execute_reply.started": "2024-05-26T11:22:03.495228Z",
          "shell.execute_reply": "2024-05-26T11:22:03.750223Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print lengths\n",
        "\n",
        "print(data_culled[\"pois\"].list.len().min(), data_culled[\"pois\"].list.len().max())"
      ],
      "metadata": {
        "id": "mcWNAa-HaItt",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:03.883574Z",
          "iopub.execute_input": "2024-05-26T11:22:03.883891Z",
          "iopub.status.idle": "2024-05-26T11:22:03.895506Z",
          "shell.execute_reply.started": "2024-05-26T11:22:03.883866Z",
          "shell.execute_reply": "2024-05-26T11:22:03.894516Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract unique elements from each lists in data_culled[\"pois\"]\n",
        "out = data_culled.with_columns(\n",
        "    [\n",
        "        rs.col(\"pois\").list.unique(),\n",
        "        rs.col(\"pois\").list.unique().list.len().alias(\"n_unique_pois\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "t9jLArwDCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:04.312634Z",
          "iopub.execute_input": "2024-05-26T11:22:04.313454Z",
          "iopub.status.idle": "2024-05-26T11:22:04.442127Z",
          "shell.execute_reply.started": "2024-05-26T11:22:04.313424Z",
          "shell.execute_reply": "2024-05-26T11:22:04.441142Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "id": "xmWP2h6uCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:04.748350Z",
          "iopub.execute_input": "2024-05-26T11:22:04.748678Z",
          "iopub.status.idle": "2024-05-26T11:22:04.756842Z",
          "shell.execute_reply.started": "2024-05-26T11:22:04.748649Z",
          "shell.execute_reply": "2024-05-26T11:22:04.755982Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = out[\"pois\"][0].to_list()\n",
        "len(set(l))  # print number of unique POIs in first sequence"
      ],
      "metadata": {
        "id": "BTYdomCBCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:05.575531Z",
          "iopub.execute_input": "2024-05-26T11:22:05.575871Z",
          "iopub.status.idle": "2024-05-26T11:22:05.581986Z",
          "shell.execute_reply.started": "2024-05-26T11:22:05.575844Z",
          "shell.execute_reply": "2024-05-26T11:22:05.581082Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2 = data_culled[\"pois\"][0].to_list()\n",
        "len(l2)  # print sequence length of first user"
      ],
      "metadata": {
        "id": "3ZvejeoKCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:06.007099Z",
          "iopub.execute_input": "2024-05-26T11:22:06.007847Z",
          "iopub.status.idle": "2024-05-26T11:22:06.013230Z",
          "shell.execute_reply.started": "2024-05-26T11:22:06.007818Z",
          "shell.execute_reply": "2024-05-26T11:22:06.012290Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(l2))  # confirm that the two match"
      ],
      "metadata": {
        "id": "8f24-SOxCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:06.362537Z",
          "iopub.execute_input": "2024-05-26T11:22:06.363083Z",
          "iopub.status.idle": "2024-05-26T11:22:06.369470Z",
          "shell.execute_reply.started": "2024-05-26T11:22:06.363056Z",
          "shell.execute_reply": "2024-05-26T11:22:06.368418Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run a Polars query to obtain all the frequent POIs, the ones expected to survive the filtering\n",
        "unique_pois = out[\"pois\"]\n",
        "frequent_pois = unique_pois.list.explode().value_counts().filter(rs.col(\"count\") >= 10)"
      ],
      "metadata": {
        "id": "i51vz46MCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:06.857431Z",
          "iopub.execute_input": "2024-05-26T11:22:06.857942Z",
          "iopub.status.idle": "2024-05-26T11:22:06.997847Z",
          "shell.execute_reply.started": "2024-05-26T11:22:06.857915Z",
          "shell.execute_reply": "2024-05-26T11:22:06.996789Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_pois"
      ],
      "metadata": {
        "id": "7aHVCPtcCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:07.358850Z",
          "iopub.execute_input": "2024-05-26T11:22:07.359183Z",
          "iopub.status.idle": "2024-05-26T11:22:07.368380Z",
          "shell.execute_reply.started": "2024-05-26T11:22:07.359155Z",
          "shell.execute_reply": "2024-05-26T11:22:07.367552Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_pois = frequent_pois[\"pois\"]\n",
        "frequent_pois = set(frequent_pois.to_list())"
      ],
      "metadata": {
        "id": "34H0_RIbCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:08.125019Z",
          "iopub.execute_input": "2024-05-26T11:22:08.125515Z",
          "iopub.status.idle": "2024-05-26T11:22:08.133209Z",
          "shell.execute_reply.started": "2024-05-26T11:22:08.125479Z",
          "shell.execute_reply": "2024-05-26T11:22:08.132231Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_culled"
      ],
      "metadata": {
        "id": "ib_qORq7CCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:08.564226Z",
          "iopub.execute_input": "2024-05-26T11:22:08.564575Z",
          "iopub.status.idle": "2024-05-26T11:22:08.572707Z",
          "shell.execute_reply.started": "2024-05-26T11:22:08.564547Z",
          "shell.execute_reply": "2024-05-26T11:22:08.571734Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_culled = data_culled.with_columns(\n",
        "    [\n",
        "        rs.col(\"pois\")\n",
        "        .list.eval(\n",
        "            rs.element().is_in(frequent_pois),\n",
        "        )\n",
        "        .alias(\"is_frequent\")\n",
        "    ]\n",
        ")  # prep mask"
      ],
      "metadata": {
        "id": "n5IdbHrNCCyp",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:09.093190Z",
          "iopub.execute_input": "2024-05-26T11:22:09.093534Z",
          "iopub.status.idle": "2024-05-26T11:22:09.136596Z",
          "shell.execute_reply.started": "2024-05-26T11:22:09.093507Z",
          "shell.execute_reply": "2024-05-26T11:22:09.135898Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = (\n",
        "    data_culled.lazy()\n",
        "    .explode(\n",
        "        [\n",
        "            \"pois\",\n",
        "            \"dates\",\n",
        "            \"TZs\",\n",
        "            \"is_frequent\",\n",
        "        ]\n",
        "    )\n",
        "    .group_by(\"user\")\n",
        "    .agg(\n",
        "        [\n",
        "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).alias(\"pois\"),\n",
        "            rs.col(\"dates\").filter(rs.col(\"is_frequent\")).alias(\"dates\"),\n",
        "            rs.col(\"TZs\").filter(rs.col(\"is_frequent\")).alias(\"TZs\"),\n",
        "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).n_unique().alias(\"n_pois\"),\n",
        "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).count().alias(\"n_checkins\"),\n",
        "        ]\n",
        "    )\n",
        "    .filter(rs.col(\"n_checkins\") > 0)\n",
        "    .filter(rs.col(\"n_pois\") > 0)\n",
        "    .collect()\n",
        ")  # filter out infrequent pois and users with no pois"
      ],
      "metadata": {
        "id": "rpFQCNJGCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:09.563590Z",
          "iopub.execute_input": "2024-05-26T11:22:09.563961Z",
          "iopub.status.idle": "2024-05-26T11:22:09.744432Z",
          "shell.execute_reply.started": "2024-05-26T11:22:09.563932Z",
          "shell.execute_reply": "2024-05-26T11:22:09.743417Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data.describe()"
      ],
      "metadata": {
        "id": "CS0MglAhCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:10.020412Z",
          "iopub.execute_input": "2024-05-26T11:22:10.020735Z",
          "iopub.status.idle": "2024-05-26T11:22:10.031433Z",
          "shell.execute_reply.started": "2024-05-26T11:22:10.020709Z",
          "shell.execute_reply": "2024-05-26T11:22:10.030529Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this stage, culling is done, we can appreciate that `polars`'s SQL/functional-style API is different from Pandas, but it is very powerful and efficient."
      ],
      "metadata": {
        "id": "ItBEF5DFCCyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is geohashing the POIs, that is, we want to convert the latitude-longitude positions of the POIs into a grid-based geohash representation, which will form the basis for our network's embeddings."
      ],
      "metadata": {
        "id": "HxS9E5bBCCyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geohash2 as gh\n",
        "\n",
        "POI_DATASET = \"/content/dataset_TIST2015_POIs.txt\"\n",
        "\n",
        "pois = rs.read_csv(\n",
        "    POI_DATASET,\n",
        "    has_header=False,\n",
        "    low_memory=True,\n",
        "    separator=\"\\t\",\n",
        ")\n",
        "pois.columns = [\"poi\", \"lat\", \"long\", \"category\", \"country\"]\n",
        "pois = pois.drop(\"category\").drop(\"country\")"
      ],
      "metadata": {
        "id": "5tSt9gYqCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:12.119609Z",
          "iopub.execute_input": "2024-05-26T11:22:12.119942Z",
          "iopub.status.idle": "2024-05-26T11:22:13.531807Z",
          "shell.execute_reply.started": "2024-05-26T11:22:12.119916Z",
          "shell.execute_reply": "2024-05-26T11:22:13.530775Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from folium import plugins\n",
        "from shapely.geometry import Point\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt#\n",
        "\n",
        "geometry = [Point(lon, lat) for lon, lat in zip(pois[\"long\"], pois[\"lat\"])]\n",
        "gdf = gpd.GeoDataFrame(pois, geometry=geometry, crs=\"EPSG:4326\")\n",
        "\n",
        "# Crea una mappa di sfondo\n",
        "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
        "n_pois=pois[\"poi\"].n_unique()\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "world.boundary.plot(ax=ax, linewidth=1)\n",
        "gdf.plot(ax=ax, markersize=8, color=\"red\", alpha=0.5, legend=True)\n",
        "plt.text(-180, -90, f\"Number of POIs: {n_pois}\", fontsize=14, backgroundcolor=\"white\", bbox=dict(facecolor=\"white\", alpha=1))\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-26T11:22:17.771349Z",
          "iopub.execute_input": "2024-05-26T11:22:17.771694Z",
          "iopub.status.idle": "2024-05-26T11:32:18.482051Z",
          "shell.execute_reply.started": "2024-05-26T11:22:17.771668Z",
          "shell.execute_reply": "2024-05-26T11:32:18.481100Z"
        },
        "trusted": true,
        "id": "j_c87j36spNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pois"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-26T11:32:58.876500Z",
          "iopub.execute_input": "2024-05-26T11:32:58.877228Z",
          "iopub.status.idle": "2024-05-26T11:32:58.884218Z",
          "shell.execute_reply.started": "2024-05-26T11:32:58.877194Z",
          "shell.execute_reply": "2024-05-26T11:32:58.883300Z"
        },
        "trusted": true,
        "id": "YkkbKuZ3spNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pois = (\n",
        "    pois.lazy()\n",
        "    .filter(rs.col(\"poi\").is_in(frequent_pois))\n",
        "    .select(\n",
        "        [\n",
        "            rs.col(\"poi\"),\n",
        "            rs.struct(\n",
        "                [\n",
        "                    rs.col(\"lat\").cast(rs.Float32),\n",
        "                    rs.col(\"long\").cast(rs.Float32),\n",
        "                ]\n",
        "            )\n",
        "            .alias(\"location\")\n",
        "            .map_elements(\n",
        "                lambda s: gh.encode(s[\"lat\"], s[\"long\"], precision=6),\n",
        "                return_dtype=rs.String,\n",
        "            )\n",
        "            .alias(\"geohash\"),\n",
        "        ]\n",
        "    )\n",
        "    .collect()\n",
        ")\n",
        "poi_geo_dict = dict(zip(pois[\"poi\"], pois[\"geohash\"]))"
      ],
      "metadata": {
        "id": "fa3YSEGrCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:32:59.674979Z",
          "iopub.execute_input": "2024-05-26T11:32:59.675818Z",
          "iopub.status.idle": "2024-05-26T11:32:59.941485Z",
          "shell.execute_reply.started": "2024-05-26T11:32:59.675780Z",
          "shell.execute_reply": "2024-05-26T11:32:59.940674Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show the final data on the map\n",
        "#decode lat and long from geohash\n",
        "def decode_geohash(geohash):\n",
        "    lat, long = gh.decode(geohash)\n",
        "    return long, lat\n",
        "\n",
        "SAVE_PLOT = False\n",
        "\n",
        "geometry = [Point(float(lon), float(lat)) for lon, lat in map(decode_geohash, poi_geo_dict.values())]\n",
        "gdf = gpd.GeoDataFrame(pois, geometry=geometry, crs=\"EPSG:4326\")\n",
        "\n",
        "# # Crea una mappa di sfondo\n",
        "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
        "\n",
        "# print number of unique POIs\n",
        "n_pois=pois[\"poi\"].n_unique()\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "world.boundary.plot(ax=ax, linewidth=1)\n",
        "gdf.plot(ax=ax, markersize=8, color=\"red\", alpha=0.5, legend=True)\n",
        "plt.text(-180, -90, f\"Number of POIs: {n_pois}\", fontsize=14, backgroundcolor=\"white\", bbox=dict(facecolor=\"white\", alpha=1))\n",
        "plt.show()\n",
        "\n",
        "if SAVE_PLOT:\n",
        "    plt.savefig(\"report/poi_after_processing\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-26T11:36:12.722664Z",
          "iopub.execute_input": "2024-05-26T11:36:12.723385Z",
          "iopub.status.idle": "2024-05-26T11:36:13.960620Z",
          "shell.execute_reply.started": "2024-05-26T11:36:12.723354Z",
          "shell.execute_reply": "2024-05-26T11:36:13.959653Z"
        },
        "trusted": true,
        "id": "k2A07PXqspNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each row in final_data, add the geohash of the pois by hitting the poi_geo_dict\n",
        "\n",
        "final_data = final_data.with_columns(\n",
        "    [\n",
        "        rs.col(\"pois\")\n",
        "        .map_elements(\n",
        "            lambda s: [poi_geo_dict[s] for s in s],\n",
        "            return_dtype=rs.List(rs.String),\n",
        "        )\n",
        "        .alias(\"geohashes\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "y1GevNOtCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-26T11:36:13.962440Z",
          "iopub.execute_input": "2024-05-26T11:36:13.962764Z",
          "iopub.status.idle": "2024-05-26T11:36:14.475860Z",
          "shell.execute_reply.started": "2024-05-26T11:36:13.962737Z",
          "shell.execute_reply": "2024-05-26T11:36:14.475064Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "geometry = [Point(float(lon), float(lat)) for lon, lat in map(decode_geohash, final_data[\"geohashes\"].explode())]\n",
        "gdf = gpd.GeoDataFrame(final_data[\"geohashes\"].explode(), geometry=geometry, crs=\"EPSG:4326\")\n",
        "\n",
        "# Crea una mappa di sfondo\n",
        "world = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
        "\n",
        "# Plotta i punti sullo sfondo della mappa\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "world.boundary.plot(ax=ax, linewidth=1)\n",
        "gdf.plot(ax=ax, markersize=10, color=\"red\", alpha=0.5, legend=True)\n",
        "plt.title(\"Dataset Division based on GeoPandas\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-26T11:39:05.808204Z",
          "iopub.execute_input": "2024-05-26T11:39:05.808611Z",
          "iopub.status.idle": "2024-05-26T11:39:41.162775Z",
          "shell.execute_reply.started": "2024-05-26T11:39:05.808578Z",
          "shell.execute_reply": "2024-05-26T11:39:41.161877Z"
        },
        "trusted": true,
        "id": "wuqH8xLbspNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data[\"dates\"][79].to_list()  # check out a temporal sequence"
      ],
      "metadata": {
        "id": "qaXNXfVfCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:03:51.940011Z",
          "iopub.execute_input": "2024-05-25T18:03:51.941103Z",
          "iopub.status.idle": "2024-05-25T18:03:51.947915Z",
          "shell.execute_reply.started": "2024-05-25T18:03:51.941055Z",
          "shell.execute_reply": "2024-05-25T18:03:51.946909Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data[\"TZs\"][79].to_list()  # ... and the corresponding timezones"
      ],
      "metadata": {
        "id": "BenJc82OCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:03:52.154436Z",
          "iopub.execute_input": "2024-05-25T18:03:52.154760Z",
          "iopub.status.idle": "2024-05-25T18:03:52.161232Z",
          "shell.execute_reply.started": "2024-05-25T18:03:52.154735Z",
          "shell.execute_reply": "2024-05-25T18:03:52.160401Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The work *might* seem over, however, we still have timezones to account for, we want to normalize everything according to GMT, so we convert the timestamps accordingly."
      ],
      "metadata": {
        "id": "Vkv4I9FhCCyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "\n",
        "def UTC_to_local(utc, tz):\n",
        "\n",
        "    date = datetime.datetime.strptime(utc, \"%a %b %d %H:%M:%S %z %Y\")\n",
        "    date = date.replace(tzinfo=datetime.timezone.utc)\n",
        "\n",
        "    # shift by tz offset\n",
        "    date = date.astimezone(datetime.timezone(datetime.timedelta(minutes=tz)))\n",
        "\n",
        "    date_s = datetime.datetime.strftime(date, \"%Y-%m-%d %H:%M:%S\")\n",
        "    return date_s\n",
        "\n",
        "\n",
        "def to_UNIX_time(date):\n",
        "    return datetime.datetime.strptime(\n",
        "        date, \"%Y-%m-%d %H:%M:%S\"\n",
        "    ).timestamp()  # we use UNIX time as a key for sorting the POIs in our polars query"
      ],
      "metadata": {
        "id": "ufyhRTJMCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:03:52.632672Z",
          "iopub.execute_input": "2024-05-25T18:03:52.632996Z",
          "iopub.status.idle": "2024-05-25T18:03:52.639284Z",
          "shell.execute_reply.started": "2024-05-25T18:03:52.632972Z",
          "shell.execute_reply": "2024-05-25T18:03:52.638239Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UTC_to_local(\"Mon May 21 15:53:01 +0000 2012\", -420)  # example of usage"
      ],
      "metadata": {
        "id": "P1n-YGXLCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:03:52.910161Z",
          "iopub.execute_input": "2024-05-25T18:03:52.910906Z",
          "iopub.status.idle": "2024-05-25T18:03:52.916523Z",
          "shell.execute_reply.started": "2024-05-25T18:03:52.910880Z",
          "shell.execute_reply": "2024-05-25T18:03:52.915546Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = final_data.with_columns(\n",
        "    [\n",
        "        rs.struct([rs.col(\"dates\"), rs.col(\"TZs\")])\n",
        "        .alias(\"times\")\n",
        "        .map_elements(\n",
        "            lambda struct: [\n",
        "                UTC_to_local(date, tz)\n",
        "                for date, tz in zip(struct[\"dates\"], struct[\"TZs\"])\n",
        "            ],\n",
        "            return_dtype=rs.List(rs.String),\n",
        "        )\n",
        "    ]\n",
        ")  # This performs timezone conversion"
      ],
      "metadata": {
        "id": "-QJbyPkeCCyq",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:03:53.127180Z",
          "iopub.execute_input": "2024-05-25T18:03:53.127999Z",
          "iopub.status.idle": "2024-05-25T18:04:05.272682Z",
          "shell.execute_reply.started": "2024-05-25T18:03:53.127965Z",
          "shell.execute_reply": "2024-05-25T18:04:05.271708Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_sorted = final_data.select(  # sort the times\n",
        "    [\n",
        "        rs.col(\"user\"),\n",
        "        rs.struct(\n",
        "            [\n",
        "                rs.col(\"pois\"),\n",
        "                rs.col(\"times\"),\n",
        "            ]\n",
        "        ).map_elements(\n",
        "            lambda struct: [\n",
        "                poi\n",
        "                for poi, _ in sorted(\n",
        "                    zip(  # here we sort the POIs struct by UNIX timestamps of the GMT times\n",
        "                        struct[\"pois\"], [to_UNIX_time(date) for date in struct[\"times\"]]\n",
        "                    ),\n",
        "                    key=lambda s: s[1],\n",
        "                )\n",
        "            ],\n",
        "            return_dtype=rs.List(rs.String),\n",
        "        ),\n",
        "        rs.struct(\n",
        "            [\n",
        "                rs.col(\"geohashes\"),\n",
        "                rs.col(\"times\"),\n",
        "            ]\n",
        "        ).map_elements(\n",
        "            lambda struct: [\n",
        "                geo\n",
        "                for geo, _ in sorted(\n",
        "                    zip(\n",
        "                        struct[\"geohashes\"],  # same thing goes on for geohashes\n",
        "                        [to_UNIX_time(date) for date in struct[\"times\"]],\n",
        "                    ),\n",
        "                    key=lambda s: s[1],\n",
        "                )\n",
        "            ],\n",
        "            return_dtype=rs.List(rs.String),\n",
        "        ),\n",
        "        rs.col(\"times\")\n",
        "        .map_elements(\n",
        "            lambda dates: sorted(dates, key=to_UNIX_time),\n",
        "            return_dtype=rs.List(rs.String),\n",
        "        )\n",
        "        .alias(\"times_sorted\"),\n",
        "        rs.col(\"n_checkins\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# P.S, admittedly, it would have been more efficient to encode the geohashes *after* sorting the POIs,\n",
        "# so that we could save on the sorting of the geohashes. Tough luck, you can't win 'em all."
      ],
      "metadata": {
        "id": "mI9bmD3UCCyt",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:04:05.274392Z",
          "iopub.execute_input": "2024-05-25T18:04:05.274683Z",
          "iopub.status.idle": "2024-05-25T18:04:29.984072Z",
          "shell.execute_reply.started": "2024-05-25T18:04:05.274660Z",
          "shell.execute_reply": "2024-05-25T18:04:29.983265Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_sorted"
      ],
      "metadata": {
        "id": "8I9t4dirCCyt",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:04:29.985122Z",
          "iopub.execute_input": "2024-05-25T18:04:29.985405Z",
          "iopub.status.idle": "2024-05-25T18:04:29.993157Z",
          "shell.execute_reply.started": "2024-05-25T18:04:29.985381Z",
          "shell.execute_reply": "2024-05-25T18:04:29.992160Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we now need to obtain a dataframe containing: each POI, it's geohash, and a set of all the check-ins it appears in\n",
        "this is just one `polars` query away!"
      ],
      "metadata": {
        "id": "w-uFPvXPCCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pois_checkins = final_sorted.explode([\"pois\", \"geohashes\"]).drop(\"n_checkins\")\n",
        "\n",
        "pois_checkins = (\n",
        "    pois_checkins.with_columns(\n",
        "        [\n",
        "            rs.col(\"geohashes\").map_elements(lambda s: s[:4], rs.String).alias(\"g4\"),\n",
        "        ]\n",
        "    )\n",
        "    .drop(\"geohashes\")\n",
        "    .group_by([\"pois\", \"g4\"])\n",
        "    .agg([rs.col(\"times_sorted\").flatten().alias(\"checkin_times\")])\n",
        ")"
      ],
      "metadata": {
        "id": "_nS1s8GECCyt",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:04:29.995132Z",
          "iopub.execute_input": "2024-05-25T18:04:29.995519Z",
          "iopub.status.idle": "2024-05-25T18:04:30.442043Z",
          "shell.execute_reply.started": "2024-05-25T18:04:29.995494Z",
          "shell.execute_reply": "2024-05-25T18:04:30.441029Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pois_checkins  # with this we can *efficiently* build our POI-POI spatial-temporal graphs"
      ],
      "metadata": {
        "id": "U-2qN1sPCCyt",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:04:30.443677Z",
          "iopub.execute_input": "2024-05-25T18:04:30.444049Z",
          "iopub.status.idle": "2024-05-25T18:04:30.451239Z",
          "shell.execute_reply.started": "2024-05-25T18:04:30.444017Z",
          "shell.execute_reply": "2024-05-25T18:04:30.450275Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UTC_to_weekslot(utc: str) -> int:\n",
        "    \"\"\"UTC_to_weekslot converts a UTC timestamp to a weekslot.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    utc : str\n",
        "        A string representing a UTC timestamp.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        A weekslot in the range [0, 56).\n",
        "    \"\"\"\n",
        "\n",
        "    date = datetime.datetime.strptime(utc, \"%Y-%m-%d %H:%M:%S\")\n",
        "    week = date.weekday()\n",
        "    hour = date.hour\n",
        "\n",
        "    return week * 8 + hour // 3"
      ],
      "metadata": {
        "id": "XY2TcDbXCCyt",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:04:30.452653Z",
          "iopub.execute_input": "2024-05-25T18:04:30.453603Z",
          "iopub.status.idle": "2024-05-25T18:04:30.461685Z",
          "shell.execute_reply.started": "2024-05-25T18:04:30.453553Z",
          "shell.execute_reply": "2024-05-25T18:04:30.460983Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we want to encode all of our inputs for our neural networks, this could *probably* be done\n",
        "with polars magic, but it's too delicate and we prefer classic for-looping."
      ],
      "metadata": {
        "id": "8fkRkLFgCCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_dict = {\n",
        "    \"users\": LabelEncoder(),\n",
        "    \"pois\": LabelEncoder(),\n",
        "    \"g2\": LabelEncoder(),\n",
        "    \"g3\": LabelEncoder(),\n",
        "    \"g4\": LabelEncoder(),\n",
        "    \"g5\": LabelEncoder(),\n",
        "    \"g6\": LabelEncoder(),\n",
        "}\n",
        "\n",
        "encoded_data = {\n",
        "    \"users\": [],\n",
        "    \"pois\": [],\n",
        "    \"g2\": [],\n",
        "    \"g3\": [],\n",
        "    \"g4\": [],\n",
        "    \"g5\": [],\n",
        "    \"g6\": [],\n",
        "}\n",
        "\n",
        "unique_data = {\n",
        "    \"users\": set(),\n",
        "    \"pois\": set(),\n",
        "    \"g2\": set(),\n",
        "    \"g3\": set(),\n",
        "    \"g4\": set(),\n",
        "    \"g5\": set(),\n",
        "    \"g6\": set(),\n",
        "}\n",
        "\n",
        "# quick and dirty encoding:\n",
        "# 1. put every unique symbol in a list\n",
        "# 2. fit the respective encoder\n",
        "# 3. transform the lists\n",
        "\n",
        "for i, row in enumerate(final_sorted.iter_rows()):\n",
        "\n",
        "    user, pois, geohashes, times_sorted, n_checkins = row\n",
        "\n",
        "    g2 = [geo[:2] for geo in geohashes]\n",
        "    g3 = [geo[:3] for geo in geohashes]\n",
        "    g4 = [geo[:4] for geo in geohashes]\n",
        "    g5 = [geo[:5] for geo in geohashes]\n",
        "    g6 = [geo[:6] for geo in geohashes]  # redundant, but I like symmetry\n",
        "\n",
        "    unique_data[\"users\"].add(user)\n",
        "    unique_data[\"pois\"].update(pois)\n",
        "    unique_data[\"g2\"].update(g2)\n",
        "    unique_data[\"g3\"].update(g3)\n",
        "    unique_data[\"g4\"].update(g4)\n",
        "    unique_data[\"g5\"].update(g5)\n",
        "    unique_data[\"g6\"].update(g6)\n",
        "\n",
        "for property, enc, data in zip(\n",
        "    encoder_dict.keys(), encoder_dict.values(), unique_data.values()\n",
        "):\n",
        "    enc.fit(list(data))\n",
        "    encoder_dict[property] = enc"
      ],
      "metadata": {
        "id": "ItDfQyVUCCyt",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:04:30.462856Z",
          "iopub.execute_input": "2024-05-25T18:04:30.463118Z",
          "iopub.status.idle": "2024-05-25T18:04:30.809283Z",
          "shell.execute_reply.started": "2024-05-25T18:04:30.463097Z",
          "shell.execute_reply": "2024-05-25T18:04:30.808569Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this could be optimized, right now it takes a while, at least we have a nice progress bar to look at\n",
        "\n",
        "ds_size = len(final_sorted)\n",
        "\n",
        "for i, row in tqdm(enumerate(final_sorted.iter_rows()), total=ds_size):\n",
        "\n",
        "    user, pois, geohashes, times_sorted, n_checkins = row\n",
        "\n",
        "    g2 = [geo[:2] for geo in geohashes]\n",
        "    g3 = [geo[:3] for geo in geohashes]\n",
        "    g4 = [geo[:4] for geo in geohashes]\n",
        "    g5 = [geo[:5] for geo in geohashes]\n",
        "    g6 = [geo[:6] for geo in geohashes]\n",
        "\n",
        "    encoded_data[\"users\"].append(encoder_dict[\"users\"].transform([user])[0])\n",
        "    encoded_data[\"pois\"].append(encoder_dict[\"pois\"].transform(pois))\n",
        "    encoded_data[\"g2\"].append(encoder_dict[\"g2\"].transform(g2))\n",
        "    encoded_data[\"g3\"].append(encoder_dict[\"g3\"].transform(g3))\n",
        "    encoded_data[\"g4\"].append(encoder_dict[\"g4\"].transform(g4))\n",
        "    encoded_data[\"g5\"].append(encoder_dict[\"g5\"].transform(g5))\n",
        "    encoded_data[\"g6\"].append(encoder_dict[\"g6\"].transform(g6))\n",
        "\n",
        "    # sum 1 to all values to avoid 0s\n",
        "    encoded_data[\"users\"][-1] += 1\n",
        "    encoded_data[\"pois\"][-1] += 1\n",
        "    encoded_data[\"g2\"][-1] += 1\n",
        "    encoded_data[\"g3\"][-1] += 1\n",
        "    encoded_data[\"g4\"][-1] += 1\n",
        "    encoded_data[\"g5\"][-1] += 1\n",
        "    encoded_data[\"g6\"][-1] += 1"
      ],
      "metadata": {
        "id": "Il4AnsMUCCyt",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:04:30.810541Z",
          "iopub.execute_input": "2024-05-25T18:04:30.810835Z",
          "iopub.status.idle": "2024-05-25T18:08:50.557111Z",
          "shell.execute_reply.started": "2024-05-25T18:04:30.810812Z",
          "shell.execute_reply": "2024-05-25T18:08:50.556183Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check that we left space for the padding token\n",
        "min((arr.min() for arr in encoded_data[\"pois\"]))"
      ],
      "metadata": {
        "id": "nN6GpNCFCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:08:50.558375Z",
          "iopub.execute_input": "2024-05-25T18:08:50.558684Z",
          "iopub.status.idle": "2024-05-25T18:08:50.616624Z",
          "shell.execute_reply.started": "2024-05-25T18:08:50.558660Z",
          "shell.execute_reply": "2024-05-25T18:08:50.615558Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pois_checkins"
      ],
      "metadata": {
        "id": "enab_ljUCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:08:50.620179Z",
          "iopub.execute_input": "2024-05-25T18:08:50.620447Z",
          "iopub.status.idle": "2024-05-25T18:08:50.629386Z",
          "shell.execute_reply.started": "2024-05-25T18:08:50.620425Z",
          "shell.execute_reply": "2024-05-25T18:08:50.628548Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we also encode the graph dataframe so we can build the graphs\n",
        "\n",
        "pois_checkins = (\n",
        "    pois_checkins.lazy()\n",
        "    .with_columns(\n",
        "        [\n",
        "            rs.col(\"pois\").map_elements(\n",
        "                lambda s: encoder_dict[\"pois\"].transform([s])[0] + 1, rs.Int64\n",
        "            ),\n",
        "            rs.col(\"g4\").map_elements(\n",
        "                lambda s: encoder_dict[\"g4\"].transform([s])[0] + 1, rs.Int64\n",
        "            ),  # apply utc_to_weekslot to each timestamp in the list\n",
        "            rs.col(\"checkin_times\").map_elements(\n",
        "                lambda s: [UTC_to_weekslot(date) for date in s], rs.List(rs.Int64)\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    .sort(\"pois\")\n",
        "    .collect()\n",
        ")"
      ],
      "metadata": {
        "id": "qyEXUwAcCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:08:50.630468Z",
          "iopub.execute_input": "2024-05-25T18:08:50.630802Z",
          "iopub.status.idle": "2024-05-25T18:09:57.457385Z",
          "shell.execute_reply.started": "2024-05-25T18:08:50.630779Z",
          "shell.execute_reply": "2024-05-25T18:09:57.456379Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add fictitious POI 0 to the graph, with nonexistent geohash and no timeslot, so we get a 0 row and column for the padding token\n",
        "fake_datapoint = rs.DataFrame(\n",
        "    {\n",
        "        \"pois\": [0],\n",
        "        \"g4\": [pois_checkins[\"g4\"].max() + 42],\n",
        "        \"checkin_times\": [[43]],\n",
        "    }\n",
        ")\n",
        "# this is a lot of work since polars dataframes are immutable by default, we have to run a query to change the 43 into an empty list\n",
        "# we NEED the 43 otherwise polars won't infer the datatype of the list\n",
        "\n",
        "fake_datapoint = fake_datapoint.with_columns(\n",
        "    [rs.col(\"checkin_times\").map_elements(lambda s: [], rs.List(rs.Int64))]\n",
        ")\n",
        "\n",
        "pois_checkins = fake_datapoint.vstack(pois_checkins)"
      ],
      "metadata": {
        "id": "w1-P4fDgCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:57.458570Z",
          "iopub.execute_input": "2024-05-25T18:09:57.458882Z",
          "iopub.status.idle": "2024-05-25T18:09:57.466538Z",
          "shell.execute_reply.started": "2024-05-25T18:09:57.458858Z",
          "shell.execute_reply": "2024-05-25T18:09:57.465575Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spatial_row = np.array(pois_checkins[\"g4\"].to_list()).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "i4zaRXGPCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:57.467691Z",
          "iopub.execute_input": "2024-05-25T18:09:57.468112Z",
          "iopub.status.idle": "2024-05-25T18:09:57.480483Z",
          "shell.execute_reply.started": "2024-05-25T18:09:57.468081Z",
          "shell.execute_reply": "2024-05-25T18:09:57.479647Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outer product using equality\n",
        "spatial_graph = (spatial_row == spatial_row.T).astype(np.int32)\n",
        "spatial_graph[0, 0] = (\n",
        "    0  # the fake g4 is still equal to itself, we suppress this equality\n",
        ")\n",
        "spatial_graph = torch.tensor(spatial_graph)"
      ],
      "metadata": {
        "id": "rAL2xYaSCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:57.481683Z",
          "iopub.execute_input": "2024-05-25T18:09:57.482420Z",
          "iopub.status.idle": "2024-05-25T18:09:57.540008Z",
          "shell.execute_reply.started": "2024-05-25T18:09:57.482388Z",
          "shell.execute_reply": "2024-05-25T18:09:57.539295Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_row = pois_checkins[\"checkin_times\"].to_list()"
      ],
      "metadata": {
        "id": "O5Glb5TaCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:57.541239Z",
          "iopub.execute_input": "2024-05-25T18:09:57.541490Z",
          "iopub.status.idle": "2024-05-25T18:09:57.626099Z",
          "shell.execute_reply.started": "2024-05-25T18:09:57.541469Z",
          "shell.execute_reply": "2024-05-25T18:09:57.625105Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_graph = np.zeros((spatial_row.shape[0], spatial_row.shape[0]))"
      ],
      "metadata": {
        "id": "EKaTa7VNCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:57.627108Z",
          "iopub.execute_input": "2024-05-25T18:09:57.627380Z",
          "iopub.status.idle": "2024-05-25T18:09:57.633403Z",
          "shell.execute_reply.started": "2024-05-25T18:09:57.627357Z",
          "shell.execute_reply": "2024-05-25T18:09:57.632640Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_sets = [np.array(list(set(row))) for row in temporal_row]"
      ],
      "metadata": {
        "id": "sWGavlW5CCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:57.634410Z",
          "iopub.execute_input": "2024-05-25T18:09:57.634747Z",
          "iopub.status.idle": "2024-05-25T18:09:57.696312Z",
          "shell.execute_reply.started": "2024-05-25T18:09:57.634718Z",
          "shell.execute_reply": "2024-05-25T18:09:57.695627Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_sets = torch.zeros((len(temporal_sets), 56), dtype=torch.int8)\n",
        "\n",
        "for i, r in enumerate(temporal_row):\n",
        "    indices = torch.tensor(r, dtype=torch.long)\n",
        "    time_sets[i, indices] = 1"
      ],
      "metadata": {
        "id": "IAWEvt1mCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:57.697275Z",
          "iopub.execute_input": "2024-05-25T18:09:57.697534Z",
          "iopub.status.idle": "2024-05-25T18:09:58.133261Z",
          "shell.execute_reply.started": "2024-05-25T18:09:57.697512Z",
          "shell.execute_reply": "2024-05-25T18:09:58.132309Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_sets.shape"
      ],
      "metadata": {
        "id": "wGjJgRWaCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:58.134354Z",
          "iopub.execute_input": "2024-05-25T18:09:58.134652Z",
          "iopub.status.idle": "2024-05-25T18:09:58.140505Z",
          "shell.execute_reply.started": "2024-05-25T18:09:58.134625Z",
          "shell.execute_reply": "2024-05-25T18:09:58.139558Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AND outer product\n",
        "\n",
        "intersection = time_sets @ time_sets.T\n",
        "union = time_sets.unsqueeze(1) | time_sets.unsqueeze(0)\n",
        "union = union.sum(dim=2)\n",
        "iou = intersection / union"
      ],
      "metadata": {
        "id": "Ym-XXavSCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:09:58.141931Z",
          "iopub.execute_input": "2024-05-25T18:09:58.142272Z",
          "iopub.status.idle": "2024-05-25T18:10:03.156721Z",
          "shell.execute_reply.started": "2024-05-25T18:09:58.142241Z",
          "shell.execute_reply": "2024-05-25T18:10:03.155851Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_graph = iou >= 0.9\n",
        "# cast to int\n",
        "temporal_graph = temporal_graph.int()"
      ],
      "metadata": {
        "id": "uXE6xSDoCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.157954Z",
          "iopub.execute_input": "2024-05-25T18:10:03.158294Z",
          "iopub.status.idle": "2024-05-25T18:10:03.179647Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.158264Z",
          "shell.execute_reply": "2024-05-25T18:10:03.178749Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_graph[0, :].sum()"
      ],
      "metadata": {
        "id": "F_e6VXbgCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.182779Z",
          "iopub.execute_input": "2024-05-25T18:10:03.183044Z",
          "iopub.status.idle": "2024-05-25T18:10:03.198663Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.183023Z",
          "shell.execute_reply": "2024-05-25T18:10:03.197820Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We print information about the sparsity of the graphs, we note that\n",
        "the sparsity of the graphs is similar to that of the paper."
      ],
      "metadata": {
        "id": "NeCUaMGtCCyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temporal_density = (\n",
        "    temporal_graph.sum() / (temporal_graph.shape[0] * temporal_graph.shape[1])\n",
        ").item()\n",
        "spatial_density = (\n",
        "    spatial_graph.sum() / (spatial_graph.shape[0] * spatial_graph.shape[1])\n",
        ").item()\n",
        "\n",
        "print(f\"Temporal sparsity: {(1 - temporal_density) * 100:.2f}%\")\n",
        "\n",
        "print(f\"Spatial sparsity: {(1 - spatial_density) * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "-xX2oUeoCCyu",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.199848Z",
          "iopub.execute_input": "2024-05-25T18:10:03.200181Z",
          "iopub.status.idle": "2024-05-25T18:10:03.371438Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.200152Z",
          "shell.execute_reply": "2024-05-25T18:10:03.370596Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split\n",
        "\n",
        "We now generate two dataframes from the `encoded_data` dataframe, one for training and one for testing.\n",
        "\n",
        "First, we have to drop every sequence that has less than 4 timestamps, as we wouldn't be able to get the minimum of two samples for each of the sets,\n",
        "we then calculate the 80% of the sequences and split the data accordingly."
      ],
      "metadata": {
        "id": "6iiU7c42aItw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded_data[\"pois\"])"
      ],
      "metadata": {
        "id": "nNlKXjXbaItw",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.372583Z",
          "iopub.execute_input": "2024-05-25T18:10:03.372855Z",
          "iopub.status.idle": "2024-05-25T18:10:03.378652Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.372833Z",
          "shell.execute_reply": "2024-05-25T18:10:03.377776Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = rs.DataFrame(encoded_data)"
      ],
      "metadata": {
        "id": "_tyiaen0aItw",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.379933Z",
          "iopub.execute_input": "2024-05-25T18:10:03.380202Z",
          "iopub.status.idle": "2024-05-25T18:10:03.810721Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.380180Z",
          "shell.execute_reply": "2024-05-25T18:10:03.809856Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = total_data.with_columns(\n",
        "    [\n",
        "        rs.col(\"pois\").list.len().alias(\"length\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "K67_I3DwaItw",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.811828Z",
          "iopub.execute_input": "2024-05-25T18:10:03.812156Z",
          "iopub.status.idle": "2024-05-25T18:10:03.816824Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.812132Z",
          "shell.execute_reply": "2024-05-25T18:10:03.815966Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data = total_data.with_columns(\n",
        "    rs.col(\"length\")\n",
        "    .map_elements(lambda s: int(0.8 * s) - 1, rs.Int64)\n",
        "    .alias(\"train_end\")\n",
        ")"
      ],
      "metadata": {
        "id": "Vzaok7ZSaItw",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.817948Z",
          "iopub.execute_input": "2024-05-25T18:10:03.818208Z",
          "iopub.status.idle": "2024-05-25T18:10:03.834983Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.818185Z",
          "shell.execute_reply": "2024-05-25T18:10:03.834273Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop sequences that are too short\n",
        "total_data = total_data.filter(\n",
        "    (\n",
        "        rs.col(\"train_end\") >= 1\n",
        "    )  # at least 2 elements in the training set (1 is the index)\n",
        "    & (\n",
        "        rs.col(\"length\") - (rs.col(\"train_end\") + 1) >= 2\n",
        "    )  # at least 2 elements in the validation set\n",
        ")\n",
        "print(total_data[\"length\"].mean())\n",
        "print(total_data.count())"
      ],
      "metadata": {
        "id": "hNmcZlX2aItw",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.840362Z",
          "iopub.execute_input": "2024-05-25T18:10:03.840714Z",
          "iopub.status.idle": "2024-05-25T18:10:03.859898Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.840690Z",
          "shell.execute_reply": "2024-05-25T18:10:03.859103Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data.sort(\"length\")  # check out the distribution of sequence lengths"
      ],
      "metadata": {
        "id": "Mbl9-lbgaItx",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.860915Z",
          "iopub.execute_input": "2024-05-25T18:10:03.861225Z",
          "iopub.status.idle": "2024-05-25T18:10:03.884456Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.861194Z",
          "shell.execute_reply": "2024-05-25T18:10:03.883612Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the shortest sequence is long enough\n",
        "total_data.sort(\"length\")[\"pois\"][0]"
      ],
      "metadata": {
        "id": "-fdFTxtRaItx",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.885499Z",
          "iopub.execute_input": "2024-05-25T18:10:03.885767Z",
          "iopub.status.idle": "2024-05-25T18:10:03.902503Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.885745Z",
          "shell.execute_reply": "2024-05-25T18:10:03.901655Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# slice the two dataframes\n",
        "train_data = total_data.select(\n",
        "    [\n",
        "        rs.col(\"users\"),\n",
        "        rs.struct(\n",
        "            [\n",
        "                rs.col(\"pois\"),\n",
        "                rs.col(\"g2\"),\n",
        "                rs.col(\"g3\"),\n",
        "                rs.col(\"g4\"),\n",
        "                rs.col(\"g5\"),\n",
        "                rs.col(\"g6\"),\n",
        "                rs.col(\"train_end\"),\n",
        "            ]\n",
        "        )\n",
        "        .map_elements(\n",
        "            lambda struct: [\n",
        "                struct[\"pois\"][: struct[\"train_end\"]],\n",
        "                struct[\"g2\"][: struct[\"train_end\"]],\n",
        "                struct[\"g3\"][: struct[\"train_end\"]],\n",
        "                struct[\"g4\"][: struct[\"train_end\"]],\n",
        "                struct[\"g5\"][: struct[\"train_end\"]],\n",
        "                struct[\"g6\"][: struct[\"train_end\"]],\n",
        "            ],\n",
        "            return_dtype=rs.List(rs.List(rs.Int64)),\n",
        "        )\n",
        "        .alias(\"sequences\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "test_data = total_data.select(\n",
        "    [\n",
        "        rs.col(\"users\"),\n",
        "        rs.struct(\n",
        "            [\n",
        "                rs.col(\"pois\"),\n",
        "                rs.col(\"g2\"),\n",
        "                rs.col(\"g3\"),\n",
        "                rs.col(\"g4\"),\n",
        "                rs.col(\"g5\"),\n",
        "                rs.col(\"g6\"),\n",
        "                rs.col(\"train_end\"),\n",
        "            ]\n",
        "        )\n",
        "        .map_elements(\n",
        "            lambda struct: [\n",
        "                struct[\"pois\"][struct[\"train_end\"] :],\n",
        "                struct[\"g2\"][struct[\"train_end\"] :],\n",
        "                struct[\"g3\"][struct[\"train_end\"] :],\n",
        "                struct[\"g4\"][struct[\"train_end\"] :],\n",
        "                struct[\"g5\"][struct[\"train_end\"] :],\n",
        "                struct[\"g6\"][struct[\"train_end\"] :],\n",
        "            ],\n",
        "            return_dtype=rs.List(rs.List(rs.Int64)),\n",
        "        )\n",
        "        .alias(\"sequences\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "bjuQpQN2aItx",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:03.903825Z",
          "iopub.execute_input": "2024-05-25T18:10:03.904401Z",
          "iopub.status.idle": "2024-05-25T18:10:06.358448Z",
          "shell.execute_reply.started": "2024-05-25T18:10:03.904361Z",
          "shell.execute_reply": "2024-05-25T18:10:06.357635Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explode_dict(d):\n",
        "    \"\"\"explode_dict Convert packed polars dataframe into a neat python dict\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    d : Polars.DataFrame\n",
        "        A polars dataframe with a struct column\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A python dict with the same structure as the struct column\n",
        "    \"\"\"\n",
        "    ret = {\n",
        "        \"users\": d[\"users\"].to_list(),\n",
        "        \"pois\": [],\n",
        "        \"g2\": [],\n",
        "        \"g3\": [],\n",
        "        \"g4\": [],\n",
        "        \"g5\": [],\n",
        "        \"g6\": [],\n",
        "    }\n",
        "\n",
        "    for sample in d[\"sequences\"]:\n",
        "        pois, g2, g3, g4, g5, g6 = sample\n",
        "        ret[\"pois\"].append(pois.to_list())\n",
        "        ret[\"g2\"].append(g2.to_list())\n",
        "        ret[\"g3\"].append(g3.to_list())\n",
        "        ret[\"g4\"].append(g4.to_list())\n",
        "        ret[\"g5\"].append(g5.to_list())\n",
        "        ret[\"g6\"].append(g6.to_list())\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "zuqr6FDiaItx",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:06.359545Z",
          "iopub.execute_input": "2024-05-25T18:10:06.359861Z",
          "iopub.status.idle": "2024-05-25T18:10:06.366971Z",
          "shell.execute_reply.started": "2024-05-25T18:10:06.359822Z",
          "shell.execute_reply": "2024-05-25T18:10:06.366083Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data_train = explode_dict(train_data.to_dict())\n",
        "encoded_data_test = explode_dict(test_data.to_dict())"
      ],
      "metadata": {
        "id": "HJYSRKeJaItx",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:06.368146Z",
          "iopub.execute_input": "2024-05-25T18:10:06.368462Z",
          "iopub.status.idle": "2024-05-25T18:10:07.018199Z",
          "shell.execute_reply.started": "2024-05-25T18:10:06.368433Z",
          "shell.execute_reply": "2024-05-25T18:10:07.017124Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data"
      ],
      "metadata": {
        "id": "6TsVcLgXZPM0",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.019358Z",
          "iopub.execute_input": "2024-05-25T18:10:07.019653Z",
          "iopub.status.idle": "2024-05-25T18:10:07.028776Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.019624Z",
          "shell.execute_reply": "2024-05-25T18:10:07.027883Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data_train[\"pois\"][10]"
      ],
      "metadata": {
        "id": "31OjFgF3ZPM0",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.029932Z",
          "iopub.execute_input": "2024-05-25T18:10:07.030613Z",
          "iopub.status.idle": "2024-05-25T18:10:07.040574Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.030564Z",
          "shell.execute_reply": "2024-05-25T18:10:07.039775Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data_test[\"pois\"][10]"
      ],
      "metadata": {
        "id": "lPdKaRW-ZPM0",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.041754Z",
          "iopub.execute_input": "2024-05-25T18:10:07.042120Z",
          "iopub.status.idle": "2024-05-25T18:10:07.050754Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.042089Z",
          "shell.execute_reply": "2024-05-25T18:10:07.049971Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data[\"pois\"][10].to_list()"
      ],
      "metadata": {
        "id": "9KbV5-4TZPM0",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.051768Z",
          "iopub.execute_input": "2024-05-25T18:10:07.052083Z",
          "iopub.status.idle": "2024-05-25T18:10:07.063225Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.052054Z",
          "shell.execute_reply": "2024-05-25T18:10:07.062334Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min([len(l) for l in encoded_data_test[\"pois\"]])"
      ],
      "metadata": {
        "id": "6S2zqagAZPM0",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.064349Z",
          "iopub.execute_input": "2024-05-25T18:10:07.064659Z",
          "iopub.status.idle": "2024-05-25T18:10:07.075570Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.064635Z",
          "shell.execute_reply": "2024-05-25T18:10:07.074814Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n"
      ],
      "metadata": {
        "id": "-PEXknqyCCyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The paper utilizes metrics that check if the target is in the top-k recommendations, we implement them here."
      ],
      "metadata": {
        "id": "KxUt4jMGCCyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AccuracyAtK(nn.Module):\n",
        "    def __init__(self, k: int):\n",
        "        \"\"\"__init__ initializes the AccuracyAtK module.\n",
        "\n",
        "        Accuracy@k is the proportion of correct predictions in the top-k elements.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        k : int\n",
        "            The number of top-k elements to consider.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "\n",
        "    def forward(\n",
        "        self, logits: torch.Tensor, targets: torch.Tensor, padding_mask: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"forward computes the accuracy at k between logits and targets.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        logits : torch.Tensor\n",
        "            Class probability, either (B, C) or (B, T, C)\n",
        "        targets : torch.Tensor\n",
        "            Ground truth class indices, either (B,) or (B, T)\n",
        "        padding_mask : torch.Tensor\n",
        "            Padding mask, either (B,) or (B, T)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The accuracy at k, a scalar-tensor.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        predicted=logits.softmax(dim=-1)\n",
        "        top_k=predicted.topk(self.k, dim=-1)[1]\n",
        "        correct=(top_k==targets.unsqueeze(-1)).any(dim=-1).float()\n",
        "        if padding_mask is not None:\n",
        "            correct *= padding_mask.float()\n",
        "            # Avoid division by zero by counting non-zero elements in the mask\n",
        "            accuracy = correct.sum() / padding_mask.float().sum()\n",
        "        else:\n",
        "            accuracy = correct.mean()\n",
        "\n",
        "        return accuracy\n",
        "        '''\n",
        "\n",
        "        # Gotta have at least one nasty python one-liner, in memory of the old\n",
        "        # programming lab 1 bachelor course\n",
        "\n",
        "        # P.S the one liner was bugged, the hubris of man...\n",
        "        return (\n",
        "            (\n",
        "                logits.softmax(dim=-1)  # apply softmax\n",
        "                .masked_fill(\n",
        "                    padding_mask.unsqueeze(-1), -1e9\n",
        "                )  # mask padding by imposing a very low probability (hacky)\n",
        "                .topk(self.k, dim=-1)[1]  # extract top-k indices\n",
        "                == targets.unsqueeze(-1)\n",
        "            )\n",
        "            .any(dim=-1)\n",
        "            .float()\n",
        "            .mean()\n",
        "        )\n",
        "        '''\n",
        "\n",
        "\n",
        "class AccuracyAt1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        predicted = logits.argmax(dim=-1)\n",
        "        correct = (predicted == targets).float()\n",
        "        accuracy = correct.mean()\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "class MeanReciprocalRank(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"__init__ initializes the MeanReciprocalRank module.\n",
        "\n",
        "        Mean reciprocal rank is the average of the reciprocal ranks of the top-k elements.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self, logits: torch.Tensor, targets: torch.Tensor, padding_mask: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"forward computes the mean reciprocal rank between logits and targets.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        logits : torch.Tensor\n",
        "            Class probability\n",
        "        targets : torch.Tensor\n",
        "            Ground truth class indices\n",
        "        padding_mask : torch.Tensor\n",
        "            Padding mask\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            The mean reciprocal rank, a scalar-tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        predicted = logits.softmax(dim=-1)\n",
        "        top_k = predicted.topk(logits.size(-1), dim=-1)[1]\n",
        "        ranks = (top_k == targets.unsqueeze(-1)).nonzero()[:, -1].float() + 1\n",
        "        reciprocal_ranks = 1.0 / ranks\n",
        "        if padding_mask is not None:\n",
        "            reciprocal_ranks *= padding_mask.float()\n",
        "            # Avoid division by zero by counting non-zero elements in the mask\n",
        "            mrr = reciprocal_ranks.sum() / padding_mask.float().sum()\n",
        "        else:\n",
        "            mrr = reciprocal_ranks.mean()\n",
        "        return mrr"
      ],
      "metadata": {
        "id": "4lW2sibnCCyv",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.076816Z",
          "iopub.execute_input": "2024-05-25T18:10:07.077079Z",
          "iopub.status.idle": "2024-05-25T18:10:07.094148Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.077057Z",
          "shell.execute_reply": "2024-05-25T18:10:07.093280Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "def rnn_collation_fn(batch):\n",
        "\n",
        "    users = []\n",
        "    pois = []\n",
        "    g2 = []\n",
        "    g3 = []\n",
        "    g4 = []\n",
        "    g5 = []\n",
        "    g6 = []\n",
        "\n",
        "\n",
        "    for user, poi, geo2, geo3, geo4, geo5, geo6 in batch:\n",
        "        users.append(user)\n",
        "        pois.append(poi)\n",
        "        g2.append(geo2)\n",
        "        g3.append(geo3)\n",
        "        g4.append(geo4)\n",
        "        g5.append(geo5)\n",
        "        g6.append(geo6)\n",
        "\n",
        "\n",
        "    seq = (\n",
        "        torch.tensor(users, dtype=torch.long),\n",
        "        pad_sequence(pois, batch_first=True, padding_value=0),\n",
        "        pad_sequence(g2, batch_first=True, padding_value=0),\n",
        "        pad_sequence(g3, batch_first=True, padding_value=0),\n",
        "        pad_sequence(g4, batch_first=True, padding_value=0),\n",
        "        pad_sequence(g5, batch_first=True, padding_value=0),\n",
        "        pad_sequence(g6, batch_first=True, padding_value=0),\n",
        "    )  # build a sequence\n",
        "\n",
        "    x = (\n",
        "        seq[0],\n",
        "        seq[1][:, :-1],\n",
        "        seq[2][:, :-1],\n",
        "        seq[3][:, :-1],\n",
        "        seq[4][:, :-1],\n",
        "        seq[5][:, :-1],\n",
        "        seq[6][:, :-1],\n",
        "    )  # omit the last one for sample\n",
        "\n",
        "    y = (\n",
        "        seq[0],\n",
        "        seq[1][:, 1:],\n",
        "        seq[2][:, 1:],\n",
        "        seq[3][:, 1:],\n",
        "        seq[4][:, 1:],\n",
        "        seq[5][:, 1:],\n",
        "        seq[6][:, 1:],\n",
        "    )  # omit the first one for ground truth\n",
        "\n",
        "    # Take sequence lengths\n",
        "    x_lengths = x[1].count_nonzero(dim=1)\n",
        "    x_lengths = x_lengths.tolist()\n",
        "\n",
        "\n",
        "    return x,y,x_lengths\n",
        "\n",
        "\n",
        "class CheckinDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data[\"users\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x = (\n",
        "            torch.tensor(self.data[\"users\"][idx], dtype=torch.long),\n",
        "            torch.tensor(self.data[\"pois\"][idx], dtype=torch.long),\n",
        "            torch.tensor(self.data[\"g2\"][idx], dtype=torch.long),\n",
        "            torch.tensor(self.data[\"g3\"][idx], dtype=torch.long),\n",
        "            torch.tensor(self.data[\"g4\"][idx], dtype=torch.long),\n",
        "            torch.tensor(self.data[\"g5\"][idx], dtype=torch.long),\n",
        "            torch.tensor(self.data[\"g6\"][idx], dtype=torch.long),\n",
        "        )\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "J0Q9II4HCCyv",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.095794Z",
          "iopub.execute_input": "2024-05-25T18:10:07.096122Z",
          "iopub.status.idle": "2024-05-25T18:10:07.111986Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.096092Z",
          "shell.execute_reply": "2024-05-25T18:10:07.111042Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and Datamodule\n",
        "\n",
        "We then define a pytorch dataset and a custom collation function that allows us to dynamically\n",
        "pad sequences to the longest one in the batch (as opposed to the longest one in the dataset)\n",
        "as they are loaded during training, this gives us an edge in performance by dramatically reducing the\n",
        "sparsity of our inputs."
      ],
      "metadata": {
        "id": "y5gC9yrsCCyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CheckinModule(pl.LightningDataModule):\n",
        "    def __init__(self, encoded_data_train, encoded_data_test, batch_size=32, workers=4):\n",
        "        \"\"\"__init__ initializes the CheckinModule.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        encoded_data_train : Union[dict, rs.DataFrame]\n",
        "            The training data.\n",
        "        encoded_data_test : Union[dict, rs.DataFrame]\n",
        "            The testing data.\n",
        "        batch_size : int, optional\n",
        "            Size of the batches, by default 32\n",
        "        workers : int, optional\n",
        "            Number of worker processes, by default 4\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.encoded_data_train = encoded_data_train\n",
        "        self.encoded_data_test = encoded_data_test\n",
        "        self.batch_size = batch_size\n",
        "        self.workers = workers\n",
        "\n",
        "        assert isinstance(self.encoded_data_train, dict) or isinstance(\n",
        "            self.encoded_data_train, rs.DataFrame\n",
        "        ), \"encoded_data_train must be a dict or a polars DataFrame\"\n",
        "        assert isinstance(self.encoded_data_test, dict) or isinstance(\n",
        "            self.encoded_data_test, rs.DataFrame\n",
        "        ), \"encoded_data_test must be a dict or a polars DataFrame\"\n",
        "\n",
        "        assert batch_size > 0, \"batch_size must be a positive integer\"\n",
        "        assert workers >= 0, \"workers must be a non-negative integer\"\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "\n",
        "        if (\n",
        "            isinstance(self.encoded_data_train, dict)\n",
        "            or isinstance(self.encoded_data_train, rs.DataFrame)\n",
        "        ) and (\n",
        "            isinstance(self.encoded_data_test, dict)\n",
        "            or isinstance(self.encoded_data_test, rs.DataFrame)\n",
        "        ):\n",
        "            print(\"Loading data from dict/dataframe\")\n",
        "            self.train_dataset = CheckinDataset(self.encoded_data_train)\n",
        "            self.test_dataset = CheckinDataset(self.encoded_data_test)\n",
        "\n",
        "        elif isinstance(self.encoded_data_train, CheckinDataset) and isinstance(\n",
        "            self.encoded_data_test, CheckinDataset\n",
        "        ):\n",
        "            print(\"Loading data from pre-instantiated datasets\")\n",
        "            self.train_dataset = self.encoded_data_train\n",
        "            self.test_dataset = self.encoded_data_test\n",
        "        else:\n",
        "            raise ValueError(\"Invalid data type\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.workers,\n",
        "            collate_fn=rnn_collation_fn,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.workers,\n",
        "            collate_fn=rnn_collation_fn,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.workers,\n",
        "            collate_fn=rnn_collation_fn,\n",
        "        )\n",
        "\n",
        "    def save(self, whole_path, train_path, test_path):\n",
        "\n",
        "        torch.save(self.train_dataset, train_path)\n",
        "        torch.save(self.test_dataset, test_path)\n",
        "\n",
        "    @staticmethod  # load without instantiating\n",
        "    def load(train_path, test_path):\n",
        "\n",
        "        train_dataset = torch.load(train_path)\n",
        "        test_dataset = torch.load(test_path)\n",
        "\n",
        "        return CheckinModule(train_dataset, test_dataset)"
      ],
      "metadata": {
        "id": "ncOgD2VxCCyv",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.113156Z",
          "iopub.execute_input": "2024-05-25T18:10:07.113387Z",
          "iopub.status.idle": "2024-05-25T18:10:07.128181Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.113367Z",
          "shell.execute_reply": "2024-05-25T18:10:07.127251Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model: LSTM"
      ],
      "metadata": {
        "id": "G_STfUGVCCyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class BaselineDimensions:\n",
        "    nuser: int\n",
        "    npoi: int\n",
        "    g2len: int\n",
        "    g3len: int\n",
        "    g4len: int\n",
        "    g5len: int\n",
        "    g6len: int\n",
        "\n",
        "\n",
        "# HMT_RN (Hierarchical Multi-Task Recurrent Network)\n",
        "class HMT_RN(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dimensions: BaselineDimensions,\n",
        "        embedding_dim,\n",
        "        lstm_hidden_dim,\n",
        "        dropout_rate=0.9,\n",
        "        lr=1e-4,\n",
        "        # 0.9 is a lot, but the paper says so.\n",
        "    ):\n",
        "        super(HMT_RN, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = lstm_hidden_dim\n",
        "        self.dims = dimensions\n",
        "\n",
        "        # Embedding layers one for user, one for poi and one for each G@P\n",
        "        self.user_embedding = nn.Embedding(\n",
        "            dimensions.nuser, embedding_dim, padding_idx=0\n",
        "        )\n",
        "        self.poi_embedding = nn.Embedding(dimensions.npoi, embedding_dim, padding_idx=0)\n",
        "        self.g2_embed = nn.Embedding(dimensions.g2len, embedding_dim, padding_idx=0)\n",
        "        self.g3_embed = nn.Embedding(dimensions.g3len, embedding_dim, padding_idx=0)\n",
        "        self.g4_embed = nn.Embedding(dimensions.g4len, embedding_dim, padding_idx=0)\n",
        "        self.g5_embed = nn.Embedding(dimensions.g5len, embedding_dim, padding_idx=0)\n",
        "        self.g6_embed = nn.Embedding(dimensions.g6len, embedding_dim, padding_idx=0)\n",
        "\n",
        "        # Dropout layer for embeddings\n",
        "        self.e_drop = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim, hidden_size=lstm_hidden_dim, batch_first=True\n",
        "        )\n",
        "\n",
        "        # Linear layers for prediction tasks\n",
        "        self.linear_poi = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.npoi)\n",
        "        self.linear_g2 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g2len)\n",
        "        self.linear_g3 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g3len)\n",
        "        self.linear_g4 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g4len)\n",
        "        self.linear_g5 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g5len)\n",
        "        self.linear_g6 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g6len)\n",
        "\n",
        "        # https://discuss.pytorch.org/t/ignore-padding-area-in-loss-computation/95804/6\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "        self.top1 = AccuracyAtK(1)\n",
        "        self.top5 = AccuracyAtK(5)\n",
        "        self.top10 = AccuracyAtK(10)\n",
        "        self.top20 = AccuracyAtK(20)\n",
        "        self.mrr = MeanReciprocalRank()\n",
        "\n",
        "        self.lr = lr\n",
        "\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, w):\n",
        "\n",
        "        if type(w) == nn.Linear:\n",
        "            nn.init.kaiming_normal_(w.weight)\n",
        "            nn.init.constant_(w.bias, 0)\n",
        "        elif type(w) == nn.LSTM:\n",
        "            for name, param in w.named_parameters():\n",
        "                if \"bias\" in name:\n",
        "                    nn.init.constant_(param, 0)\n",
        "                elif \"weight\" in name:\n",
        "                    nn.init.kaiming_normal_(param)\n",
        "        elif type(w) == nn.Embedding:\n",
        "            nn.init.kaiming_normal_(w.weight)\n",
        "            nn.init.constant_(w.weight[0], 0)\n",
        "\n",
        "    def forward(self, batch, lengths):\n",
        "        \"\"\"forward passes the batch through the model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch : `tuple[torch.Tensor]`\n",
        "            A tuple of tensors ordered as follows:\n",
        "            (users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6)\n",
        "        \"\"\"\n",
        "\n",
        "        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = batch\n",
        "\n",
        "        # unpack the packed sequences, retrieve the lengths, for the LSTM len_g2, etc... are ignored\n",
        "#         poi, len_poi = pad_packed_sequence(poi, batch_first=True)\n",
        "#         x_geoHash2, len_g2 = pad_packed_sequence(x_geoHash2, batch_first=True)\n",
        "#         x_geoHash3, len_g3 = pad_packed_sequence(x_geoHash3, batch_first=True)\n",
        "#         x_geoHash4, len_g4 = pad_packed_sequence(x_geoHash4, batch_first=True)\n",
        "#         x_geoHash5, len_g5 = pad_packed_sequence(x_geoHash5, batch_first=True)\n",
        "#         x_geoHash6, len_g6 = pad_packed_sequence(x_geoHash6, batch_first=True)\n",
        "\n",
        "        B, T = poi.shape\n",
        "\n",
        "        # make it so  that users are tiled T times\n",
        "        users = users.repeat(T, 1).T\n",
        "\n",
        "        e_user = self.e_drop(self.user_embedding(users))\n",
        "        e_poi = self.e_drop(self.poi_embedding(poi))\n",
        "        e_gap2 = self.e_drop(self.g2_embed(x_geoHash2))\n",
        "        e_gap3 = self.e_drop(self.g3_embed(x_geoHash3))\n",
        "        e_gap4 = self.e_drop(self.g4_embed(x_geoHash4))\n",
        "        e_gap5 = self.e_drop(self.g5_embed(x_geoHash5))\n",
        "        e_gap6 = self.e_drop(self.g6_embed(x_geoHash6))\n",
        "\n",
        "        packed_poi = pack_padded_sequence(\n",
        "            e_poi, lengths, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        packed_output, (h_n, c_n) = self.lstm(packed_poi)\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "        # dense layers\n",
        "        next_poi = self.linear_poi(torch.cat((output, e_user), dim=2))\n",
        "        next_g2 = self.linear_g2(torch.cat((output, e_gap2), dim=2))\n",
        "        next_g3 = self.linear_g3(torch.cat((output, e_gap3), dim=2))\n",
        "        next_g4 = self.linear_g4(torch.cat((output, e_gap4), dim=2))\n",
        "        next_g5 = self.linear_g5(torch.cat((output, e_gap5), dim=2))\n",
        "        next_g6 = self.linear_g6(torch.cat((output, e_gap6), dim=2))\n",
        "\n",
        "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, lenpoi = batch\n",
        "\n",
        "        (\n",
        "            poi_pred,\n",
        "            gap2_pred,\n",
        "            gap3_pred,\n",
        "            gap4_pred,\n",
        "            gap5_pred,\n",
        "            gap6_pred,\n",
        "        ) = self(x, lenpoi)\n",
        "\n",
        "        loss_mask = (y[1] != 0).reshape(-1)\n",
        "\n",
        "        loss_poi = (self.criterion(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap2 = (self.criterion(\n",
        "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap3 = (self.criterion(\n",
        "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap4 = (self.criterion(\n",
        "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap5 = (self.criterion(\n",
        "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap6 = (self.criterion(\n",
        "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
        "        ) / (loss_mask.sum() * 6)\n",
        "        self.log(\"train/loss\", loss)\n",
        "        self.log(\"train/loss_gap2\", loss_gap2)\n",
        "        self.log(\"train/loss_gap3\", loss_gap3)\n",
        "        self.log(\"train/loss_gap4\", loss_gap4)\n",
        "        self.log(\"train/loss_gap5\", loss_gap5)\n",
        "        self.log(\"train/loss_gap6\", loss_gap6)\n",
        "        self.log(\"train/loss_poi\", loss_poi)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, lenpoi = batch\n",
        "        (\n",
        "            poi_pred,\n",
        "            gap2_pred,\n",
        "            gap3_pred,\n",
        "            gap4_pred,\n",
        "            gap5_pred,\n",
        "            gap6_pred,\n",
        "        ) = self(x, lenpoi)\n",
        "\n",
        "        loss_mask = (y[1] != 0).reshape(-1)\n",
        "\n",
        "        loss_poi = (self.criterion(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap2 = (self.criterion(\n",
        "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap3 = (self.criterion(\n",
        "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap4 = (self.criterion(\n",
        "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap5 = (self.criterion(\n",
        "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap6 = (self.criterion(\n",
        "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
        "        ) / (loss_mask.sum() * 6)\n",
        "\n",
        "\n",
        "        top1_acc = self.top1(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top5_acc = self.top5(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top10_acc = self.top10(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top20_acc = self.top20(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        mrr = self.mrr(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "\n",
        "        self.log(\"val/loss\", loss)\n",
        "        self.log(\"val/loss_gap2\", loss_gap2)\n",
        "        self.log(\"val/loss_gap3\", loss_gap3)\n",
        "        self.log(\"val/loss_gap4\", loss_gap4)\n",
        "        self.log(\"val/loss_gap5\", loss_gap5)\n",
        "        self.log(\"val/loss_gap6\", loss_gap6)\n",
        "        self.log(\"val/loss_poi\", loss_poi)\n",
        "\n",
        "        # log \"leaderboard\" metrics\n",
        "\n",
        "        self.log(\"val/top1\", top1_acc)\n",
        "        self.log(\"val/top5\", top5_acc)\n",
        "        self.log(\"val/top10\", top10_acc)\n",
        "        self.log(\"val/top20\", top20_acc)\n",
        "        self.log(\"val/mrr\", mrr)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y, lenpoi = batch\n",
        "        (\n",
        "            poi_pred,\n",
        "            gap2_pred,\n",
        "            gap3_pred,\n",
        "            gap4_pred,\n",
        "            gap5_pred,\n",
        "            gap6_pred,\n",
        "        ) = self(x, lenpoi)\n",
        "\n",
        "        loss_mask = (y[1] != 0).reshape(-1)\n",
        "\n",
        "\n",
        "        loss_poi = (self.criterion(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap2 = (self.criterion(\n",
        "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap3 = (self.criterion(\n",
        "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap4 = (self.criterion(\n",
        "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap5 = (self.criterion(\n",
        "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap6 = (self.criterion(\n",
        "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
        "        ) / (loss_mask.sum() * 6)\n",
        "\n",
        "\n",
        "        top1_acc = self.top1(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top5_acc = self.top5(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top10_acc = self.top10(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top20_acc = self.top20(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        mrr = self.mrr(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "\n",
        "        self.log(\"test/loss\", loss)\n",
        "        self.log(\"test/loss_gap2\", loss_gap2)\n",
        "        self.log(\"test/loss_gap3\", loss_gap3)\n",
        "        self.log(\"test/loss_gap4\", loss_gap4)\n",
        "        self.log(\"test/loss_gap5\", loss_gap5)\n",
        "        self.log(\"test/loss_gap6\", loss_gap6)\n",
        "        self.log(\"test/loss_poi\", loss_poi)\n",
        "\n",
        "        # log \"leaderboard\" metrics\n",
        "        self.log(\"test/top1\", top1_acc)\n",
        "        self.log(\"test/top5\", top5_acc)\n",
        "        self.log(\"test/top10\", top10_acc)\n",
        "        self.log(\"test/top20\", top20_acc)\n",
        "        self.log(\"test/mrr\", mrr)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Define optimizer and scheduler\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, amsgrad=True)\n",
        "\n",
        "        sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, T_0=5, T_mult=2\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": sched,\n",
        "                \"interval\": \"step\",\n",
        "            },\n",
        "        }"
      ],
      "metadata": {
        "id": "RcjMtxnFCCyv",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.129739Z",
          "iopub.execute_input": "2024-05-25T18:10:07.130212Z",
          "iopub.status.idle": "2024-05-25T18:10:07.189239Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.130181Z",
          "shell.execute_reply": "2024-05-25T18:10:07.188397Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network"
      ],
      "metadata": {
        "id": "aEkguqKVCCyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GNN Components\n",
        "\n",
        "\n",
        "class attn_LSTM(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim):\n",
        "        super(attn_LSTM, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
        "        self.U = nn.Linear(hidden_dim, 4 * hidden_dim)\n",
        "\n",
        "        self.s_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
        "        self.t_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
        "\n",
        "    def forward(self, x, hidden, spatial, temporal, numTimeSteps):\n",
        "        x_unpacked,_ = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
        "\n",
        "        h_t, c_t = hidden\n",
        "\n",
        "        previous_h_t = h_t\n",
        "        previous_c_t = c_t\n",
        "\n",
        "        allGates_preact = (\n",
        "            self.W(x_unpacked) + self.U(previous_h_t) + self.s_W(spatial) + self.t_W(temporal)\n",
        "        )\n",
        "\n",
        "        input_g = allGates_preact[:, :, : self.hidden_dim].sigmoid()\n",
        "        forget_g = allGates_preact[\n",
        "            :, :, self.hidden_dim : 2 * self.hidden_dim\n",
        "        ].sigmoid()\n",
        "        output_g = allGates_preact[\n",
        "            :, :, 2 * self.hidden_dim : 3 * self.hidden_dim\n",
        "        ].sigmoid()\n",
        "        c_t_g = allGates_preact[:, :, 3 * self.hidden_dim :].tanh()\n",
        "\n",
        "        c_t = forget_g * previous_c_t + input_g * c_t_g\n",
        "        h_t = output_g * c_t.tanh()\n",
        "\n",
        "        batchSize = x_unpacked.shape[0]\n",
        "        h_t = h_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
        "        c_t = c_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
        "\n",
        "        return x, (h_t, c_t)\n",
        "\n",
        "\n",
        "def get_neighbours(adj_matrix, poi):\n",
        "    neigh_indices_list = []\n",
        "    max_length = 0\n",
        "\n",
        "    for batch_poi in poi:\n",
        "        batch_indices = []\n",
        "        for single_poi in batch_poi:\n",
        "            poi_row = adj_matrix[single_poi]\n",
        "            neigh_indices = torch.where(poi_row == 1)[0]\n",
        "            batch_indices.append(neigh_indices)\n",
        "            max_length = max(max_length, len(neigh_indices))\n",
        "\n",
        "        neigh_indices_list.append(batch_indices)\n",
        "\n",
        "    padded_neigh_indices_list = []\n",
        "    for batch_indices in neigh_indices_list:\n",
        "        padded_batch_indices = pad_sequence(\n",
        "            batch_indices, batch_first=True, padding_value=0\n",
        "        )\n",
        "        padded_neigh_indices_list.append(padded_batch_indices)\n",
        "\n",
        "    padded_tensor = torch.stack(padded_neigh_indices_list)\n",
        "\n",
        "    return padded_tensor\n",
        "\n",
        "\n",
        "class GRNSelfAttention(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_dim, n_heads):\n",
        "\n",
        "        super(GRNSelfAttention, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.Wp = nn.Linear(hidden_dim, hidden_dim)  # embeddings to pre-concat\n",
        "        self.Wa = nn.Linear(2 * hidden_dim, hidden_dim)  # concatenation to pre-softmax\n",
        "\n",
        "        # total size = 3 * (hidden_dim) ** 2, quadratic in embedding size\n",
        "\n",
        "    def forward(self, poi, neighbors):\n",
        "        \"\"\"forward\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        poi: torch.Tensor\n",
        "            A batched tensor of embedded POI vectors, (B x H) where H is the\n",
        "            embedding dimension\n",
        "        neighbors: torch.Tensor\n",
        "            A batched tensor of sequences of embedded POI vectors that are extracted\n",
        "            from an adjacency matrix (temporal or spatial neighbors of POI),\n",
        "            (B x N x H), where N is the number of neighbours of POI, B is the\n",
        "            batch size, H is the embedding dimension, and must be the same as POI\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple[torch.Tensor, torch.Tensor]\n",
        "          A tuple containing the self-attention weighted hadamard product of neighbour activations\n",
        "          in the first index, the attention weights in the second index.\n",
        "        \"\"\"\n",
        "        # assert len(poi.shape) == 2, f\"POI tensor must be 2D, got {poi.shape} instead\"\n",
        "        assert (\n",
        "            len(neighbors.shape) == 3\n",
        "        ), f\"Neighbour tensor must be 3D, got {neighbors.shape} instead\"\n",
        "\n",
        "        B, N, H = neighbors.shape\n",
        "\n",
        "        h_poi = self.Wp(poi)\n",
        "        h_n = self.Wp(neighbors)\n",
        "        h_cat = torch.cat([h_poi.expand(B, N, -1), h_n], dim=2)\n",
        "        h_att = F.leaky_relu(self.Wa(h_cat))\n",
        "\n",
        "        alpha = torch.nn.functional.softmax(h_att, dim=1)\n",
        "\n",
        "        p = torch.sum(alpha * h_n, dim=1)\n",
        "        return p, alpha"
      ],
      "metadata": {
        "id": "BbiQDx04CCyv",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.190551Z",
          "iopub.execute_input": "2024-05-25T18:10:07.190822Z",
          "iopub.status.idle": "2024-05-25T18:10:07.209132Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.190800Z",
          "shell.execute_reply": "2024-05-25T18:10:07.208254Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRN (Graph Recurrent Network)\n",
        "class GRN(pl.LightningModule):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dims: BaselineDimensions,\n",
        "        spatial_graph,\n",
        "        temporal_graph,\n",
        "        hidden_dim,\n",
        "        n_heads,\n",
        "        dropout_rate=0.9,\n",
        "        device=\"cpu\",\n",
        "        lr=1e-4,\n",
        "    ):\n",
        "        super(GRN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.dims = dims\n",
        "\n",
        "        self.spatial_graph = spatial_graph.to(device)\n",
        "        self.temporal_graph = temporal_graph.to(device)\n",
        "\n",
        "        self.spatial_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
        "        self.temporal_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
        "\n",
        "        self.lstm = attn_LSTM(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.user_embedding = nn.Embedding(dims.nuser, hidden_dim, padding_idx=0)\n",
        "        self.poi_embedding = nn.Embedding(dims.npoi, hidden_dim, padding_idx=0)\n",
        "        self.g2_embed = nn.Embedding(dims.g2len, hidden_dim, padding_idx=0)\n",
        "        self.g3_embed = nn.Embedding(dims.g3len, hidden_dim, padding_idx=0)\n",
        "        self.g4_embed = nn.Embedding(dims.g4len, hidden_dim, padding_idx=0)\n",
        "        self.g5_embed = nn.Embedding(dims.g5len, hidden_dim, padding_idx=0)\n",
        "        self.g6_embed = nn.Embedding(dims.g6len, hidden_dim, padding_idx=0)\n",
        "\n",
        "        self.linear_poi = nn.Linear(2 * hidden_dim, dims.npoi)\n",
        "        self.linear_g2 = nn.Linear(2 * hidden_dim, dims.g2len)\n",
        "        self.linear_g3 = nn.Linear(2 * hidden_dim, dims.g3len)\n",
        "        self.linear_g4 = nn.Linear(2 * hidden_dim, dims.g4len)\n",
        "        self.linear_g5 = nn.Linear(2 * hidden_dim, dims.g5len)\n",
        "        self.linear_g6 = nn.Linear(2 * hidden_dim, dims.g6len)\n",
        "        self.top1 = AccuracyAtK(1)\n",
        "        self.top5 = AccuracyAtK(5)\n",
        "        self.top10 = AccuracyAtK(10)\n",
        "        self.top20 = AccuracyAtK(20)\n",
        "        self.mrr = MeanReciprocalRank()\n",
        "\n",
        "        # extract indices from one-hot neighbor list\n",
        "        self.iota = torch.arange(self.dims.npoi, requires_grad=False, device=device)\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "        self.lr = lr\n",
        "\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, w):\n",
        "        if type(w) == nn.Linear:\n",
        "            nn.init.kaiming_normal_(w.weight)\n",
        "            nn.init.constant_(w.bias, 0)\n",
        "        elif type(w) == nn.LSTM:\n",
        "            for name, param in w.named_parameters():\n",
        "                if \"bias\" in name:\n",
        "                    nn.init.constant_(param, 0)\n",
        "                elif \"weight\" in name:\n",
        "                    nn.init.kaiming_normal_(param)\n",
        "        elif type(w) == nn.Embedding:\n",
        "            nn.init.kaiming_normal_(w.weight)\n",
        "            nn.init.constant_(w.weight[0], 0)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "\n",
        "        users, poi, x_g2, x_g3, x_g4, x_g5, x_g6 = x\n",
        "        B, T = poi.shape\n",
        "\n",
        "        users = users.repeat(T, 1).T\n",
        "\n",
        "        neighbors_spatial = self.spatial_graph[poi]\n",
        "        neighbors_temporal = self.temporal_graph[poi]\n",
        "\n",
        "        e_user = self.dropout(self.user_embedding(users))\n",
        "        e_poi = self.dropout(self.poi_embedding(poi))\n",
        "        e_gap2 = self.dropout(self.g2_embed(x_g2))\n",
        "        e_gap3 = self.dropout(self.g3_embed(x_g3))\n",
        "        e_gap4 = self.dropout(self.g4_embed(x_g4))\n",
        "        e_gap5 = self.dropout(self.g5_embed(x_g5))\n",
        "        e_gap6 = self.dropout(self.g6_embed(x_g6))\n",
        "\n",
        "        spatial_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
        "        temporal_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
        "\n",
        "        for b in range(B):\n",
        "            for t in range(T):\n",
        "\n",
        "                spatial_neigh = neighbors_spatial[b, t] * self.iota\n",
        "                temporal_neigh = neighbors_temporal[b, t] * self.iota\n",
        "\n",
        "                spatial_neigh = spatial_neigh[spatial_neigh != 0]\n",
        "                temporal_neigh = temporal_neigh[temporal_neigh != 0]\n",
        "\n",
        "                spatial_neigh = spatial_neigh.unsqueeze(0)\n",
        "                temporal_neigh = temporal_neigh.unsqueeze(0)\n",
        "\n",
        "                e_spatial = self.dropout(self.poi_embedding(spatial_neigh))\n",
        "                e_temporal = self.dropout(self.poi_embedding(temporal_neigh))\n",
        "\n",
        "                curr_poi = e_poi[b, t].unsqueeze(0)\n",
        "\n",
        "                spatial_p, _ = self.spatial_attn(curr_poi, e_spatial)\n",
        "                temporal_p, _ = self.temporal_attn(curr_poi, e_temporal)\n",
        "\n",
        "                # we are not using the batch dimension, so we squeeze it\n",
        "                spatial_atts[b, t] = spatial_p.squeeze()\n",
        "                temporal_atts[b, t] = temporal_p.squeeze()\n",
        "\n",
        "        # zero-init LSTM states\n",
        "        h_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
        "        c_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
        "\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(\n",
        "            e_poi, lengths, batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        pack_out, (h_t, c_t) = self.lstm(\n",
        "            packed_input, (h_t, c_t), spatial_atts, temporal_atts, T\n",
        "        )\n",
        "        output, _ = nn.utils.rnn.pad_packed_sequence(\n",
        "            pack_out, batch_first=True\n",
        "        )\n",
        "\n",
        "        # Note:the prediction of the poi depends on the embedding of the user\n",
        "        next_poi = self.linear_poi(torch.cat((output, e_user), dim=2))\n",
        "        next_g2 = self.linear_g2(torch.cat((output, e_gap2), dim=2))\n",
        "        next_g3 = self.linear_g3(torch.cat((output, e_gap3), dim=2))\n",
        "        next_g4 = self.linear_g4(torch.cat((output, e_gap4), dim=2))\n",
        "        next_g5 = self.linear_g5(torch.cat((output, e_gap5), dim=2))\n",
        "        next_g6 = self.linear_g6(torch.cat((output, e_gap6), dim=2))\n",
        "\n",
        "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, len_x = batch\n",
        "        (\n",
        "            poi_pred,\n",
        "            gap2_pred,\n",
        "            gap3_pred,\n",
        "            gap4_pred,\n",
        "            gap5_pred,\n",
        "            gap6_pred,\n",
        "        ) = self(x, len_x)\n",
        "\n",
        "        loss_mask = (y[1] != 0).reshape(-1)\n",
        "        loss_poi = (\n",
        "            self.criterion(poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap2 = (\n",
        "            self.criterion(gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap3 = (\n",
        "            self.criterion(gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap4 = (\n",
        "            self.criterion(gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap5 = (\n",
        "            self.criterion(gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap6 = (\n",
        "            self.criterion(gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            (loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6)\n",
        "            / loss_mask.sum()\n",
        "            * 6\n",
        "        )\n",
        "\n",
        "        self.log(\"train/loss\", loss)\n",
        "        self.log(\"train/loss_gap2\", loss_gap2)\n",
        "        self.log(\"train/loss_gap3\", loss_gap3)\n",
        "        self.log(\"train/loss_gap4\", loss_gap4)\n",
        "        self.log(\"train/loss_gap5\", loss_gap5)\n",
        "        self.log(\"train/loss_gap6\", loss_gap6)\n",
        "        self.log(\"train/loss_poi\", loss_poi)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, len_x = batch\n",
        "\n",
        "        (\n",
        "            poi_pred,\n",
        "            gap2_pred,\n",
        "            gap3_pred,\n",
        "            gap4_pred,\n",
        "            gap5_pred,\n",
        "            gap6_pred,\n",
        "        ) = self(x, len_x)\n",
        "\n",
        "\n",
        "        loss_mask = (y[1] != 0).reshape(-1)\n",
        "        loss_poi = (\n",
        "            self.criterion(poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap2 = (\n",
        "            self.criterion(gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap3 = (\n",
        "            self.criterion(gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap4 = (\n",
        "            self.criterion(gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap5 = (\n",
        "            self.criterion(gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap6 = (\n",
        "            self.criterion(gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            (loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6)\n",
        "            / loss_mask.sum()\n",
        "            * 6\n",
        "        )\n",
        "\n",
        "        top1_acc = self.top1(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top5_acc = self.top5(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top10_acc = self.top10(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top20_acc = self.top20(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        mrr = self.mrr(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "\n",
        "        self.log(\"val/loss\", loss)\n",
        "        self.log(\"val/loss_gap2\", loss_gap2)\n",
        "        self.log(\"val/loss_gap3\", loss_gap3)\n",
        "        self.log(\"val/loss_gap4\", loss_gap4)\n",
        "        self.log(\"val/loss_gap5\", loss_gap5)\n",
        "        self.log(\"val/loss_gap6\", loss_gap6)\n",
        "        self.log(\"val/loss_poi\", loss_poi)\n",
        "\n",
        "        # log \"leaderboard\" metrics\n",
        "        self.log(\"val/top1\", top1_acc)\n",
        "        self.log(\"val/top5\", top5_acc)\n",
        "        self.log(\"val/top10\", top10_acc)\n",
        "        self.log(\"val/top20\", top20_acc)\n",
        "        self.log(\"val/mrr\", mrr)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y, len_x = batch\n",
        "\n",
        "        (\n",
        "            poi_pred,\n",
        "            gap2_pred,\n",
        "            gap3_pred,\n",
        "            gap4_pred,\n",
        "            gap5_pred,\n",
        "            gap6_pred,\n",
        "        ) = self(x, len_x)\n",
        "\n",
        "\n",
        "\n",
        "        loss_mask = (y[1] != 0).reshape(-1)\n",
        "\n",
        "        loss_poi = (\n",
        "            self.criterion(poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap2 = (\n",
        "            self.criterion(gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap3 = (\n",
        "            self.criterion(gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap4 = (\n",
        "            self.criterion(gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap5 = (\n",
        "            self.criterion(gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "        loss_gap6 = (\n",
        "            self.criterion(gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1))\n",
        "            .where(loss_mask, torch.tensor(0.0))\n",
        "            .sum()\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            (loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6)\n",
        "            / loss_mask.sum()\n",
        "            * 6\n",
        "        )\n",
        "\n",
        "        top1_acc = self.top1(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top5_acc = self.top5(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top10_acc = self.top10(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        top20_acc = self.top20(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        mrr = self.mrr(\n",
        "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1), loss_mask\n",
        "        )\n",
        "        self.log(\"test/loss\", loss)\n",
        "        self.log(\"test/loss_gap2\", loss_gap2)\n",
        "        self.log(\"test/loss_gap3\", loss_gap3)\n",
        "        self.log(\"test/loss_gap4\", loss_gap4)\n",
        "        self.log(\"test/loss_gap5\", loss_gap5)\n",
        "        self.log(\"test/loss_gap6\", loss_gap6)\n",
        "        self.log(\"test/loss_poi\", loss_poi)\n",
        "\n",
        "        # log \"leaderboard\" metrics\n",
        "        self.log(\"test/top1\", top1_acc)\n",
        "        self.log(\"test/top5\", top5_acc)\n",
        "        self.log(\"test/top10\", top10_acc)\n",
        "        self.log(\"test/top20\", top20_acc)\n",
        "        self.log(\"test/mrr\", mrr)\n",
        "\n",
        "        return {\"loss\": loss}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Define optimizer and scheduler\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, amsgrad=True)\n",
        "\n",
        "        sched = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            optimizer, T_0=5, T_mult=2\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": sched,\n",
        "                \"interval\": \"step\",\n",
        "            },\n",
        "        }"
      ],
      "metadata": {
        "id": "lpnLqpOSCCyv",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.210575Z",
          "iopub.execute_input": "2024-05-25T18:10:07.210922Z",
          "iopub.status.idle": "2024-05-25T18:10:07.271939Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.210892Z",
          "shell.execute_reply": "2024-05-25T18:10:07.271070Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loops"
      ],
      "metadata": {
        "id": "kRG9Fg0sCCyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_users = encoder_dict[\"users\"].classes_.shape[0]\n",
        "n_pois = encoder_dict[\"pois\"].classes_.shape[0]\n",
        "n_g2 = encoder_dict[\"g2\"].classes_.shape[0]\n",
        "n_g3 = encoder_dict[\"g3\"].classes_.shape[0]\n",
        "n_g4 = encoder_dict[\"g4\"].classes_.shape[0]\n",
        "n_g5 = encoder_dict[\"g5\"].classes_.shape[0]\n",
        "n_g6 = encoder_dict[\"g6\"].classes_.shape[0]\n",
        "\n",
        "\n",
        "# account for the padding token\n",
        "dims = BaselineDimensions(\n",
        "    n_users + 1, n_pois + 1, n_g2 + 1, n_g3 + 1, n_g4 + 1, n_g5 + 1, n_g6 + 1\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4B3gEpRhCCyw",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.272897Z",
          "iopub.execute_input": "2024-05-25T18:10:07.273168Z",
          "iopub.status.idle": "2024-05-25T18:10:07.307838Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.273147Z",
          "shell.execute_reply": "2024-05-25T18:10:07.307153Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning.pytorch.loggers import WandbLogger\n",
        "from lightning.pytorch import Trainer\n",
        "from lightning.pytorch.tuner import Tuner\n",
        "\n",
        "TRAIN_BASELINE = True\n",
        "\n",
        "wandb.finish()\n",
        "torch.cuda.empty_cache()\n",
        "# cargo-cult like stuff that is supposed to make you faster\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "ds = CheckinModule(encoded_data_train, encoded_data_test, batch_size=32, workers=4)\n",
        "\n",
        "wandb.login(key=\"344bb70e22754f0a0dd7500f074ca1413eaba409\")\n",
        "wandb.init(project=\"trovailpoi\")\n",
        "\n",
        "classifier_baseline = HMT_RN(dims, embedding_dim=1024, lstm_hidden_dim=1024)\n",
        "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
        "trainer = Trainer(\n",
        "    max_epochs=200,\n",
        "    accelerator=\"auto\",\n",
        "    devices=[0],\n",
        "    log_every_n_steps=10,\n",
        "    logger=wandb_logger,\n",
        "    strategy=\"auto\",\n",
        "    callbacks=[\n",
        "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
        "        torchpl.callbacks.ModelCheckpoint(\n",
        "            monitor=\"val/loss\",\n",
        "            mode=\"min\",\n",
        "            save_top_k=1,\n",
        "            save_last=True,\n",
        "            filename=\"best_model\",\n",
        "        ),\n",
        "        torchpl.callbacks.EarlyStopping(\n",
        "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "tuner = Tuner(trainer)\n",
        "\n",
        "if TRAIN_BASELINE:\n",
        "\n",
        "    tuner.scale_batch_size(classifier_baseline, datamodule=ds, mode=\"power\")\n",
        "    tuner.lr_find(\n",
        "        classifier_baseline, datamodule=ds, min_lr=5e-5, max_lr=5e-3, num_training=100\n",
        "    )\n",
        "    trainer.fit(model=classifier_baseline, datamodule=ds)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "ZJsxdOY5CCyw",
        "execution": {
          "iopub.status.busy": "2024-05-25T18:10:07.308814Z",
          "iopub.execute_input": "2024-05-25T18:10:07.309073Z",
          "iopub.status.idle": "2024-05-25T18:23:21.878192Z",
          "shell.execute_reply.started": "2024-05-25T18:10:07.309052Z",
          "shell.execute_reply": "2024-05-25T18:23:21.877185Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_GNN = True\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "wandb.finish()\n",
        "torch.cuda.empty_cache()\n",
        "# cargo-cult like stuff that is supposed to make you faster\n",
        "torch.set_float32_matmul_precision(\"medium\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "ds = CheckinModule(encoded_data_train, encoded_data_test, batch_size=32, workers=4)\n",
        "\n",
        "wandb.login(key=\"344bb70e22754f0a0dd7500f074ca1413eaba409\")\n",
        "wandb.init(project=\"trovailpoi\")\n",
        "\n",
        "classifier_gnn = GRN(\n",
        "    dims,\n",
        "    spatial_graph,\n",
        "    temporal_graph,\n",
        "    hidden_dim=1024,\n",
        "    n_heads=1,\n",
        "    dropout_rate=0.9,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=200,\n",
        "    accelerator=\"auto\",\n",
        "    devices=[0],\n",
        "    log_every_n_steps=10,\n",
        "    logger=wandb_logger,\n",
        "    strategy=\"auto\",\n",
        "    callbacks=[\n",
        "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
        "        torchpl.callbacks.ModelCheckpoint(\n",
        "            monitor=\"val/loss\",\n",
        "            mode=\"min\",\n",
        "            save_top_k=1,\n",
        "            save_last=True,\n",
        "            filename=\"best_model\",\n",
        "        ),\n",
        "        torchpl.callbacks.EarlyStopping(\n",
        "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "tuner = Tuner(trainer)\n",
        "\n",
        "if TRAIN_GNN:\n",
        "\n",
        "    tuner.scale_batch_size(classifier_gnn, datamodule=ds, mode=\"power\")\n",
        "    tuner.lr_find(\n",
        "        classifier_gnn, datamodule=ds, min_lr=5e-5, max_lr=1e-3, num_training=100\n",
        "    )\n",
        "    gc.collect()\n",
        "    trainer.fit(model=classifier_gnn, datamodule=ds)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "ZltK8HPhCCyw",
        "execution": {
          "iopub.status.busy": "2024-05-25T19:53:13.249108Z",
          "iopub.execute_input": "2024-05-25T19:53:13.251700Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/trovailpoi/dnpotgxc/checkpoints/best_model.ckpt\"\n",
        "# Load the trained model from the checkpoint\n",
        "trained_model = HMT_RN.load_from_checkpoint(\n",
        "    checkpoint_path,\n",
        "    dimensions=dims,\n",
        "    embedding_dim=1024,  # Example embedding dimension\n",
        "    lstm_hidden_dim=1024,  # Example LSTM hidden dimension\n",
        "    dropout_rate=0.9,  # Example dropout rate\n",
        ")\n",
        "\n",
        "# Create a test dataloader\n",
        "# Assuming you have a method `test_dataloader` in your data module\n",
        "test_loader = ds.test_dataloader()  # Replace `ds` with your actual data module instance\n",
        "\n",
        "# Instantiate the trainer\n",
        "trainer = Trainer(accelerator=\"auto\", devices=[0])\n",
        "\n",
        "# Test the model\n",
        "results = trainer.test(trained_model, test_loader)\n",
        "\n",
        "# Print the test results\n",
        "print(results)"
      ],
      "metadata": {
        "id": "abzS8kwAKPPu",
        "execution": {
          "iopub.status.busy": "2024-05-25T17:59:15.140123Z",
          "iopub.status.idle": "2024-05-25T17:59:15.140453Z",
          "shell.execute_reply.started": "2024-05-25T17:59:15.140284Z",
          "shell.execute_reply": "2024-05-25T17:59:15.140298Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scrapbook for Experimentation\n",
        "\n",
        "Ignore all code below, it's just for quick prototyping"
      ],
      "metadata": {
        "id": "ik7z0iyRCCyw"
      }
    }
  ]
}