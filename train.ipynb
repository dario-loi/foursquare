{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare dataset next-POI Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off we import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as rs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as pl\n",
    "import lightning.pytorch as torchpl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataclasses import dataclass\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define WANDB_NOTEBOOK_NAME\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "# clean CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# sometimes jupyter notebook does not release memory, we leave this here so a run-all\n",
    "# can *sometimes* fix leaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the data, we utilize `polars` since it is much more efficient than `pandas` and can handle large datasets with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"user\", \"poi\", \"date\", \"TZ\"]\n",
    "data = rs.read_csv(\n",
    "    \"dataset_TIST2015/dataset_TIST2015_Checkins.txt\",\n",
    "    has_header=False,\n",
    "    low_memory=True,\n",
    "    separator=\"\\t\",\n",
    ")\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (33_263_633, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>poi</th><th>date</th><th>TZ</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>50756</td><td>&quot;4f5e3a72e4b053fd6a4313f6&quot;</td><td>&quot;Tue Apr 03 18:00:06 +0000 2012&quot;</td><td>240</td></tr><tr><td>190571</td><td>&quot;4b4b87b5f964a5204a9f26e3&quot;</td><td>&quot;Tue Apr 03 18:00:07 +0000 2012&quot;</td><td>180</td></tr><tr><td>221021</td><td>&quot;4a85b1b3f964a520eefe1fe3&quot;</td><td>&quot;Tue Apr 03 18:00:08 +0000 2012&quot;</td><td>-240</td></tr><tr><td>66981</td><td>&quot;4b4606f2f964a520751426e3&quot;</td><td>&quot;Tue Apr 03 18:00:08 +0000 2012&quot;</td><td>-300</td></tr><tr><td>21010</td><td>&quot;4c2b4e8a9a559c74832f0de2&quot;</td><td>&quot;Tue Apr 03 18:00:09 +0000 2012&quot;</td><td>240</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>16349</td><td>&quot;4c957755c8a1bfb7e89024f3&quot;</td><td>&quot;Mon Sep 16 23:24:11 +0000 2013&quot;</td><td>-240</td></tr><tr><td>256757</td><td>&quot;4c8bbb6d9ef0224bd2d6667b&quot;</td><td>&quot;Mon Sep 16 23:24:13 +0000 2013&quot;</td><td>-180</td></tr><tr><td>66425</td><td>&quot;513e82a5e4b0ed4f0f3bcf2d&quot;</td><td>&quot;Mon Sep 16 23:24:14 +0000 2013&quot;</td><td>-180</td></tr><tr><td>1830</td><td>&quot;4b447865f964a5204cf525e3&quot;</td><td>&quot;Mon Sep 16 23:24:14 +0000 2013&quot;</td><td>120</td></tr><tr><td>22704</td><td>&quot;50df4ee5e4b0c48b5a1c2968&quot;</td><td>&quot;Mon Sep 16 23:24:15 +0000 2013&quot;</td><td>180</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (33_263_633, 4)\n",
       "┌────────┬──────────────────────────┬────────────────────────────────┬──────┐\n",
       "│ user   ┆ poi                      ┆ date                           ┆ TZ   │\n",
       "│ ---    ┆ ---                      ┆ ---                            ┆ ---  │\n",
       "│ i64    ┆ str                      ┆ str                            ┆ i64  │\n",
       "╞════════╪══════════════════════════╪════════════════════════════════╪══════╡\n",
       "│ 50756  ┆ 4f5e3a72e4b053fd6a4313f6 ┆ Tue Apr 03 18:00:06 +0000 2012 ┆ 240  │\n",
       "│ 190571 ┆ 4b4b87b5f964a5204a9f26e3 ┆ Tue Apr 03 18:00:07 +0000 2012 ┆ 180  │\n",
       "│ 221021 ┆ 4a85b1b3f964a520eefe1fe3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -240 │\n",
       "│ 66981  ┆ 4b4606f2f964a520751426e3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -300 │\n",
       "│ 21010  ┆ 4c2b4e8a9a559c74832f0de2 ┆ Tue Apr 03 18:00:09 +0000 2012 ┆ 240  │\n",
       "│ …      ┆ …                        ┆ …                              ┆ …    │\n",
       "│ 16349  ┆ 4c957755c8a1bfb7e89024f3 ┆ Mon Sep 16 23:24:11 +0000 2013 ┆ -240 │\n",
       "│ 256757 ┆ 4c8bbb6d9ef0224bd2d6667b ┆ Mon Sep 16 23:24:13 +0000 2013 ┆ -180 │\n",
       "│ 66425  ┆ 513e82a5e4b0ed4f0f3bcf2d ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ -180 │\n",
       "│ 1830   ┆ 4b447865f964a5204cf525e3 ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ 120  │\n",
       "│ 22704  ┆ 50df4ee5e4b0c48b5a1c2968 ┆ Mon Sep 16 23:24:15 +0000 2013 ┆ 180  │\n",
       "└────────┴──────────────────────────┴────────────────────────────────┴──────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from what suggested by the professor, we utilize the full TIST2015 dataset, which has a far greater scale compared to the reduced NY one. However, by following the pruning steps detailed in the paper (http://dx.doi.org/10.1145/3477495.3531989, section 5.1), we obtain sequences that are much smaller in size, resulting in a dataset that is usable on Google Colab's free tier (as required by the assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users = (\n",
    "    data.lazy()\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        [\n",
    "            rs.col(\"poi\").n_unique().alias(\"n_pois\"),\n",
    "            rs.col(\"poi\").count().alias(\"n_checkins\"),\n",
    "            # turn the rest into a list\n",
    "            rs.col(\"poi\").alias(\"pois\"),\n",
    "            rs.col(\"date\").alias(\"dates\"),\n",
    "            rs.col(\"TZ\").alias(\"TZs\"),\n",
    "        ]\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>133455.0</td><td>56.477459</td><td>124.62537</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>77050.135837</td><td>45.968603</td><td>140.692138</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>66728.0</td><td>30.0</td><td>61.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>133455.0</td><td>49.0</td><td>93.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>200182.0</td><td>71.0</td><td>148.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>1246.0</td><td>5430.0</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬──────────────┬───────────┬────────────┬──────────┬──────────┬──────────┐\n",
       "│ statistic  ┆ user         ┆ n_pois    ┆ n_checkins ┆ pois     ┆ dates    ┆ TZs      │\n",
       "│ ---        ┆ ---          ┆ ---       ┆ ---        ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str        ┆ f64          ┆ f64       ┆ f64        ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞════════════╪══════════════╪═══════════╪════════════╪══════════╪══════════╪══════════╡\n",
       "│ count      ┆ 266909.0     ┆ 266909.0  ┆ 266909.0   ┆ 266909.0 ┆ 266909.0 ┆ 266909.0 │\n",
       "│ null_count ┆ 0.0          ┆ 0.0       ┆ 0.0        ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "│ mean       ┆ 133455.0     ┆ 56.477459 ┆ 124.62537  ┆ null     ┆ null     ┆ null     │\n",
       "│ std        ┆ 77050.135837 ┆ 45.968603 ┆ 140.692138 ┆ null     ┆ null     ┆ null     │\n",
       "│ min        ┆ 1.0          ┆ 1.0       ┆ 1.0        ┆ null     ┆ null     ┆ null     │\n",
       "│ 25%        ┆ 66728.0      ┆ 30.0      ┆ 61.0       ┆ null     ┆ null     ┆ null     │\n",
       "│ 50%        ┆ 133455.0     ┆ 49.0      ┆ 93.0       ┆ null     ┆ null     ┆ null     │\n",
       "│ 75%        ┆ 200182.0     ┆ 71.0      ┆ 148.0      ┆ null     ┆ null     ┆ null     │\n",
       "│ max        ┆ 266909.0     ┆ 1246.0    ┆ 5430.0     ┆ null     ┆ null     ┆ null     │\n",
       "└────────────┴──────────────┴───────────┴────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_culled = data_users.filter(\n",
    "    (rs.col(\"n_checkins\") > 20) & (rs.col(\"n_checkins\") < 50)\n",
    ").drop_nulls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the original dataset is huge, we delete it and call the python garbage collector to free up memory. We then proceed with the second pruning step (frequency-based pruning) as detailed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "del data_users\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique elements from each lists in data_culled[\"pois\"]\n",
    "out = data_culled.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\").list.unique(),\n",
    "        rs.col(\"pois\").list.unique().list.len().alias(\"n_unique_pois\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_697, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th><th>n_unique_pois</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td><td>u32</td></tr></thead><tbody><tr><td>249664</td><td>31</td><td>41</td><td>[&quot;4bb21c0cf964a5209ab93ce3&quot;, &quot;4c17a3fe30d30f4751ce36a9&quot;, … &quot;4b7163d8f964a52046442de3&quot;]</td><td>[&quot;Wed May 23 16:02:52 +0000 2012&quot;, &quot;Mon May 28 14:18:57 +0000 2012&quot;, … &quot;Thu Sep 05 08:25:32 +0000 2013&quot;]</td><td>[240, 240, … 240]</td><td>31</td></tr><tr><td>234554</td><td>31</td><td>45</td><td>[&quot;4bf60d51abdaef3bf02fa184&quot;, &quot;4c4ccb68b301b713b4410d89&quot;, … &quot;4bb6b0cf46d4a593d0afc6c0&quot;]</td><td>[&quot;Fri Apr 06 16:17:45 +0000 2012&quot;, &quot;Sat Apr 07 19:34:33 +0000 2012&quot;, … &quot;Thu May 30 14:07:35 +0000 2013&quot;]</td><td>[-300, -300, … -300]</td><td>31</td></tr><tr><td>117383</td><td>26</td><td>29</td><td>[&quot;506db535e4b0e36e9b7d3f8f&quot;, &quot;414b7a80f964a520d01c1fe3&quot;, … &quot;4cd2c49b2b52a09318a72039&quot;]</td><td>[&quot;Sun Apr 22 20:22:41 +0000 2012&quot;, &quot;Sun Apr 22 23:03:46 +0000 2012&quot;, … &quot;Mon May 06 01:08:32 +0000 2013&quot;]</td><td>[-420, -420, … -420]</td><td>26</td></tr><tr><td>249857</td><td>21</td><td>23</td><td>[&quot;4adb3e5df964a5202f2521e3&quot;, &quot;4aa65909f964a520c14920e3&quot;, … &quot;411c0480f964a5201a0c1fe3&quot;]</td><td>[&quot;Tue Jul 03 17:20:30 +0000 2012&quot;, &quot;Fri Jul 13 17:18:26 +0000 2012&quot;, … &quot;Thu Aug 08 20:55:11 +0000 2013&quot;]</td><td>[-300, -300, … -240]</td><td>21</td></tr><tr><td>49709</td><td>18</td><td>24</td><td>[&quot;4b0587fdf964a52034ab22e3&quot;, &quot;4c9ca2649975a14397b833cf&quot;, … &quot;4af833a6f964a5205a0b22e3&quot;]</td><td>[&quot;Sat Nov 17 01:40:22 +0000 2012&quot;, &quot;Sat Nov 17 02:50:24 +0000 2012&quot;, … &quot;Tue Aug 13 08:43:25 +0000 2013&quot;]</td><td>[420, 420, … 420]</td><td>18</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>98164</td><td>32</td><td>37</td><td>[&quot;4d5693c7ba5b224b5a581c14&quot;, &quot;4e3fb86018a83d5b2861d811&quot;, … &quot;4f4fce61e4b0b5f5b17cbfc4&quot;]</td><td>[&quot;Wed May 23 17:57:42 +0000 2012&quot;, &quot;Wed May 23 18:16:45 +0000 2012&quot;, … &quot;Fri Jul 05 22:50:16 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td><td>32</td></tr><tr><td>231293</td><td>27</td><td>45</td><td>[&quot;4f4936cae4b00005b946a261&quot;, &quot;4bd72e080b779c74bb9804a0&quot;, … &quot;4f031fc09adffb90d0134adf&quot;]</td><td>[&quot;Sat Apr 07 12:37:32 +0000 2012&quot;, &quot;Sun Apr 08 08:24:55 +0000 2012&quot;, … &quot;Wed May 08 12:25:32 +0000 2013&quot;]</td><td>[180, 180, … 180]</td><td>27</td></tr><tr><td>16360</td><td>28</td><td>32</td><td>[&quot;4be9582d4485d13af22494ee&quot;, &quot;4b658924f964a52091f32ae3&quot;, … &quot;4b63e1b3f964a52096952ae3&quot;]</td><td>[&quot;Mon Apr 16 15:14:49 +0000 2012&quot;, &quot;Tue Apr 17 16:40:19 +0000 2012&quot;, … &quot;Fri Jan 18 04:59:42 +0000 2013&quot;]</td><td>[480, 480, … 420]</td><td>28</td></tr><tr><td>190576</td><td>42</td><td>45</td><td>[&quot;4ab0402ff964a520ad6620e3&quot;, &quot;4a062e12f964a520ca721fe3&quot;, … &quot;4bd96841e914a593f25d56fa&quot;]</td><td>[&quot;Wed Apr 18 13:11:25 +0000 2012&quot;, &quot;Tue May 15 14:56:48 +0000 2012&quot;, … &quot;Fri Sep 06 12:54:14 +0000 2013&quot;]</td><td>[-240, -240, … 420]</td><td>42</td></tr><tr><td>28114</td><td>22</td><td>23</td><td>[&quot;4fe2d609e4b0391ded404fbd&quot;, &quot;4c8aa965770fb60ce7a2d4c3&quot;, … &quot;50ab1f79e4b02dee071f05c4&quot;]</td><td>[&quot;Sat Nov 17 10:06:44 +0000 2012&quot;, &quot;Mon Nov 19 16:23:54 +0000 2012&quot;, … &quot;Tue Feb 12 02:27:43 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td><td>22</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_697, 7)\n",
       "┌────────┬────────┬────────────┬─────────────────┬────────────────┬────────────────┬───────────────┐\n",
       "│ user   ┆ n_pois ┆ n_checkins ┆ pois            ┆ dates          ┆ TZs            ┆ n_unique_pois │\n",
       "│ ---    ┆ ---    ┆ ---        ┆ ---             ┆ ---            ┆ ---            ┆ ---           │\n",
       "│ i64    ┆ u32    ┆ u32        ┆ list[str]       ┆ list[str]      ┆ list[i64]      ┆ u32           │\n",
       "╞════════╪════════╪════════════╪═════════════════╪════════════════╪════════════════╪═══════════════╡\n",
       "│ 249664 ┆ 31     ┆ 41         ┆ [\"4bb21c0cf964a ┆ [\"Wed May 23   ┆ [240, 240, …   ┆ 31            │\n",
       "│        ┆        ┆            ┆ 5209ab93ce3\",   ┆ 16:02:52 +0000 ┆ 240]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 234554 ┆ 31     ┆ 45         ┆ [\"4bf60d51abdae ┆ [\"Fri Apr 06   ┆ [-300, -300, … ┆ 31            │\n",
       "│        ┆        ┆            ┆ f3bf02fa184\",   ┆ 16:17:45 +0000 ┆ -300]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 117383 ┆ 26     ┆ 29         ┆ [\"506db535e4b0e ┆ [\"Sun Apr 22   ┆ [-420, -420, … ┆ 26            │\n",
       "│        ┆        ┆            ┆ 36e9b7d3f8f\",   ┆ 20:22:41 +0000 ┆ -420]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 249857 ┆ 21     ┆ 23         ┆ [\"4adb3e5df964a ┆ [\"Tue Jul 03   ┆ [-300, -300, … ┆ 21            │\n",
       "│        ┆        ┆            ┆ 5202f2521e3\",   ┆ 17:20:30 +0000 ┆ -240]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 49709  ┆ 18     ┆ 24         ┆ [\"4b0587fdf964a ┆ [\"Sat Nov 17   ┆ [420, 420, …   ┆ 18            │\n",
       "│        ┆        ┆            ┆ 52034ab22e3\",   ┆ 01:40:22 +0000 ┆ 420]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ …      ┆ …      ┆ …          ┆ …               ┆ …              ┆ …              ┆ …             │\n",
       "│ 98164  ┆ 32     ┆ 37         ┆ [\"4d5693c7ba5b2 ┆ [\"Wed May 23   ┆ [-180, -180, … ┆ 32            │\n",
       "│        ┆        ┆            ┆ 24b5a581c14\",   ┆ 17:57:42 +0000 ┆ -180]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 231293 ┆ 27     ┆ 45         ┆ [\"4f4936cae4b00 ┆ [\"Sat Apr 07   ┆ [180, 180, …   ┆ 27            │\n",
       "│        ┆        ┆            ┆ 005b946a261\",   ┆ 12:37:32 +0000 ┆ 180]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 16360  ┆ 28     ┆ 32         ┆ [\"4be9582d4485d ┆ [\"Mon Apr 16   ┆ [480, 480, …   ┆ 28            │\n",
       "│        ┆        ┆            ┆ 13af22494ee\",   ┆ 15:14:49 +0000 ┆ 420]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 190576 ┆ 42     ┆ 45         ┆ [\"4ab0402ff964a ┆ [\"Wed Apr 18   ┆ [-240, -240, … ┆ 42            │\n",
       "│        ┆        ┆            ┆ 520ad6620e3\",   ┆ 13:11:25 +0000 ┆ 420]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 28114  ┆ 22     ┆ 23         ┆ [\"4fe2d609e4b03 ┆ [\"Sat Nov 17   ┆ [-180, -180, … ┆ 22            │\n",
       "│        ┆        ┆            ┆ 91ded404fbd\",   ┆ 10:06:44 +0000 ┆ -180]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "└────────┴────────┴────────────┴─────────────────┴────────────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = out[\"pois\"][0].to_list()\n",
    "len(set(l))  # print number of unique POIs in first sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = data_culled[\"pois\"][0].to_list()\n",
    "len(l2)  # print sequence length of first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(l2))  # confirm that the two match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a Polars query to obtain all the frequent POIs, the ones expected to survive the filtering\n",
    "unique_pois = out[\"pois\"]\n",
    "frequent_pois = unique_pois.list.explode().value_counts().filter(rs.col(\"count\") >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;4f7192fee4b022ab2187553e&quot;</td><td>10</td></tr><tr><td>&quot;41f43a80f964a520281f1fe3&quot;</td><td>12</td></tr><tr><td>&quot;4ca9dddbf47ea1433c2d8321&quot;</td><td>26</td></tr><tr><td>&quot;4b765f93f964a520dc492ee3&quot;</td><td>10</td></tr><tr><td>&quot;4451c80ef964a520a5321fe3&quot;</td><td>16</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4b5ae98ff964a52000da28e3&quot;</td><td>30</td></tr><tr><td>&quot;4d9cb215ef8f370474830aae&quot;</td><td>16</td></tr><tr><td>&quot;4b86baeaf964a520599931e3&quot;</td><td>34</td></tr><tr><td>&quot;4cf6211464e3721ef15a1fc8&quot;</td><td>22</td></tr><tr><td>&quot;4c35618b213c2d7f63213a5d&quot;</td><td>33</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 2)\n",
       "┌──────────────────────────┬───────┐\n",
       "│ pois                     ┆ count │\n",
       "│ ---                      ┆ ---   │\n",
       "│ str                      ┆ u32   │\n",
       "╞══════════════════════════╪═══════╡\n",
       "│ 4f7192fee4b022ab2187553e ┆ 10    │\n",
       "│ 41f43a80f964a520281f1fe3 ┆ 12    │\n",
       "│ 4ca9dddbf47ea1433c2d8321 ┆ 26    │\n",
       "│ 4b765f93f964a520dc492ee3 ┆ 10    │\n",
       "│ 4451c80ef964a520a5321fe3 ┆ 16    │\n",
       "│ …                        ┆ …     │\n",
       "│ 4b5ae98ff964a52000da28e3 ┆ 30    │\n",
       "│ 4d9cb215ef8f370474830aae ┆ 16    │\n",
       "│ 4b86baeaf964a520599931e3 ┆ 34    │\n",
       "│ 4cf6211464e3721ef15a1fc8 ┆ 22    │\n",
       "│ 4c35618b213c2d7f63213a5d ┆ 33    │\n",
       "└──────────────────────────┴───────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_pois = frequent_pois[\"pois\"]\n",
    "frequent_pois = set(frequent_pois.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_697, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td></tr></thead><tbody><tr><td>249664</td><td>31</td><td>41</td><td>[&quot;4ef1e0d16da16847cc6ed35e&quot;, &quot;4bbea7ae006dc9b6d096fb3f&quot;, … &quot;4b7163d8f964a52046442de3&quot;]</td><td>[&quot;Wed May 23 16:02:52 +0000 2012&quot;, &quot;Mon May 28 14:18:57 +0000 2012&quot;, … &quot;Thu Sep 05 08:25:32 +0000 2013&quot;]</td><td>[240, 240, … 240]</td></tr><tr><td>234554</td><td>31</td><td>45</td><td>[&quot;4bd3a4f3046076b098a77671&quot;, &quot;4bd3a4f3046076b098a77671&quot;, … &quot;4d34477f5017a09303a2599b&quot;]</td><td>[&quot;Fri Apr 06 16:17:45 +0000 2012&quot;, &quot;Sat Apr 07 19:34:33 +0000 2012&quot;, … &quot;Thu May 30 14:07:35 +0000 2013&quot;]</td><td>[-300, -300, … -300]</td></tr><tr><td>117383</td><td>26</td><td>29</td><td>[&quot;4b15503df964a5202eb023e3&quot;, &quot;40e0b100f964a5203c021fe3&quot;, … &quot;4a2f333df964a520b7981fe3&quot;]</td><td>[&quot;Sun Apr 22 20:22:41 +0000 2012&quot;, &quot;Sun Apr 22 23:03:46 +0000 2012&quot;, … &quot;Mon May 06 01:08:32 +0000 2013&quot;]</td><td>[-420, -420, … -420]</td></tr><tr><td>249857</td><td>21</td><td>23</td><td>[&quot;4b0aca7ef964a520e02723e3&quot;, &quot;4fe34634e4b0410e78edc187&quot;, … &quot;4a55c1f7f964a52046b41fe3&quot;]</td><td>[&quot;Tue Jul 03 17:20:30 +0000 2012&quot;, &quot;Fri Jul 13 17:18:26 +0000 2012&quot;, … &quot;Thu Aug 08 20:55:11 +0000 2013&quot;]</td><td>[-300, -300, … -240]</td></tr><tr><td>49709</td><td>18</td><td>24</td><td>[&quot;4b2df07cf964a5201bdc24e3&quot;, &quot;4d64a7547f84f04d774bf8b4&quot;, … &quot;4b2df07cf964a5201bdc24e3&quot;]</td><td>[&quot;Sat Nov 17 01:40:22 +0000 2012&quot;, &quot;Sat Nov 17 02:50:24 +0000 2012&quot;, … &quot;Tue Aug 13 08:43:25 +0000 2013&quot;]</td><td>[420, 420, … 420]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>98164</td><td>32</td><td>37</td><td>[&quot;4e1c6e5f45dd94fe4a52c2ed&quot;, &quot;4da052d7784f3704a8bf96af&quot;, … &quot;4f6a6fe4e4b0d8154b452fbe&quot;]</td><td>[&quot;Wed May 23 17:57:42 +0000 2012&quot;, &quot;Wed May 23 18:16:45 +0000 2012&quot;, … &quot;Fri Jul 05 22:50:16 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td></tr><tr><td>231293</td><td>27</td><td>45</td><td>[&quot;4b860111f964a520327d31e3&quot;, &quot;4f814b51e4b088077f9e67ff&quot;, … &quot;4b7ac5ebf964a5200d3c2fe3&quot;]</td><td>[&quot;Sat Apr 07 12:37:32 +0000 2012&quot;, &quot;Sun Apr 08 08:24:55 +0000 2012&quot;, … &quot;Wed May 08 12:25:32 +0000 2013&quot;]</td><td>[180, 180, … 180]</td></tr><tr><td>16360</td><td>28</td><td>32</td><td>[&quot;4c6ea27df323bfb72ebd2499&quot;, &quot;4c6ea27df323bfb72ebd2499&quot;, … &quot;4bb711d62f70c9b66e448630&quot;]</td><td>[&quot;Mon Apr 16 15:14:49 +0000 2012&quot;, &quot;Tue Apr 17 16:40:19 +0000 2012&quot;, … &quot;Fri Jan 18 04:59:42 +0000 2013&quot;]</td><td>[480, 480, … 420]</td></tr><tr><td>190576</td><td>42</td><td>45</td><td>[&quot;49c6d05ef964a52082571fe3&quot;, &quot;4e70a36d922e8e01baadf45c&quot;, … &quot;4b794beef964a520bef22ee3&quot;]</td><td>[&quot;Wed Apr 18 13:11:25 +0000 2012&quot;, &quot;Tue May 15 14:56:48 +0000 2012&quot;, … &quot;Fri Sep 06 12:54:14 +0000 2013&quot;]</td><td>[-240, -240, … 420]</td></tr><tr><td>28114</td><td>22</td><td>23</td><td>[&quot;4f5c20dde4b068aa4f098f10&quot;, &quot;4fe2d609e4b0391ded404fbd&quot;, … &quot;50ab1f79e4b02dee071f05c4&quot;]</td><td>[&quot;Sat Nov 17 10:06:44 +0000 2012&quot;, &quot;Mon Nov 19 16:23:54 +0000 2012&quot;, … &quot;Tue Feb 12 02:27:43 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_697, 6)\n",
       "┌────────┬────────┬────────────┬──────────────────────┬──────────────────────┬─────────────────────┐\n",
       "│ user   ┆ n_pois ┆ n_checkins ┆ pois                 ┆ dates                ┆ TZs                 │\n",
       "│ ---    ┆ ---    ┆ ---        ┆ ---                  ┆ ---                  ┆ ---                 │\n",
       "│ i64    ┆ u32    ┆ u32        ┆ list[str]            ┆ list[str]            ┆ list[i64]           │\n",
       "╞════════╪════════╪════════════╪══════════════════════╪══════════════════════╪═════════════════════╡\n",
       "│ 249664 ┆ 31     ┆ 41         ┆ [\"4ef1e0d16da16847cc ┆ [\"Wed May 23         ┆ [240, 240, … 240]   │\n",
       "│        ┆        ┆            ┆ 6ed35e\", \"…          ┆ 16:02:52 +0000 20…   ┆                     │\n",
       "│ 234554 ┆ 31     ┆ 45         ┆ [\"4bd3a4f3046076b098 ┆ [\"Fri Apr 06         ┆ [-300, -300, …      │\n",
       "│        ┆        ┆            ┆ a77671\", \"…          ┆ 16:17:45 +0000 20…   ┆ -300]               │\n",
       "│ 117383 ┆ 26     ┆ 29         ┆ [\"4b15503df964a5202e ┆ [\"Sun Apr 22         ┆ [-420, -420, …      │\n",
       "│        ┆        ┆            ┆ b023e3\", \"…          ┆ 20:22:41 +0000 20…   ┆ -420]               │\n",
       "│ 249857 ┆ 21     ┆ 23         ┆ [\"4b0aca7ef964a520e0 ┆ [\"Tue Jul 03         ┆ [-300, -300, …      │\n",
       "│        ┆        ┆            ┆ 2723e3\", \"…          ┆ 17:20:30 +0000 20…   ┆ -240]               │\n",
       "│ 49709  ┆ 18     ┆ 24         ┆ [\"4b2df07cf964a5201b ┆ [\"Sat Nov 17         ┆ [420, 420, … 420]   │\n",
       "│        ┆        ┆            ┆ dc24e3\", \"…          ┆ 01:40:22 +0000 20…   ┆                     │\n",
       "│ …      ┆ …      ┆ …          ┆ …                    ┆ …                    ┆ …                   │\n",
       "│ 98164  ┆ 32     ┆ 37         ┆ [\"4e1c6e5f45dd94fe4a ┆ [\"Wed May 23         ┆ [-180, -180, …      │\n",
       "│        ┆        ┆            ┆ 52c2ed\", \"…          ┆ 17:57:42 +0000 20…   ┆ -180]               │\n",
       "│ 231293 ┆ 27     ┆ 45         ┆ [\"4b860111f964a52032 ┆ [\"Sat Apr 07         ┆ [180, 180, … 180]   │\n",
       "│        ┆        ┆            ┆ 7d31e3\", \"…          ┆ 12:37:32 +0000 20…   ┆                     │\n",
       "│ 16360  ┆ 28     ┆ 32         ┆ [\"4c6ea27df323bfb72e ┆ [\"Mon Apr 16         ┆ [480, 480, … 420]   │\n",
       "│        ┆        ┆            ┆ bd2499\", \"…          ┆ 15:14:49 +0000 20…   ┆                     │\n",
       "│ 190576 ┆ 42     ┆ 45         ┆ [\"49c6d05ef964a52082 ┆ [\"Wed Apr 18         ┆ [-240, -240, … 420] │\n",
       "│        ┆        ┆            ┆ 571fe3\", \"…          ┆ 13:11:25 +0000 20…   ┆                     │\n",
       "│ 28114  ┆ 22     ┆ 23         ┆ [\"4f5c20dde4b068aa4f ┆ [\"Sat Nov 17         ┆ [-180, -180, …      │\n",
       "│        ┆        ┆            ┆ 098f10\", \"…          ┆ 10:06:44 +0000 20…   ┆ -180]               │\n",
       "└────────┴────────┴────────────┴──────────────────────┴──────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_culled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_culled = data_culled.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\")\n",
    "        .list.eval(\n",
    "            rs.element().is_in(frequent_pois),\n",
    "        )\n",
    "        .alias(\"is_frequent\")\n",
    "    ]\n",
    ")  # prep mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = (\n",
    "    data_culled.lazy()\n",
    "    .with_row_index()\n",
    "    .explode(\n",
    "        [\n",
    "            \"pois\",\n",
    "            \"dates\",\n",
    "            \"TZs\",\n",
    "            \"is_frequent\",\n",
    "        ]\n",
    "    )\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        [\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).alias(\"pois\"),\n",
    "            rs.col(\"dates\").filter(rs.col(\"is_frequent\")).alias(\"dates\"),\n",
    "            rs.col(\"TZs\").filter(rs.col(\"is_frequent\")).alias(\"TZs\"),\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).n_unique().alias(\"n_pois\"),\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).count().alias(\"n_checkins\"),\n",
    "        ]\n",
    "    )\n",
    "    .filter(rs.col(\"n_checkins\") > 0)\n",
    "    .filter(rs.col(\"n_pois\") > 0)\n",
    "    .collect()\n",
    ")  # filter out infrequent pois and users with no pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>pois</th><th>dates</th><th>TZs</th><th>n_pois</th><th>n_checkins</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>156852.822274</td><td>null</td><td>null</td><td>null</td><td>6.123452</td><td>8.831437</td></tr><tr><td>&quot;std&quot;</td><td>76314.892884</td><td>null</td><td>null</td><td>null</td><td>4.609024</td><td>6.877662</td></tr><tr><td>&quot;min&quot;</td><td>49.0</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>95613.0</td><td>null</td><td>null</td><td>null</td><td>3.0</td><td>4.0</td></tr><tr><td>&quot;50%&quot;</td><td>167846.0</td><td>null</td><td>null</td><td>null</td><td>5.0</td><td>7.0</td></tr><tr><td>&quot;75%&quot;</td><td>224576.0</td><td>null</td><td>null</td><td>null</td><td>8.0</td><td>12.0</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>null</td><td>null</td><td>null</td><td>32.0</td><td>46.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬───────────────┬─────────┬─────────┬─────────┬──────────┬────────────┐\n",
       "│ statistic  ┆ user          ┆ pois    ┆ dates   ┆ TZs     ┆ n_pois   ┆ n_checkins │\n",
       "│ ---        ┆ ---           ┆ ---     ┆ ---     ┆ ---     ┆ ---      ┆ ---        │\n",
       "│ str        ┆ f64           ┆ f64     ┆ f64     ┆ f64     ┆ f64      ┆ f64        │\n",
       "╞════════════╪═══════════════╪═════════╪═════════╪═════════╪══════════╪════════════╡\n",
       "│ count      ┆ 19862.0       ┆ 19862.0 ┆ 19862.0 ┆ 19862.0 ┆ 19862.0  ┆ 19862.0    │\n",
       "│ null_count ┆ 0.0           ┆ 0.0     ┆ 0.0     ┆ 0.0     ┆ 0.0      ┆ 0.0        │\n",
       "│ mean       ┆ 156852.822274 ┆ null    ┆ null    ┆ null    ┆ 6.123452 ┆ 8.831437   │\n",
       "│ std        ┆ 76314.892884  ┆ null    ┆ null    ┆ null    ┆ 4.609024 ┆ 6.877662   │\n",
       "│ min        ┆ 49.0          ┆ null    ┆ null    ┆ null    ┆ 1.0      ┆ 1.0        │\n",
       "│ 25%        ┆ 95613.0       ┆ null    ┆ null    ┆ null    ┆ 3.0      ┆ 4.0        │\n",
       "│ 50%        ┆ 167846.0      ┆ null    ┆ null    ┆ null    ┆ 5.0      ┆ 7.0        │\n",
       "│ 75%        ┆ 224576.0      ┆ null    ┆ null    ┆ null    ┆ 8.0      ┆ 12.0       │\n",
       "│ max        ┆ 266909.0      ┆ null    ┆ null    ┆ null    ┆ 32.0     ┆ 46.0       │\n",
       "└────────────┴───────────────┴─────────┴─────────┴─────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, culling is done, we can appreciate that `polars`'s SQL/functional-style API is different from Pandas, but it is very powerful and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is geohashing the POIs, that is, we want to convert the latitude-longitude positions of the POIs into a grid-based geohash representation, which will form the basis for our network's embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash2 as gh\n",
    "\n",
    "pois = rs.read_csv(\n",
    "    \"dataset_TIST2015/dataset_TIST2015_POIs.txt\",\n",
    "    has_header=False,\n",
    "    low_memory=True,\n",
    "    separator=\"\\t\",\n",
    ")\n",
    "pois.columns = [\"poi\", \"lat\", \"long\", \"category\", \"country\"]\n",
    "pois = pois.drop(\"category\").drop(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = (\n",
    "    pois.lazy()\n",
    "    .filter(rs.col(\"poi\").is_in(frequent_pois))\n",
    "    .select(\n",
    "        [\n",
    "            rs.col(\"poi\"),\n",
    "            rs.struct(\n",
    "                [\n",
    "                    rs.col(\"lat\").cast(rs.Float32),\n",
    "                    rs.col(\"long\").cast(rs.Float32),\n",
    "                ]\n",
    "            )\n",
    "            .alias(\"location\")\n",
    "            .map_elements(\n",
    "                lambda s: gh.encode(s[\"lat\"], s[\"long\"], precision=6),\n",
    "                return_dtype=rs.String,\n",
    "            )\n",
    "            .alias(\"geohash\"),\n",
    "        ]\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "poi_geo_dict = dict(zip(pois[\"poi\"], pois[\"geohash\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row in final_data, add the geohash of the pois by hitting the poi_geo_dict\n",
    "\n",
    "final_data = final_data.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\")\n",
    "        .map_elements(\n",
    "            lambda s: [poi_geo_dict[s] for s in s],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "        .alias(\"geohashes\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sat Mar 30 08:31:42 +0000 2013',\n",
       " 'Tue Aug 20 09:57:12 +0000 2013',\n",
       " 'Sun Aug 25 02:07:24 +0000 2013']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"dates\"][79].to_list()  # check out a temporal sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[420, 420, 420]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"TZs\"][79].to_list()  # ... and the corresponding timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work *might* seem over, however, we still have timezones to account for, we want to normalize everything according to GMT, so we convert the timestamps accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def UTC_to_local(utc, tz):\n",
    "\n",
    "    date = datetime.datetime.strptime(utc, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    date = date.replace(tzinfo=datetime.timezone.utc)\n",
    "\n",
    "    # shift by tz offset\n",
    "    date = date.astimezone(datetime.timezone(datetime.timedelta(minutes=tz)))\n",
    "\n",
    "    date_s = datetime.datetime.strftime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return date_s\n",
    "\n",
    "\n",
    "def to_UNIX_time(date):\n",
    "    return datetime.datetime.strptime(\n",
    "        date, \"%Y-%m-%d %H:%M:%S\"\n",
    "    ).timestamp()  # we use UNIX time as a key for sorting the POIs in our polars query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-05-21 08:53:01'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UTC_to_local(\"Mon May 21 15:53:01 +0000 2012\", -420)  # example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.with_columns(\n",
    "    [\n",
    "        rs.struct([rs.col(\"dates\"), rs.col(\"TZs\")])\n",
    "        .alias(\"times\")\n",
    "        .map_elements(\n",
    "            lambda struct: [\n",
    "                UTC_to_local(date, tz)\n",
    "                for date, tz in zip(struct[\"dates\"], struct[\"TZs\"])\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "    ]\n",
    ")  # This performs timezone conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sorted = final_data.select(  # sort the times\n",
    "    [\n",
    "        rs.col(\"user\"),\n",
    "        rs.struct(\n",
    "            [\n",
    "                rs.col(\"pois\"),\n",
    "                rs.col(\"times\"),\n",
    "            ]\n",
    "        ).map_elements(\n",
    "            lambda struct: [\n",
    "                poi\n",
    "                for poi, _ in sorted(\n",
    "                    zip(  # here we sort the POIs struct by UNIX timestamps of the GMT times\n",
    "                        struct[\"pois\"], [to_UNIX_time(date) for date in struct[\"times\"]]\n",
    "                    ),\n",
    "                    key=lambda s: s[1],\n",
    "                )\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        ),\n",
    "        rs.struct(\n",
    "            [\n",
    "                rs.col(\"geohashes\"),\n",
    "                rs.col(\"times\"),\n",
    "            ]\n",
    "        ).map_elements(\n",
    "            lambda struct: [\n",
    "                geo\n",
    "                for geo, _ in sorted(\n",
    "                    zip(\n",
    "                        struct[\"geohashes\"],  # same thing goes on for geohashes\n",
    "                        [to_UNIX_time(date) for date in struct[\"times\"]],\n",
    "                    ),\n",
    "                    key=lambda s: s[1],\n",
    "                )\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        ),\n",
    "        rs.col(\"times\")\n",
    "        .map_elements(\n",
    "            lambda dates: sorted(dates, key=to_UNIX_time),\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "        .alias(\"times_sorted\"),\n",
    "        rs.col(\"n_checkins\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# P.S, admittedly, it would have been more efficient to encode the geohashes *after* sorting the POIs,\n",
    "# so that we could save on the sorting of the geohashes. Tough luck, you can't win 'em all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (19_862, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>pois</th><th>geohashes</th><th>times_sorted</th><th>n_checkins</th></tr><tr><td>i64</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>u32</td></tr></thead><tbody><tr><td>256994</td><td>[&quot;4b9532c8f964a520639434e3&quot;, &quot;430a6700f964a52036271fe3&quot;, … &quot;4be1ae703ef676b0e44ec0ca&quot;]</td><td>[&quot;dr46se&quot;, &quot;dqcjr9&quot;, … &quot;dr5x82&quot;]</td><td>[&quot;2012-05-13 12:11:37&quot;, &quot;2012-06-21 06:57:17&quot;, … &quot;2012-10-12 21:15:46&quot;]</td><td>18</td></tr><tr><td>166422</td><td>[&quot;43ba62b4f964a520e72c1fe3&quot;, &quot;45073758f964a52021391fe3&quot;, … &quot;4b10b461f964a520f17423e3&quot;]</td><td>[&quot;9q9k96&quot;, &quot;9q8yyv&quot;, … &quot;dn6m9q&quot;]</td><td>[&quot;2012-04-22 23:04:14&quot;, &quot;2012-05-04 17:56:21&quot;, … &quot;2013-04-12 21:01:55&quot;]</td><td>7</td></tr><tr><td>36332</td><td>[&quot;4b4dbb3ff964a52074d626e3&quot;, &quot;4b48b393f964a520585326e3&quot;, &quot;4d6ea39c134ea143d699931a&quot;]</td><td>[&quot;6vjvtw&quot;, &quot;6vjvut&quot;, &quot;75cnj4&quot;]</td><td>[&quot;2012-04-27 12:33:53&quot;, &quot;2012-04-28 21:37:15&quot;, &quot;2012-08-19 21:44:14&quot;]</td><td>3</td></tr><tr><td>123397</td><td>[&quot;4bb37f77eb3e9521c034cb0a&quot;, &quot;4bb37f77eb3e9521c034cb0a&quot;, … &quot;4bb37f77eb3e9521c034cb0a&quot;]</td><td>[&quot;75cnm0&quot;, &quot;75cnm0&quot;, … &quot;75cnm0&quot;]</td><td>[&quot;2012-11-26 07:33:21&quot;, &quot;2012-12-04 07:57:52&quot;, … &quot;2013-01-29 08:16:31&quot;]</td><td>11</td></tr><tr><td>75924</td><td>[&quot;4adcdaf3f964a520815c21e3&quot;, &quot;4b876cf4f964a520eebe31e3&quot;, &quot;4adcdaf3f964a520815c21e3&quot;]</td><td>[&quot;u6sc8m&quot;, &quot;u09ycf&quot;, &quot;u6sc8m&quot;]</td><td>[&quot;2012-04-27 14:36:26&quot;, &quot;2012-10-26 13:21:29&quot;, &quot;2013-05-08 17:31:55&quot;]</td><td>3</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>218437</td><td>[&quot;4b37981ff964a520b84225e3&quot;, &quot;4e53023d45ddffa8d188a50e&quot;, … &quot;4b59181cf964a5203f7c28e3&quot;]</td><td>[&quot;9g3qvz&quot;, &quot;9g3w96&quot;, … &quot;9g3wb4&quot;]</td><td>[&quot;2012-04-15 12:14:10&quot;, &quot;2012-04-15 16:52:55&quot;, … &quot;2013-08-04 22:08:26&quot;]</td><td>8</td></tr><tr><td>247987</td><td>[&quot;4b86b2a7f964a520f89631e3&quot;, &quot;4ad94f83f964a520b91921e3&quot;, … &quot;4b0586e3f964a520867322e3&quot;]</td><td>[&quot;dpz2s0&quot;, &quot;dpz839&quot;, … &quot;f241y4&quot;]</td><td>[&quot;2012-05-19 12:06:25&quot;, &quot;2012-05-19 15:03:06&quot;, … &quot;2013-07-28 17:45:20&quot;]</td><td>18</td></tr><tr><td>266315</td><td>[&quot;4d39e3eefa736ea85cdd108a&quot;, &quot;4d39e3eefa736ea85cdd108a&quot;, … &quot;4b8bc40bf964a5204faa32e3&quot;]</td><td>[&quot;75cqhk&quot;, &quot;75cqhk&quot;, … &quot;75cq5y&quot;]</td><td>[&quot;2013-01-31 14:12:38&quot;, &quot;2013-01-31 14:12:38&quot;, … &quot;2013-09-03 13:59:33&quot;]</td><td>5</td></tr><tr><td>74113</td><td>[&quot;4bb7d18153649c74975446fb&quot;, &quot;4d7b7d69da568cfafa9351ff&quot;, … &quot;4bb7d18153649c74975446fb&quot;]</td><td>[&quot;sychrh&quot;, &quot;sxk9s8&quot;, … &quot;sychrh&quot;]</td><td>[&quot;2013-06-06 13:26:23&quot;, &quot;2013-06-24 13:13:14&quot;, … &quot;2013-09-04 10:08:10&quot;]</td><td>21</td></tr><tr><td>213566</td><td>[&quot;4ac518d1f964a520c3a620e3&quot;, &quot;4d5ed23c149637047e12cf94&quot;, … &quot;4e175b25183880768f35a7e5&quot;]</td><td>[&quot;gcpvj1&quot;, &quot;gcpvj1&quot;, … &quot;gcpuut&quot;]</td><td>[&quot;2012-12-11 12:49:44&quot;, &quot;2012-12-12 19:54:37&quot;, … &quot;2013-05-27 21:43:14&quot;]</td><td>9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (19_862, 5)\n",
       "┌────────┬──────────────────────────────┬────────────────────────┬────────────────────┬────────────┐\n",
       "│ user   ┆ pois                         ┆ geohashes              ┆ times_sorted       ┆ n_checkins │\n",
       "│ ---    ┆ ---                          ┆ ---                    ┆ ---                ┆ ---        │\n",
       "│ i64    ┆ list[str]                    ┆ list[str]              ┆ list[str]          ┆ u32        │\n",
       "╞════════╪══════════════════════════════╪════════════════════════╪════════════════════╪════════════╡\n",
       "│ 256994 ┆ [\"4b9532c8f964a520639434e3\", ┆ [\"dr46se\", \"dqcjr9\", … ┆ [\"2012-05-13       ┆ 18         │\n",
       "│        ┆ \"…                           ┆ \"dr5x82…               ┆ 12:11:37\", \"2012-… ┆            │\n",
       "│ 166422 ┆ [\"43ba62b4f964a520e72c1fe3\", ┆ [\"9q9k96\", \"9q8yyv\", … ┆ [\"2012-04-22       ┆ 7          │\n",
       "│        ┆ \"…                           ┆ \"dn6m9q…               ┆ 23:04:14\", \"2012-… ┆            │\n",
       "│ 36332  ┆ [\"4b4dbb3ff964a52074d626e3\", ┆ [\"6vjvtw\", \"6vjvut\",   ┆ [\"2012-04-27       ┆ 3          │\n",
       "│        ┆ \"…                           ┆ \"75cnj4\"]              ┆ 12:33:53\", \"2012-… ┆            │\n",
       "│ 123397 ┆ [\"4bb37f77eb3e9521c034cb0a\", ┆ [\"75cnm0\", \"75cnm0\", … ┆ [\"2012-11-26       ┆ 11         │\n",
       "│        ┆ \"…                           ┆ \"75cnm0…               ┆ 07:33:21\", \"2012-… ┆            │\n",
       "│ 75924  ┆ [\"4adcdaf3f964a520815c21e3\", ┆ [\"u6sc8m\", \"u09ycf\",   ┆ [\"2012-04-27       ┆ 3          │\n",
       "│        ┆ \"…                           ┆ \"u6sc8m\"]              ┆ 14:36:26\", \"2012-… ┆            │\n",
       "│ …      ┆ …                            ┆ …                      ┆ …                  ┆ …          │\n",
       "│ 218437 ┆ [\"4b37981ff964a520b84225e3\", ┆ [\"9g3qvz\", \"9g3w96\", … ┆ [\"2012-04-15       ┆ 8          │\n",
       "│        ┆ \"…                           ┆ \"9g3wb4…               ┆ 12:14:10\", \"2012-… ┆            │\n",
       "│ 247987 ┆ [\"4b86b2a7f964a520f89631e3\", ┆ [\"dpz2s0\", \"dpz839\", … ┆ [\"2012-05-19       ┆ 18         │\n",
       "│        ┆ \"…                           ┆ \"f241y4…               ┆ 12:06:25\", \"2012-… ┆            │\n",
       "│ 266315 ┆ [\"4d39e3eefa736ea85cdd108a\", ┆ [\"75cqhk\", \"75cqhk\", … ┆ [\"2013-01-31       ┆ 5          │\n",
       "│        ┆ \"…                           ┆ \"75cq5y…               ┆ 14:12:38\", \"2013-… ┆            │\n",
       "│ 74113  ┆ [\"4bb7d18153649c74975446fb\", ┆ [\"sychrh\", \"sxk9s8\", … ┆ [\"2013-06-06       ┆ 21         │\n",
       "│        ┆ \"…                           ┆ \"sychrh…               ┆ 13:26:23\", \"2013-… ┆            │\n",
       "│ 213566 ┆ [\"4ac518d1f964a520c3a620e3\", ┆ [\"gcpvj1\", \"gcpvj1\", … ┆ [\"2012-12-11       ┆ 9          │\n",
       "│        ┆ \"…                           ┆ \"gcpuut…               ┆ 12:49:44\", \"2012-… ┆            │\n",
       "└────────┴──────────────────────────────┴────────────────────────┴────────────────────┴────────────┘"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now need to obtain a dataframe containing: each POI, it's geohash, and a set of all the check-ins it appears in\n",
    "this is just one `polars` query away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_checkins = final_sorted.explode([\"pois\", \"geohashes\"]).drop(\"n_checkins\")\n",
    "\n",
    "pois_checkins = (\n",
    "    pois_checkins.with_columns(\n",
    "        [\n",
    "            rs.col(\"geohashes\").map_elements(lambda s: s[:4], rs.String).alias(\"g4\"),\n",
    "        ]\n",
    "    )\n",
    "    .drop(\"geohashes\")\n",
    "    .group_by([\"pois\", \"g4\"])\n",
    "    .agg([rs.col(\"times_sorted\").flatten().alias(\"checkin_times\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4b84dd37f964a5200a4631e3&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-07-17 18:22:36&quot;, &quot;2012-08-09 18:00:48&quot;, … &quot;2013-08-23 14:19:15&quot;]</td></tr><tr><td>&quot;4b683963f964a520c66c2be3&quot;</td><td>&quot;66jc&quot;</td><td>[&quot;2012-05-04 18:13:51&quot;, &quot;2012-05-05 20:46:02&quot;, … &quot;2012-08-16 12:22:44&quot;]</td></tr><tr><td>&quot;4c9e6e2a7c096dcb3d32d5d1&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-11-02 00:04:33&quot;, &quot;2012-11-02 00:41:38&quot;, … &quot;2013-08-05 00:52:41&quot;]</td></tr><tr><td>&quot;4b56cf5df964a520d11b28e3&quot;</td><td>&quot;xn0j&quot;</td><td>[&quot;2012-06-18 08:29:08&quot;, &quot;2012-06-18 08:43:22&quot;, … &quot;2013-07-20 14:25:25&quot;]</td></tr><tr><td>&quot;4d4d2db24aa3a093d7eb3fae&quot;</td><td>&quot;swvs&quot;</td><td>[&quot;2013-02-28 08:27:47&quot;, &quot;2013-03-14 08:47:58&quot;, … &quot;2013-09-07 22:58:31&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4cea74b8e888f04d743b4d6b&quot;</td><td>&quot;sp36&quot;</td><td>[&quot;2012-12-07 18:13:45&quot;, &quot;2012-12-23 08:55:53&quot;, … &quot;2013-03-15 08:34:50&quot;]</td></tr><tr><td>&quot;4c993bbf9818ef3bc0751afa&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2013-04-28 13:18:52&quot;, &quot;2013-07-09 14:39:55&quot;, … &quot;2013-08-27 12:53:39&quot;]</td></tr><tr><td>&quot;4dd198d5fa767fb707804fc8&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-10-16 20:41:13&quot;, &quot;2012-11-12 18:42:43&quot;, … &quot;2013-09-16 13:17:09&quot;]</td></tr><tr><td>&quot;4bad20dff964a5208a303be3&quot;</td><td>&quot;djgz&quot;</td><td>[&quot;2012-07-07 21:00:17&quot;, &quot;2012-07-29 14:22:24&quot;, … &quot;2013-03-20 13:51:23&quot;]</td></tr><tr><td>&quot;4d49b3554509721e852e27b0&quot;</td><td>&quot;6gyf&quot;</td><td>[&quot;2012-04-05 06:29:30&quot;, &quot;2012-04-14 15:03:10&quot;, … &quot;2013-08-08 13:47:26&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 3)\n",
       "┌──────────────────────────┬──────┬─────────────────────────────────┐\n",
       "│ pois                     ┆ g4   ┆ checkin_times                   │\n",
       "│ ---                      ┆ ---  ┆ ---                             │\n",
       "│ str                      ┆ str  ┆ list[str]                       │\n",
       "╞══════════════════════════╪══════╪═════════════════════════════════╡\n",
       "│ 4b84dd37f964a5200a4631e3 ┆ sxk9 ┆ [\"2012-07-17 18:22:36\", \"2012-… │\n",
       "│ 4b683963f964a520c66c2be3 ┆ 66jc ┆ [\"2012-05-04 18:13:51\", \"2012-… │\n",
       "│ 4c9e6e2a7c096dcb3d32d5d1 ┆ sxk9 ┆ [\"2012-11-02 00:04:33\", \"2012-… │\n",
       "│ 4b56cf5df964a520d11b28e3 ┆ xn0j ┆ [\"2012-06-18 08:29:08\", \"2012-… │\n",
       "│ 4d4d2db24aa3a093d7eb3fae ┆ swvs ┆ [\"2013-02-28 08:27:47\", \"2013-… │\n",
       "│ …                        ┆ …    ┆ …                               │\n",
       "│ 4cea74b8e888f04d743b4d6b ┆ sp36 ┆ [\"2012-12-07 18:13:45\", \"2012-… │\n",
       "│ 4c993bbf9818ef3bc0751afa ┆ sxk9 ┆ [\"2013-04-28 13:18:52\", \"2013-… │\n",
       "│ 4dd198d5fa767fb707804fc8 ┆ sxk9 ┆ [\"2012-10-16 20:41:13\", \"2012-… │\n",
       "│ 4bad20dff964a5208a303be3 ┆ djgz ┆ [\"2012-07-07 21:00:17\", \"2012-… │\n",
       "│ 4d49b3554509721e852e27b0 ┆ 6gyf ┆ [\"2012-04-05 06:29:30\", \"2012-… │\n",
       "└──────────────────────────┴──────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_checkins  # with this we can *efficiently* build our POI-POI spatial-temporal graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UTC_to_weekslot(utc: str) -> int:\n",
    "    \"\"\"UTC_to_weekslot converts a UTC timestamp to a weekslot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    utc : str\n",
    "        A string representing a UTC timestamp.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        A weekslot in the range [0, 56).\n",
    "    \"\"\"\n",
    "\n",
    "    date = datetime.datetime.strptime(utc, \"%Y-%m-%d %H:%M:%S\")\n",
    "    week = date.weekday()\n",
    "    hour = date.hour\n",
    "\n",
    "    return week * 8 + hour // 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to encode all of our inputs for our neural networks, this could *probably* be done \n",
    "with polars magic, but it's too delicate and we prefer classic for-looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dict = {\n",
    "    \"users\": LabelEncoder(),\n",
    "    \"pois\": LabelEncoder(),\n",
    "    \"g2\": LabelEncoder(),\n",
    "    \"g3\": LabelEncoder(),\n",
    "    \"g4\": LabelEncoder(),\n",
    "    \"g5\": LabelEncoder(),\n",
    "    \"g6\": LabelEncoder(),\n",
    "}\n",
    "\n",
    "encoded_data = {\n",
    "    \"users\": [],\n",
    "    \"pois\": [],\n",
    "    \"g2\": [],\n",
    "    \"g3\": [],\n",
    "    \"g4\": [],\n",
    "    \"g5\": [],\n",
    "    \"g6\": [],\n",
    "}\n",
    "\n",
    "unique_data = {\n",
    "    \"users\": set(),\n",
    "    \"pois\": set(),\n",
    "    \"g2\": set(),\n",
    "    \"g3\": set(),\n",
    "    \"g4\": set(),\n",
    "    \"g5\": set(),\n",
    "    \"g6\": set(),\n",
    "}\n",
    "\n",
    "# quick and dirty encoding:\n",
    "# 1. put every unique symbol in a list\n",
    "# 2. fit the respective encoder\n",
    "# 3. transform the lists\n",
    "\n",
    "for i, row in enumerate(final_sorted.iter_rows()):\n",
    "\n",
    "    user, pois, geohashes, times_sorted, n_checkins = row\n",
    "\n",
    "    g2 = [geo[:2] for geo in geohashes]\n",
    "    g3 = [geo[:3] for geo in geohashes]\n",
    "    g4 = [geo[:4] for geo in geohashes]\n",
    "    g5 = [geo[:5] for geo in geohashes]\n",
    "    g6 = [geo[:6] for geo in geohashes]  # redundant, but I like symmetry\n",
    "\n",
    "    unique_data[\"users\"].add(user)\n",
    "    unique_data[\"pois\"].update(pois)\n",
    "    unique_data[\"g2\"].update(g2)\n",
    "    unique_data[\"g3\"].update(g3)\n",
    "    unique_data[\"g4\"].update(g4)\n",
    "    unique_data[\"g5\"].update(g5)\n",
    "    unique_data[\"g6\"].update(g6)\n",
    "\n",
    "for property, enc, data in zip(\n",
    "    encoder_dict.keys(), encoder_dict.values(), unique_data.values()\n",
    "):\n",
    "    enc.fit(list(data))\n",
    "    encoder_dict[property] = enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19862 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19862/19862 [03:12<00:00, 102.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# this could be optimized, right now it takes a while, at least we have a nice progress bar to look at\n",
    "\n",
    "ds_size = len(final_sorted)\n",
    "\n",
    "for i, row in tqdm(enumerate(final_sorted.iter_rows()), total=ds_size):\n",
    "\n",
    "    user, pois, geohashes, times_sorted, n_checkins = row\n",
    "\n",
    "    g2 = [geo[:2] for geo in geohashes]\n",
    "    g3 = [geo[:3] for geo in geohashes]\n",
    "    g4 = [geo[:4] for geo in geohashes]\n",
    "    g5 = [geo[:5] for geo in geohashes]\n",
    "    g6 = [geo[:6] for geo in geohashes]\n",
    "\n",
    "    encoded_data[\"users\"].append(encoder_dict[\"users\"].transform([user])[0])\n",
    "    encoded_data[\"pois\"].append(encoder_dict[\"pois\"].transform(pois))\n",
    "    encoded_data[\"g2\"].append(encoder_dict[\"g2\"].transform(g2))\n",
    "    encoded_data[\"g3\"].append(encoder_dict[\"g3\"].transform(g3))\n",
    "    encoded_data[\"g4\"].append(encoder_dict[\"g4\"].transform(g4))\n",
    "    encoded_data[\"g5\"].append(encoder_dict[\"g5\"].transform(g5))\n",
    "    encoded_data[\"g6\"].append(encoder_dict[\"g6\"].transform(g6))\n",
    "\n",
    "    # sum 1 to all values to avoid 0s\n",
    "    encoded_data[\"users\"][-1] += 1\n",
    "    encoded_data[\"pois\"][-1] += 1\n",
    "    encoded_data[\"g2\"][-1] += 1\n",
    "    encoded_data[\"g3\"][-1] += 1\n",
    "    encoded_data[\"g4\"][-1] += 1\n",
    "    encoded_data[\"g5\"][-1] += 1\n",
    "    encoded_data[\"g6\"][-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we left space for the padding token\n",
    "min((arr.min() for arr in encoded_data[\"pois\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4b84dd37f964a5200a4631e3&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-07-17 18:22:36&quot;, &quot;2012-08-09 18:00:48&quot;, … &quot;2013-08-23 14:19:15&quot;]</td></tr><tr><td>&quot;4b683963f964a520c66c2be3&quot;</td><td>&quot;66jc&quot;</td><td>[&quot;2012-05-04 18:13:51&quot;, &quot;2012-05-05 20:46:02&quot;, … &quot;2012-08-16 12:22:44&quot;]</td></tr><tr><td>&quot;4c9e6e2a7c096dcb3d32d5d1&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-11-02 00:04:33&quot;, &quot;2012-11-02 00:41:38&quot;, … &quot;2013-08-05 00:52:41&quot;]</td></tr><tr><td>&quot;4b56cf5df964a520d11b28e3&quot;</td><td>&quot;xn0j&quot;</td><td>[&quot;2012-06-18 08:29:08&quot;, &quot;2012-06-18 08:43:22&quot;, … &quot;2013-07-20 14:25:25&quot;]</td></tr><tr><td>&quot;4d4d2db24aa3a093d7eb3fae&quot;</td><td>&quot;swvs&quot;</td><td>[&quot;2013-02-28 08:27:47&quot;, &quot;2013-03-14 08:47:58&quot;, … &quot;2013-09-07 22:58:31&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4cea74b8e888f04d743b4d6b&quot;</td><td>&quot;sp36&quot;</td><td>[&quot;2012-12-07 18:13:45&quot;, &quot;2012-12-23 08:55:53&quot;, … &quot;2013-03-15 08:34:50&quot;]</td></tr><tr><td>&quot;4c993bbf9818ef3bc0751afa&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2013-04-28 13:18:52&quot;, &quot;2013-07-09 14:39:55&quot;, … &quot;2013-08-27 12:53:39&quot;]</td></tr><tr><td>&quot;4dd198d5fa767fb707804fc8&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-10-16 20:41:13&quot;, &quot;2012-11-12 18:42:43&quot;, … &quot;2013-09-16 13:17:09&quot;]</td></tr><tr><td>&quot;4bad20dff964a5208a303be3&quot;</td><td>&quot;djgz&quot;</td><td>[&quot;2012-07-07 21:00:17&quot;, &quot;2012-07-29 14:22:24&quot;, … &quot;2013-03-20 13:51:23&quot;]</td></tr><tr><td>&quot;4d49b3554509721e852e27b0&quot;</td><td>&quot;6gyf&quot;</td><td>[&quot;2012-04-05 06:29:30&quot;, &quot;2012-04-14 15:03:10&quot;, … &quot;2013-08-08 13:47:26&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 3)\n",
       "┌──────────────────────────┬──────┬─────────────────────────────────┐\n",
       "│ pois                     ┆ g4   ┆ checkin_times                   │\n",
       "│ ---                      ┆ ---  ┆ ---                             │\n",
       "│ str                      ┆ str  ┆ list[str]                       │\n",
       "╞══════════════════════════╪══════╪═════════════════════════════════╡\n",
       "│ 4b84dd37f964a5200a4631e3 ┆ sxk9 ┆ [\"2012-07-17 18:22:36\", \"2012-… │\n",
       "│ 4b683963f964a520c66c2be3 ┆ 66jc ┆ [\"2012-05-04 18:13:51\", \"2012-… │\n",
       "│ 4c9e6e2a7c096dcb3d32d5d1 ┆ sxk9 ┆ [\"2012-11-02 00:04:33\", \"2012-… │\n",
       "│ 4b56cf5df964a520d11b28e3 ┆ xn0j ┆ [\"2012-06-18 08:29:08\", \"2012-… │\n",
       "│ 4d4d2db24aa3a093d7eb3fae ┆ swvs ┆ [\"2013-02-28 08:27:47\", \"2013-… │\n",
       "│ …                        ┆ …    ┆ …                               │\n",
       "│ 4cea74b8e888f04d743b4d6b ┆ sp36 ┆ [\"2012-12-07 18:13:45\", \"2012-… │\n",
       "│ 4c993bbf9818ef3bc0751afa ┆ sxk9 ┆ [\"2013-04-28 13:18:52\", \"2013-… │\n",
       "│ 4dd198d5fa767fb707804fc8 ┆ sxk9 ┆ [\"2012-10-16 20:41:13\", \"2012-… │\n",
       "│ 4bad20dff964a5208a303be3 ┆ djgz ┆ [\"2012-07-07 21:00:17\", \"2012-… │\n",
       "│ 4d49b3554509721e852e27b0 ┆ 6gyf ┆ [\"2012-04-05 06:29:30\", \"2012-… │\n",
       "└──────────────────────────┴──────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also encode the graph dataframe so we can build the graphs\n",
    "\n",
    "pois_checkins = (\n",
    "    pois_checkins.lazy()\n",
    "    .with_columns(\n",
    "        [\n",
    "            rs.col(\"pois\").map_elements(\n",
    "                lambda s: encoder_dict[\"pois\"].transform([s])[0] + 1, rs.Int64\n",
    "            ),\n",
    "            rs.col(\"g4\").map_elements(\n",
    "                lambda s: encoder_dict[\"g4\"].transform([s])[0] + 1, rs.Int64\n",
    "            ),  # apply utc_to_weekslot to each timestamp in the list\n",
    "            rs.col(\"checkin_times\").map_elements(\n",
    "                lambda s: [UTC_to_weekslot(date) for date in s], rs.List(rs.Int64)\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    .sort(\"pois\")\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fictitious POI 0 to the graph, with nonexistent geohash and no timeslot, so we get a 0 row and column for the padding token\n",
    "fake_datapoint = rs.DataFrame(\n",
    "    {\n",
    "        \"pois\": [0],\n",
    "        \"g4\": [pois_checkins[\"g4\"].max() + 42],\n",
    "        \"checkin_times\": [[43]],\n",
    "    }\n",
    ")\n",
    "# this is a lot of work since polars dataframes are immutable by default, we have to run a query to change the 43 into an empty list\n",
    "# we NEED the 43 otherwise polars won't infer the datatype of the list\n",
    "\n",
    "fake_datapoint = fake_datapoint.with_columns(\n",
    "    [rs.col(\"checkin_times\").map_elements(lambda s: [], rs.List(rs.Int64))]\n",
    ")\n",
    "\n",
    "pois_checkins = fake_datapoint.vstack(pois_checkins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_row = np.array(pois_checkins[\"g4\"].to_list()).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer product using equality\n",
    "spatial_graph = (spatial_row == spatial_row.T).astype(np.int32)\n",
    "spatial_graph[0, 0] = (\n",
    "    0  # the fake g4 is still equal to itself, we suppress this equality\n",
    ")\n",
    "spatial_graph = torch.tensor(spatial_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_row = pois_checkins[\"checkin_times\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_graph = np.zeros((spatial_row.shape[0], spatial_row.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_sets = [np.array(list(set(row))) for row in temporal_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sets = torch.zeros((len(temporal_sets), 56), dtype=torch.int8)\n",
    "\n",
    "for i, r in enumerate(temporal_row):\n",
    "    indices = torch.tensor(r, dtype=torch.long)\n",
    "    time_sets[i, indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4456, 56])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND outer product\n",
    "\n",
    "intersection = time_sets @ time_sets.T\n",
    "union = time_sets.unsqueeze(1) | time_sets.unsqueeze(0)\n",
    "union = union.sum(dim=2)\n",
    "iou = intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_graph = iou >= 0.9\n",
    "# cast to int\n",
    "temporal_graph = temporal_graph.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_graph[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print information about the sparsity of the graphs, we note that \n",
    "the sparsity of the graphs is similar to that of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal sparsity: 97.05%\n",
      "Spatial sparsity: 96.99%\n"
     ]
    }
   ],
   "source": [
    "temporal_density = (\n",
    "    temporal_graph.sum() / (temporal_graph.shape[0] * temporal_graph.shape[1])\n",
    ").item()\n",
    "spatial_density = (\n",
    "    spatial_graph.sum() / (spatial_graph.shape[0] * spatial_graph.shape[1])\n",
    ").item()\n",
    "\n",
    "print(f\"Temporal sparsity: {(1 - temporal_density) * 100:.2f}%\")\n",
    "\n",
    "print(f\"Spatial sparsity: {(1 - spatial_density) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Datamodule\n",
    "\n",
    "We then define a pytorch dataset and a custom collation function that allows us to dynamically\n",
    "pad sequences to the longest one in the batch (as opposed to the longest one in the dataset)\n",
    "as they are loaded during training, this gives us an edge in performance by dramatically reducing the \n",
    "sparsity of our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def rnn_collation_fn(batch):\n",
    "\n",
    "    users = []\n",
    "    pois = []\n",
    "    g2 = []\n",
    "    g3 = []\n",
    "    g4 = []\n",
    "    g5 = []\n",
    "    g6 = []\n",
    "\n",
    "    for user, poi, geo2, geo3, geo4, geo5, geo6 in batch:\n",
    "        users.append(user)\n",
    "        pois.append(poi)\n",
    "        g2.append(geo2)\n",
    "        g3.append(geo3)\n",
    "        g4.append(geo4)\n",
    "        g5.append(geo5)\n",
    "        g6.append(geo6)\n",
    "    seq = (\n",
    "        torch.tensor(users, dtype=torch.long),\n",
    "        pad_sequence(pois, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g2, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g3, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g4, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g5, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g6, batch_first=True, padding_value=0),\n",
    "    )  # build a sequence\n",
    "\n",
    "    x = (\n",
    "        seq[0],\n",
    "        seq[1][:, :-1],\n",
    "        seq[2][:, :-1],\n",
    "        seq[3][:, :-1],\n",
    "        seq[4][:, :-1],\n",
    "        seq[5][:, :-1],\n",
    "        seq[6][:, :-1],\n",
    "    )  # omit the last one for sample\n",
    "\n",
    "    y = (\n",
    "        seq[0],\n",
    "        seq[1][:, 1:],\n",
    "        seq[2][:, 1:],\n",
    "        seq[3][:, 1:],\n",
    "        seq[4][:, 1:],\n",
    "        seq[5][:, 1:],\n",
    "        seq[6][:, 1:],\n",
    "    )  # omit the first one for ground truth\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class CheckinDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"users\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = (\n",
    "            torch.tensor(encoded_data[\"users\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"pois\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g2\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g3\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g4\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g5\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g6\"][idx], dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckinModule(pl.LightningDataModule):\n",
    "    def __init__(self, encoded_data, batch_size=32, workers=4):\n",
    "        super().__init__()\n",
    "        self.encoded_data = encoded_data\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.whole_dataset = CheckinDataset(self.encoded_data)\n",
    "\n",
    "        l = len(self.whole_dataset)\n",
    "\n",
    "        train_size = int(0.8 * l)\n",
    "        val_size = int(0.1 * l)\n",
    "        test_size = l - train_size - val_size\n",
    "\n",
    "        # generate train, val, test datasets by random split\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = (\n",
    "            torch.utils.data.random_split(\n",
    "                self.whole_dataset, [train_size, val_size, test_size]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def save(self, whole_path, train_path, val_path, test_path):\n",
    "        torch.save(self.whole_dataset, whole_path)\n",
    "        torch.save(self.train_dataset, train_path)\n",
    "        torch.save(self.val_dataset, val_path)\n",
    "        torch.save(self.test_dataset, test_path)\n",
    "\n",
    "    @staticmethod  # load without instantiating\n",
    "    def load(whole_path, train_path, val_path, test_path):\n",
    "        whole_dataset = torch.load(whole_path)\n",
    "        train_dataset = torch.load(train_path)\n",
    "        val_dataset = torch.load(val_path)\n",
    "        test_dataset = torch.load(test_path)\n",
    "        return whole_dataset, train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaselineDimensions:\n",
    "    nuser: int\n",
    "    npoi: int\n",
    "    g2len: int\n",
    "    g3len: int\n",
    "    g4len: int\n",
    "    g5len: int\n",
    "    g6len: int\n",
    "\n",
    "\n",
    "# HMT_RN (Hierarchical Multi-Task Recurrent Network)\n",
    "class HMT_RN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimensions: BaselineDimensions,\n",
    "        embedding_dim,\n",
    "        lstm_hidden_dim,\n",
    "        dropout_rate=0.9,  # 0.9 is a lot, but the paper says so.\n",
    "    ):\n",
    "        super(HMT_RN, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = lstm_hidden_dim\n",
    "        self.dims = dimensions\n",
    "\n",
    "        # Embedding layers one for user, one for poi and one for each G@P\n",
    "        self.user_embedding = nn.Embedding(\n",
    "            dimensions.nuser, embedding_dim, padding_idx=0\n",
    "        )\n",
    "        self.poi_embedding = nn.Embedding(dimensions.npoi, embedding_dim, padding_idx=0)\n",
    "        self.g2_embed = nn.Embedding(dimensions.g2len, embedding_dim, padding_idx=0)\n",
    "        self.g3_embed = nn.Embedding(dimensions.g3len, embedding_dim, padding_idx=0)\n",
    "        self.g4_embed = nn.Embedding(dimensions.g4len, embedding_dim, padding_idx=0)\n",
    "        self.g5_embed = nn.Embedding(dimensions.g5len, embedding_dim, padding_idx=0)\n",
    "        self.g6_embed = nn.Embedding(dimensions.g6len, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Dropout layer for embeddings\n",
    "        self.e_drop = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.user_poi_proj = nn.Linear(2 * embedding_dim, embedding_dim)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=lstm_hidden_dim, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Linear layers for prediction tasks\n",
    "        self.linear_poi = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.npoi)\n",
    "        self.linear_g2 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g2len)\n",
    "        self.linear_g3 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g3len)\n",
    "        self.linear_g4 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g4len)\n",
    "        self.linear_g5 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g5len)\n",
    "        self.linear_g6 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g6len)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, w):\n",
    "\n",
    "        if type(w) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "        elif type(w) == nn.LSTM:\n",
    "            for name, param in w.named_parameters():\n",
    "                if \"bias\" in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "                elif \"weight\" in name:\n",
    "                    nn.init.kaiming_normal_(param)\n",
    "        elif type(w) == nn.Embedding:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.weight[0], 0)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"forward passes the batch through the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : `tuple[torch.Tensor]`\n",
    "            A tuple of tensors ordered as follows:\n",
    "            (users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6)\n",
    "        \"\"\"\n",
    "\n",
    "        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = batch\n",
    "\n",
    "        B, T = poi.shape\n",
    "\n",
    "        # make it so  that users are tiled T times\n",
    "        users = users.repeat(T, 1).T\n",
    "\n",
    "        e_user = self.e_drop(self.user_embedding(users))\n",
    "        e_poi = self.e_drop(self.poi_embedding(poi))\n",
    "        e_gap2 = self.e_drop(self.g2_embed(x_geoHash2))\n",
    "        e_gap3 = self.e_drop(self.g3_embed(x_geoHash3))\n",
    "        e_gap4 = self.e_drop(self.g4_embed(x_geoHash4))\n",
    "        e_gap5 = self.e_drop(self.g5_embed(x_geoHash5))\n",
    "        e_gap6 = self.e_drop(self.g6_embed(x_geoHash6))\n",
    "\n",
    "        visit = self.e_drop(self.user_poi_proj(torch.cat((e_user, e_poi), dim=2)))\n",
    "\n",
    "        h_t, c_t = self.lstm(visit)\n",
    "\n",
    "        # dense layers\n",
    "        next_poi = self.linear_poi(torch.cat((h_t, e_poi), dim=2))\n",
    "        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n",
    "        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n",
    "        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n",
    "        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n",
    "        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n",
    "\n",
    "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/loss_gap2\", loss_gap2)\n",
    "        self.log(\"train/loss_gap3\", loss_gap3)\n",
    "        self.log(\"train/loss_gap4\", loss_gap4)\n",
    "        self.log(\"train/loss_gap5\", loss_gap5)\n",
    "        self.log(\"train/loss_gap6\", loss_gap6)\n",
    "        self.log(\"train/loss_poi\", loss_poi)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "        self.log(\"val/loss_gap2\", loss_gap2)\n",
    "        self.log(\"val/loss_gap3\", loss_gap3)\n",
    "        self.log(\"val/loss_gap4\", loss_gap4)\n",
    "        self.log(\"val/loss_gap5\", loss_gap5)\n",
    "        self.log(\"val/loss_gap6\", loss_gap6)\n",
    "        self.log(\"val/loss_poi\", loss_poi)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer and scheduler\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Components\n",
    "\n",
    "\n",
    "class attn_LSTM(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super(attn_LSTM, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.U = nn.Linear(hidden_dim, 4 * hidden_dim)\n",
    "\n",
    "        self.s_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.t_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "\n",
    "    def forward(self, x, hidden, spatial, temporal, numTimeSteps):\n",
    "        h_t, c_t = hidden\n",
    "\n",
    "        previous_h_t = h_t\n",
    "        previous_c_t = c_t\n",
    "\n",
    "        allGates_preact = (\n",
    "            self.W(x) + self.U(previous_h_t) + self.s_W(spatial) + self.t_W(temporal)\n",
    "        )\n",
    "\n",
    "        input_g = allGates_preact[:, :, : self.hidden_dim].sigmoid()\n",
    "        forget_g = allGates_preact[\n",
    "            :, :, self.hidden_dim : 2 * self.hidden_dim\n",
    "        ].sigmoid()\n",
    "        output_g = allGates_preact[\n",
    "            :, :, 2 * self.hidden_dim : 3 * self.hidden_dim\n",
    "        ].sigmoid()\n",
    "        c_t_g = allGates_preact[:, :, 3 * self.hidden_dim :].tanh()\n",
    "\n",
    "        c_t = forget_g * previous_c_t + input_g * c_t_g\n",
    "        h_t = output_g * c_t.tanh()\n",
    "\n",
    "        batchSize = x.shape[0]\n",
    "        h_t = h_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
    "        c_t = c_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
    "\n",
    "        return h_t, c_t\n",
    "\n",
    "\n",
    "def get_neighbours(adj_matrix, poi):\n",
    "    neigh_indices_list = []\n",
    "    max_length = 0\n",
    "\n",
    "    for batch_poi in poi:\n",
    "        batch_indices = []\n",
    "        for single_poi in batch_poi:\n",
    "            poi_row = adj_matrix[single_poi]\n",
    "            neigh_indices = torch.where(poi_row == 1)[0]\n",
    "            batch_indices.append(neigh_indices)\n",
    "            max_length = max(max_length, len(neigh_indices))\n",
    "\n",
    "        neigh_indices_list.append(batch_indices)\n",
    "\n",
    "    padded_neigh_indices_list = []\n",
    "    for batch_indices in neigh_indices_list:\n",
    "        padded_batch_indices = pad_sequence(\n",
    "            batch_indices, batch_first=True, padding_value=0\n",
    "        )\n",
    "        padded_neigh_indices_list.append(padded_batch_indices)\n",
    "\n",
    "    padded_tensor = torch.stack(padded_neigh_indices_list)\n",
    "\n",
    "    return padded_tensor\n",
    "\n",
    "\n",
    "class GRNSelfAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, n_heads):\n",
    "\n",
    "        super(GRNSelfAttention, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.Wp = nn.Linear(hidden_dim, hidden_dim)  # embeddings to pre-concat\n",
    "        self.Wa = nn.Linear(2 * hidden_dim, hidden_dim)  # concatenation to pre-softmax\n",
    "\n",
    "        # total size = 3 * (hidden_dim) ** 2, quadratic in embedding size\n",
    "\n",
    "    def forward(self, poi, neighbors):\n",
    "        \"\"\"forward\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        poi: torch.Tensor\n",
    "            A batched tensor of embedded POI vectors, (B x H) where H is the\n",
    "            embedding dimension\n",
    "        neighbors: torch.Tensor\n",
    "            A batched tensor of sequences of embedded POI vectors that are extracted\n",
    "            from an adjacency matrix (temporal or spatial neighbors of POI),\n",
    "            (B x N x H), where N is the number of neighbours of POI, B is the\n",
    "            batch size, H is the embedding dimension, and must be the same as POI\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[torch.Tensor, torch.Tensor]\n",
    "          A tuple containing the self-attention weighted hadamard product of neighbour activations\n",
    "          in the first index, the attention weights in the second index.\n",
    "        \"\"\"\n",
    "        # assert len(poi.shape) == 2, f\"POI tensor must be 2D, got {poi.shape} instead\"\n",
    "        assert (\n",
    "            len(neighbors.shape) == 3\n",
    "        ), f\"Neighbour tensor must be 3D, got {neighbors.shape} instead\"\n",
    "\n",
    "        B, N, H = neighbors.shape\n",
    "\n",
    "        h_poi = self.Wp(poi)\n",
    "        h_n = self.Wp(neighbors)\n",
    "        h_cat = torch.cat([h_poi.expand(B, N, -1), h_n], dim=2)\n",
    "        h_att = F.leaky_relu(self.Wa(h_cat))\n",
    "\n",
    "        alpha = torch.nn.functional.softmax(h_att, dim=1)\n",
    "\n",
    "        p = torch.sum(alpha * h_n, dim=1)\n",
    "        return p, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRN (Graph Recurrent Network)\n",
    "class GRN(pl.LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dims: BaselineDimensions,\n",
    "        spatial_graph,\n",
    "        temporal_graph,\n",
    "        hidden_dim,\n",
    "        n_heads,\n",
    "        dropout_rate=0.9,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super(GRN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dims = dims\n",
    "\n",
    "        self.spatial_graph = spatial_graph.to(device)\n",
    "        self.temporal_graph = temporal_graph.to(device)\n",
    "\n",
    "        self.spatial_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
    "        self.temporal_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
    "\n",
    "        self.lstm = attn_LSTM(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.user_embedding = nn.Embedding(dims.nuser, hidden_dim, padding_idx=0)\n",
    "        self.poi_embedding = nn.Embedding(dims.npoi, hidden_dim, padding_idx=0)\n",
    "        self.g2_embed = nn.Embedding(dims.g2len, hidden_dim, padding_idx=0)\n",
    "        self.g3_embed = nn.Embedding(dims.g3len, hidden_dim, padding_idx=0)\n",
    "        self.g4_embed = nn.Embedding(dims.g4len, hidden_dim, padding_idx=0)\n",
    "        self.g5_embed = nn.Embedding(dims.g5len, hidden_dim, padding_idx=0)\n",
    "        self.g6_embed = nn.Embedding(dims.g6len, hidden_dim, padding_idx=0)\n",
    "\n",
    "        self.linear_poi = nn.Linear(2 * hidden_dim, dims.npoi)\n",
    "        self.linear_g2 = nn.Linear(2 * hidden_dim, dims.g2len)\n",
    "        self.linear_g3 = nn.Linear(2 * hidden_dim, dims.g3len)\n",
    "        self.linear_g4 = nn.Linear(2 * hidden_dim, dims.g4len)\n",
    "        self.linear_g5 = nn.Linear(2 * hidden_dim, dims.g5len)\n",
    "        self.linear_g6 = nn.Linear(2 * hidden_dim, dims.g6len)\n",
    "\n",
    "        # extract indices from one-hot neighbor list\n",
    "        self.iota = torch.arange(self.dims.npoi, requires_grad=False, device=device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, w):\n",
    "        if type(w) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "        elif type(w) == nn.LSTM:\n",
    "            for name, param in w.named_parameters():\n",
    "                if \"bias\" in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "                elif \"weight\" in name:\n",
    "                    nn.init.kaiming_normal_(param)\n",
    "        elif type(w) == nn.Embedding:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.weight[0], 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = x\n",
    "\n",
    "        B, T = poi.shape\n",
    "\n",
    "        users = users.repeat(T, 1).T\n",
    "\n",
    "        neighbors_spatial = self.spatial_graph[poi]\n",
    "        neighbors_temporal = self.temporal_graph[poi]\n",
    "\n",
    "        e_user = self.dropout(self.user_embedding(users))\n",
    "        e_poi = self.dropout(self.poi_embedding(poi))\n",
    "        e_gap2 = self.dropout(self.g2_embed(x_geoHash2))\n",
    "        e_gap3 = self.dropout(self.g3_embed(x_geoHash3))\n",
    "        e_gap4 = self.dropout(self.g4_embed(x_geoHash4))\n",
    "        e_gap5 = self.dropout(self.g5_embed(x_geoHash5))\n",
    "        e_gap6 = self.dropout(self.g6_embed(x_geoHash6))\n",
    "\n",
    "        spatial_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
    "        temporal_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
    "\n",
    "        for b in range(B):\n",
    "            for t in range(T):\n",
    "\n",
    "                print(b, t)\n",
    "\n",
    "                spatial_neigh = neighbors_spatial[b, t] * self.iota\n",
    "                temporal_neigh = neighbors_temporal[b, t] * self.iota\n",
    "\n",
    "                spatial_neigh = spatial_neigh[spatial_neigh != 0]\n",
    "                temporal_neigh = temporal_neigh[temporal_neigh != 0]\n",
    "\n",
    "                spatial_neigh = spatial_neigh.unsqueeze(0)\n",
    "                temporal_neigh = temporal_neigh.unsqueeze(0)\n",
    "\n",
    "                e_spatial = self.dropout(self.poi_embedding(spatial_neigh))\n",
    "                e_temporal = self.dropout(self.poi_embedding(temporal_neigh))\n",
    "\n",
    "                curr_poi = e_poi[b, t].unsqueeze(0)\n",
    "\n",
    "                spatial_p, _ = self.spatial_attn(curr_poi, e_spatial)\n",
    "                temporal_p, _ = self.temporal_attn(curr_poi, e_temporal)\n",
    "\n",
    "                # we are not using the batch dimension, so we squeeze it\n",
    "                spatial_atts[b, t] = spatial_p.squeeze()\n",
    "                temporal_atts[b, t] = temporal_p.squeeze()\n",
    "\n",
    "        # zero-init LSTM states\n",
    "        h_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
    "        c_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
    "\n",
    "        h_t, c_t = self.lstm(e_poi, (h_t, c_t), spatial_atts, temporal_atts, T)\n",
    "\n",
    "        next_poi = self.linear_poi(torch.cat((h_t, e_poi), dim=2))\n",
    "        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n",
    "        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n",
    "        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n",
    "        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n",
    "        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n",
    "\n",
    "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/loss_gap2\", loss_gap2)\n",
    "        self.log(\"train/loss_gap3\", loss_gap3)\n",
    "        self.log(\"train/loss_gap4\", loss_gap4)\n",
    "        self.log(\"train/loss_gap5\", loss_gap5)\n",
    "        self.log(\"train/loss_gap6\", loss_gap6)\n",
    "        self.log(\"train/loss_poi\", loss_poi)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "        self.log(\"val/loss_gap2\", loss_gap2)\n",
    "        self.log(\"val/loss_gap3\", loss_gap3)\n",
    "        self.log(\"val/loss_gap4\", loss_gap4)\n",
    "        self.log(\"val/loss_gap5\", loss_gap5)\n",
    "        self.log(\"val/loss_gap6\", loss_gap6)\n",
    "        self.log(\"val/loss_poi\", loss_poi)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer and scheduler\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = encoder_dict[\"users\"].classes_.shape[0]\n",
    "n_pois = encoder_dict[\"pois\"].classes_.shape[0]\n",
    "n_g2 = encoder_dict[\"g2\"].classes_.shape[0]\n",
    "n_g3 = encoder_dict[\"g3\"].classes_.shape[0]\n",
    "n_g4 = encoder_dict[\"g4\"].classes_.shape[0]\n",
    "n_g5 = encoder_dict[\"g5\"].classes_.shape[0]\n",
    "n_g6 = encoder_dict[\"g6\"].classes_.shape[0]\n",
    "\n",
    "\n",
    "# account for the padding token\n",
    "dims = BaselineDimensions(\n",
    "    n_users + 1, n_pois + 1, n_g2 + 1, n_g3 + 1, n_g4 + 1, n_g5 + 1, n_g6 + 1\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mloi-1940849\u001b[0m (\u001b[33mpoi-dl-airo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dario/foursquare/wandb/run-20240511_195343-8vnufmut</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/8vnufmut' target=\"_blank\">smooth-blaze-201</a></strong> to <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/8vnufmut' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/8vnufmut</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c417a01646c406da673e3a3f499a913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smooth-blaze-201</strong> at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/8vnufmut' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/8vnufmut</a><br/> View project at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240511_195343-8vnufmut/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "TRAIN_BASELINE = False\n",
    "\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()\n",
    "# cargo-cult like stuff that is supposed to make you faster\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "ds = CheckinModule(encoded_data, batch_size=32, workers=4)\n",
    "\n",
    "wandb.init(project=\"trovailpoi\")\n",
    "\n",
    "classifier_baseline = HMT_RN(dims, embedding_dim=1024, lstm_hidden_dim=1024)\n",
    "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=40,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    log_every_n_steps=10,\n",
    "    logger=wandb_logger,\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        torchpl.callbacks.ModelCheckpoint(\n",
    "            monitor=\"val/loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            save_last=True,\n",
    "            filename=\"best_model\",\n",
    "        ),\n",
    "        torchpl.callbacks.EarlyStopping(\n",
    "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if TRAIN_BASELINE:\n",
    "    trainer.fit(model=classifier_baseline, datamodule=ds)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1bdff1a7a24cff8fe5fe499a328fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113296355567097, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dario/foursquare/wandb/run-20240511_195413-6ljioz32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32' target=\"_blank\">rose-frog-202</a></strong> to <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f1b244f3d74fdda9bba89df6c43c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-frog-202</strong> at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32</a><br/> View project at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240511_195413-6ljioz32/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_GNN = False\n",
    "\n",
    "batch_size = 60\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()\n",
    "# cargo-cult like stuff that is supposed to make you faster\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "wandb.init(project=\"trovailpoi\")\n",
    "\n",
    "classifier_gnn = GRN(\n",
    "    dims,\n",
    "    spatial_graph,\n",
    "    temporal_graph,\n",
    "    hidden_dim=1024,\n",
    "    n_heads=1,\n",
    "    dropout_rate=0.9,\n",
    "    device=device,\n",
    ")\n",
    "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=40,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    log_every_n_steps=10,\n",
    "    logger=wandb_logger,\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        torchpl.callbacks.ModelCheckpoint(\n",
    "            monitor=\"val/loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            save_last=True,\n",
    "            filename=\"best_model\",\n",
    "        ),\n",
    "        torchpl.callbacks.EarlyStopping(\n",
    "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if TRAIN_GNN:\n",
    "    trainer.fit(model=classifier_gnn, datamodule=ds)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapbook for Experimentation\n",
    "\n",
    "Ignore all code below, it's just for quick prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gnn = GRN(\n",
    "    dims,\n",
    "    spatial_graph,\n",
    "    temporal_graph,\n",
    "    hidden_dim=1024,\n",
    "    n_heads=1,\n",
    "    dropout_rate=0.9,\n",
    "    device=\"cuda\",\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(ds.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "user, poi, g2, g3, g4, g5, g6 = x\n",
    "x = (\n",
    "    user.to(device)[:8, ...],\n",
    "    poi.to(device)[:8, ...],\n",
    "    g2.to(device)[:8, ...],\n",
    "    g3.to(device)[:8, ...],\n",
    "    g4.to(device)[:8, ...],\n",
    "    g5.to(device)[:8, ...],\n",
    "    g6.to(device)[:8, ...],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclassifier_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[97], line 106\u001b[0m, in \u001b[0;36mGRN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m e_temporal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoi_embedding(temporal_neigh))\n\u001b[1;32m    104\u001b[0m curr_poi \u001b[38;5;241m=\u001b[39m e_poi[b, t]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m spatial_p, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_poi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_spatial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m temporal_p, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_attn(curr_poi, e_temporal)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# we are not using the batch dimension, so we squeeze it\u001b[39;00m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/foursquare/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[67], line 114\u001b[0m, in \u001b[0;36mGRNSelfAttention.forward\u001b[0;34m(self, poi, neighbors)\u001b[0m\n\u001b[1;32m    112\u001b[0m h_poi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWp(poi)\n\u001b[1;32m    113\u001b[0m h_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWp(neighbors)\n\u001b[0;32m--> 114\u001b[0m h_cat \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mh_poi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_n\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m h_att \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWa(h_cat))\n\u001b[1;32m    117\u001b[0m alpha \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(h_att, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "classifier_gnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 + 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
