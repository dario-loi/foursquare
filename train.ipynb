{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare dataset next-POI Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off we import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as rs\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as pl\n",
    "import lightning.pytorch as torchpl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from dataclasses import dataclass\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# define WANDB_NOTEBOOK_NAME\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "# clean CUDA memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# sometimes jupyter notebook does not release memory, we leave this here so a run-all\n",
    "# can *sometimes* fix leaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the data, we utilize `polars` since it is much more efficient than `pandas` and can handle large datasets with ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"user\", \"poi\", \"date\", \"TZ\"]\n",
    "data = rs.read_csv(\n",
    "    \"dataset_TIST2015/dataset_TIST2015_Checkins.txt\",\n",
    "    has_header=False,\n",
    "    low_memory=True,\n",
    "    separator=\"\\t\",\n",
    ")\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (33_263_633, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>poi</th><th>date</th><th>TZ</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>50756</td><td>&quot;4f5e3a72e4b053fd6a4313f6&quot;</td><td>&quot;Tue Apr 03 18:00:06 +0000 2012&quot;</td><td>240</td></tr><tr><td>190571</td><td>&quot;4b4b87b5f964a5204a9f26e3&quot;</td><td>&quot;Tue Apr 03 18:00:07 +0000 2012&quot;</td><td>180</td></tr><tr><td>221021</td><td>&quot;4a85b1b3f964a520eefe1fe3&quot;</td><td>&quot;Tue Apr 03 18:00:08 +0000 2012&quot;</td><td>-240</td></tr><tr><td>66981</td><td>&quot;4b4606f2f964a520751426e3&quot;</td><td>&quot;Tue Apr 03 18:00:08 +0000 2012&quot;</td><td>-300</td></tr><tr><td>21010</td><td>&quot;4c2b4e8a9a559c74832f0de2&quot;</td><td>&quot;Tue Apr 03 18:00:09 +0000 2012&quot;</td><td>240</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>16349</td><td>&quot;4c957755c8a1bfb7e89024f3&quot;</td><td>&quot;Mon Sep 16 23:24:11 +0000 2013&quot;</td><td>-240</td></tr><tr><td>256757</td><td>&quot;4c8bbb6d9ef0224bd2d6667b&quot;</td><td>&quot;Mon Sep 16 23:24:13 +0000 2013&quot;</td><td>-180</td></tr><tr><td>66425</td><td>&quot;513e82a5e4b0ed4f0f3bcf2d&quot;</td><td>&quot;Mon Sep 16 23:24:14 +0000 2013&quot;</td><td>-180</td></tr><tr><td>1830</td><td>&quot;4b447865f964a5204cf525e3&quot;</td><td>&quot;Mon Sep 16 23:24:14 +0000 2013&quot;</td><td>120</td></tr><tr><td>22704</td><td>&quot;50df4ee5e4b0c48b5a1c2968&quot;</td><td>&quot;Mon Sep 16 23:24:15 +0000 2013&quot;</td><td>180</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (33_263_633, 4)\n",
       "┌────────┬──────────────────────────┬────────────────────────────────┬──────┐\n",
       "│ user   ┆ poi                      ┆ date                           ┆ TZ   │\n",
       "│ ---    ┆ ---                      ┆ ---                            ┆ ---  │\n",
       "│ i64    ┆ str                      ┆ str                            ┆ i64  │\n",
       "╞════════╪══════════════════════════╪════════════════════════════════╪══════╡\n",
       "│ 50756  ┆ 4f5e3a72e4b053fd6a4313f6 ┆ Tue Apr 03 18:00:06 +0000 2012 ┆ 240  │\n",
       "│ 190571 ┆ 4b4b87b5f964a5204a9f26e3 ┆ Tue Apr 03 18:00:07 +0000 2012 ┆ 180  │\n",
       "│ 221021 ┆ 4a85b1b3f964a520eefe1fe3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -240 │\n",
       "│ 66981  ┆ 4b4606f2f964a520751426e3 ┆ Tue Apr 03 18:00:08 +0000 2012 ┆ -300 │\n",
       "│ 21010  ┆ 4c2b4e8a9a559c74832f0de2 ┆ Tue Apr 03 18:00:09 +0000 2012 ┆ 240  │\n",
       "│ …      ┆ …                        ┆ …                              ┆ …    │\n",
       "│ 16349  ┆ 4c957755c8a1bfb7e89024f3 ┆ Mon Sep 16 23:24:11 +0000 2013 ┆ -240 │\n",
       "│ 256757 ┆ 4c8bbb6d9ef0224bd2d6667b ┆ Mon Sep 16 23:24:13 +0000 2013 ┆ -180 │\n",
       "│ 66425  ┆ 513e82a5e4b0ed4f0f3bcf2d ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ -180 │\n",
       "│ 1830   ┆ 4b447865f964a5204cf525e3 ┆ Mon Sep 16 23:24:14 +0000 2013 ┆ 120  │\n",
       "│ 22704  ┆ 50df4ee5e4b0c48b5a1c2968 ┆ Mon Sep 16 23:24:15 +0000 2013 ┆ 180  │\n",
       "└────────┴──────────────────────────┴────────────────────────────────┴──────┘"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from what suggested by the professor, we utilize the full TIST2015 dataset, which has a far greater scale compared to the reduced NY one. However, by following the pruning steps detailed in the paper (http://dx.doi.org/10.1145/3477495.3531989, section 5.1), we obtain sequences that are much smaller in size, resulting in a dataset that is usable on Google Colab's free tier (as required by the assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users = (\n",
    "    data.lazy()\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        [\n",
    "            rs.col(\"poi\").n_unique().alias(\"n_pois\"),\n",
    "            rs.col(\"poi\").count().alias(\"n_checkins\"),\n",
    "            # turn the rest into a list\n",
    "            rs.col(\"poi\").alias(\"pois\"),\n",
    "            rs.col(\"date\").alias(\"dates\"),\n",
    "            rs.col(\"TZ\").alias(\"TZs\"),\n",
    "        ]\n",
    "    )\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td><td>266909.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>133455.0</td><td>56.477459</td><td>124.62537</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>77050.135837</td><td>45.968603</td><td>140.692138</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;25%&quot;</td><td>66728.0</td><td>30.0</td><td>61.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>133455.0</td><td>49.0</td><td>93.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>200182.0</td><td>71.0</td><td>148.0</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>1246.0</td><td>5430.0</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬──────────────┬───────────┬────────────┬──────────┬──────────┬──────────┐\n",
       "│ statistic  ┆ user         ┆ n_pois    ┆ n_checkins ┆ pois     ┆ dates    ┆ TZs      │\n",
       "│ ---        ┆ ---          ┆ ---       ┆ ---        ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str        ┆ f64          ┆ f64       ┆ f64        ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞════════════╪══════════════╪═══════════╪════════════╪══════════╪══════════╪══════════╡\n",
       "│ count      ┆ 266909.0     ┆ 266909.0  ┆ 266909.0   ┆ 266909.0 ┆ 266909.0 ┆ 266909.0 │\n",
       "│ null_count ┆ 0.0          ┆ 0.0       ┆ 0.0        ┆ 0.0      ┆ 0.0      ┆ 0.0      │\n",
       "│ mean       ┆ 133455.0     ┆ 56.477459 ┆ 124.62537  ┆ null     ┆ null     ┆ null     │\n",
       "│ std        ┆ 77050.135837 ┆ 45.968603 ┆ 140.692138 ┆ null     ┆ null     ┆ null     │\n",
       "│ min        ┆ 1.0          ┆ 1.0       ┆ 1.0        ┆ null     ┆ null     ┆ null     │\n",
       "│ 25%        ┆ 66728.0      ┆ 30.0      ┆ 61.0       ┆ null     ┆ null     ┆ null     │\n",
       "│ 50%        ┆ 133455.0     ┆ 49.0      ┆ 93.0       ┆ null     ┆ null     ┆ null     │\n",
       "│ 75%        ┆ 200182.0     ┆ 71.0      ┆ 148.0      ┆ null     ┆ null     ┆ null     │\n",
       "│ max        ┆ 266909.0     ┆ 1246.0    ┆ 5430.0     ┆ null     ┆ null     ┆ null     │\n",
       "└────────────┴──────────────┴───────────┴────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_culled = data_users.filter(\n",
    "    (rs.col(\"n_checkins\") > 20) & (rs.col(\"n_checkins\") < 50)\n",
    ").drop_nulls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the original dataset is huge, we delete it and call the python garbage collector to free up memory. We then proceed with the second pruning step (frequency-based pruning) as detailed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data\n",
    "del data_users\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique elements from each lists in data_culled[\"pois\"]\n",
    "out = data_culled.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\").list.unique(),\n",
    "        rs.col(\"pois\").list.unique().list.len().alias(\"n_unique_pois\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_697, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th><th>n_unique_pois</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td><td>u32</td></tr></thead><tbody><tr><td>191538</td><td>26</td><td>44</td><td>[&quot;4ae282e2f964a520c18e21e3&quot;, &quot;4ad671eff964a5203d0721e3&quot;, … &quot;4dc08eee6a234f005538d918&quot;]</td><td>[&quot;Fri Apr 13 02:57:24 +0000 2012&quot;, &quot;Fri Apr 13 06:43:35 +0000 2012&quot;, … &quot;Thu Dec 06 20:27:19 +0000 2012&quot;]</td><td>[-300, -300, … -360]</td><td>26</td></tr><tr><td>234173</td><td>29</td><td>32</td><td>[&quot;4b931bd5f964a5208d3534e3&quot;, &quot;4d3b26651fc36dcb0a5e6ef5&quot;, … &quot;4c944e0ff7cfa1cd98f7b215&quot;]</td><td>[&quot;Mon Apr 23 05:15:19 +0000 2012&quot;, &quot;Sat Apr 28 00:48:30 +0000 2012&quot;, … &quot;Mon Jan 28 14:15:15 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td><td>29</td></tr><tr><td>261329</td><td>24</td><td>30</td><td>[&quot;4acbc3fdf964a520cbc620e3&quot;, &quot;4ad7e5f9f964a520e90f21e3&quot;, … &quot;4af2ca77f964a52084e821e3&quot;]</td><td>[&quot;Wed Sep 05 18:43:09 +0000 2012&quot;, &quot;Fri Sep 14 20:33:52 +0000 2012&quot;, … &quot;Wed Aug 28 12:25:56 +0000 2013&quot;]</td><td>[-300, -300, … -300]</td><td>24</td></tr><tr><td>102857</td><td>24</td><td>36</td><td>[&quot;4d40b0d589616dcbbc1f07b5&quot;, &quot;4edf60db2c5b1dfcba6dfc87&quot;, … &quot;4c93a9f238dd8cfacac7c162&quot;]</td><td>[&quot;Sat Apr 07 21:25:17 +0000 2012&quot;, &quot;Sat Apr 07 22:02:56 +0000 2012&quot;, … &quot;Mon Jul 30 19:43:46 +0000 2012&quot;]</td><td>[-240, -240, … -240]</td><td>24</td></tr><tr><td>256931</td><td>28</td><td>31</td><td>[&quot;4bf37dc8e5eba59332a41e90&quot;, &quot;4df968b6b61c7e9df14c45ac&quot;, … &quot;4c9dd3cfe9a7ef3b9c343e16&quot;]</td><td>[&quot;Fri Jun 01 13:41:52 +0000 2012&quot;, &quot;Sun Jun 03 07:09:22 +0000 2012&quot;, … &quot;Tue May 14 08:52:07 +0000 2013&quot;]</td><td>[480, 480, … 480]</td><td>28</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>51894</td><td>33</td><td>42</td><td>[&quot;4ba64cdff964a520e04339e3&quot;, &quot;4ede6d0d8b81731611092e72&quot;, … &quot;4c680e06e1da1b8dc10b9fc3&quot;]</td><td>[&quot;Sun Jul 08 07:13:26 +0000 2012&quot;, &quot;Sun Jul 15 14:07:35 +0000 2012&quot;, … &quot;Sat Aug 31 10:34:28 +0000 2013&quot;]</td><td>[180, 180, … 180]</td><td>33</td></tr><tr><td>151362</td><td>27</td><td>30</td><td>[&quot;4b9936c0f964a520586a35e3&quot;, &quot;4b2df883f964a52041dc24e3&quot;, … &quot;4f18f2fce4b02a5a238704c5&quot;]</td><td>[&quot;Sat Aug 11 10:38:10 +0000 2012&quot;, &quot;Sun Nov 25 01:18:42 +0000 2012&quot;, … &quot;Mon Aug 05 07:28:56 +0000 2013&quot;]</td><td>[480, 480, … 480]</td><td>27</td></tr><tr><td>109751</td><td>19</td><td>27</td><td>[&quot;4b6ef695f964a52085d32ce3&quot;, &quot;4f445630e4b00b32df882d28&quot;, … &quot;4b28e73cf964a520079624e3&quot;]</td><td>[&quot;Tue Apr 03 22:39:32 +0000 2012&quot;, &quot;Wed Apr 04 02:27:43 +0000 2012&quot;, … &quot;Mon May 21 20:37:43 +0000 2012&quot;]</td><td>[-240, -240, … -360]</td><td>19</td></tr><tr><td>227146</td><td>22</td><td>26</td><td>[&quot;4fe47ea0e4b0237b9dd59ed7&quot;, &quot;4d5bc64c1ef2f04d6971edcd&quot;, … &quot;5058b42fe4b083cc7008b1df&quot;]</td><td>[&quot;Tue Feb 26 10:15:57 +0000 2013&quot;, &quot;Tue Feb 26 10:24:22 +0000 2013&quot;, … &quot;Mon Sep 16 11:32:48 +0000 2013&quot;]</td><td>[120, 120, … 180]</td><td>22</td></tr><tr><td>217109</td><td>34</td><td>35</td><td>[&quot;4c880cba0f3c236a84b8ef5c&quot;, &quot;5054cf89e4b0719d67f72b4a&quot;, … &quot;4c373a11298e9c745ff107e3&quot;]</td><td>[&quot;Sat Sep 15 19:52:55 +0000 2012&quot;, &quot;Wed Jan 16 21:04:57 +0000 2013&quot;, … &quot;Mon Sep 16 19:15:13 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td><td>34</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_697, 7)\n",
       "┌────────┬────────┬────────────┬─────────────────┬────────────────┬────────────────┬───────────────┐\n",
       "│ user   ┆ n_pois ┆ n_checkins ┆ pois            ┆ dates          ┆ TZs            ┆ n_unique_pois │\n",
       "│ ---    ┆ ---    ┆ ---        ┆ ---             ┆ ---            ┆ ---            ┆ ---           │\n",
       "│ i64    ┆ u32    ┆ u32        ┆ list[str]       ┆ list[str]      ┆ list[i64]      ┆ u32           │\n",
       "╞════════╪════════╪════════════╪═════════════════╪════════════════╪════════════════╪═══════════════╡\n",
       "│ 191538 ┆ 26     ┆ 44         ┆ [\"4ae282e2f964a ┆ [\"Fri Apr 13   ┆ [-300, -300, … ┆ 26            │\n",
       "│        ┆        ┆            ┆ 520c18e21e3\",   ┆ 02:57:24 +0000 ┆ -360]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 234173 ┆ 29     ┆ 32         ┆ [\"4b931bd5f964a ┆ [\"Mon Apr 23   ┆ [-180, -180, … ┆ 29            │\n",
       "│        ┆        ┆            ┆ 5208d3534e3\",   ┆ 05:15:19 +0000 ┆ -180]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 261329 ┆ 24     ┆ 30         ┆ [\"4acbc3fdf964a ┆ [\"Wed Sep 05   ┆ [-300, -300, … ┆ 24            │\n",
       "│        ┆        ┆            ┆ 520cbc620e3\",   ┆ 18:43:09 +0000 ┆ -300]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 102857 ┆ 24     ┆ 36         ┆ [\"4d40b0d589616 ┆ [\"Sat Apr 07   ┆ [-240, -240, … ┆ 24            │\n",
       "│        ┆        ┆            ┆ dcbbc1f07b5\",   ┆ 21:25:17 +0000 ┆ -240]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 256931 ┆ 28     ┆ 31         ┆ [\"4bf37dc8e5eba ┆ [\"Fri Jun 01   ┆ [480, 480, …   ┆ 28            │\n",
       "│        ┆        ┆            ┆ 59332a41e90\",   ┆ 13:41:52 +0000 ┆ 480]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ …      ┆ …      ┆ …          ┆ …               ┆ …              ┆ …              ┆ …             │\n",
       "│ 51894  ┆ 33     ┆ 42         ┆ [\"4ba64cdff964a ┆ [\"Sun Jul 08   ┆ [180, 180, …   ┆ 33            │\n",
       "│        ┆        ┆            ┆ 520e04339e3\",   ┆ 07:13:26 +0000 ┆ 180]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 151362 ┆ 27     ┆ 30         ┆ [\"4b9936c0f964a ┆ [\"Sat Aug 11   ┆ [480, 480, …   ┆ 27            │\n",
       "│        ┆        ┆            ┆ 520586a35e3\",   ┆ 10:38:10 +0000 ┆ 480]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 109751 ┆ 19     ┆ 27         ┆ [\"4b6ef695f964a ┆ [\"Tue Apr 03   ┆ [-240, -240, … ┆ 19            │\n",
       "│        ┆        ┆            ┆ 52085d32ce3\",   ┆ 22:39:32 +0000 ┆ -360]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 227146 ┆ 22     ┆ 26         ┆ [\"4fe47ea0e4b02 ┆ [\"Tue Feb 26   ┆ [120, 120, …   ┆ 22            │\n",
       "│        ┆        ┆            ┆ 37b9dd59ed7\",   ┆ 10:15:57 +0000 ┆ 180]           ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "│ 217109 ┆ 34     ┆ 35         ┆ [\"4c880cba0f3c2 ┆ [\"Sat Sep 15   ┆ [-180, -180, … ┆ 34            │\n",
       "│        ┆        ┆            ┆ 36a84b8ef5c\",   ┆ 19:52:55 +0000 ┆ -180]          ┆               │\n",
       "│        ┆        ┆            ┆ \"…              ┆ 20…            ┆                ┆               │\n",
       "└────────┴────────┴────────────┴─────────────────┴────────────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = out[\"pois\"][0].to_list()\n",
    "len(set(l))  # print number of unique POIs in first sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = data_culled[\"pois\"][0].to_list()\n",
    "len(l2)  # print sequence length of first user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(l2))  # confirm that the two match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a Polars query to obtain all the frequent POIs, the ones expected to survive the filtering\n",
    "unique_pois = out[\"pois\"]\n",
    "frequent_pois = unique_pois.list.explode().value_counts().filter(rs.col(\"count\") >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;4bd4720acfa7b7130b0b24da&quot;</td><td>47</td></tr><tr><td>&quot;503d1682e4b031746f8f8f83&quot;</td><td>24</td></tr><tr><td>&quot;4b525412f964a520807727e3&quot;</td><td>11</td></tr><tr><td>&quot;4b5a280af964a520d2b028e3&quot;</td><td>27</td></tr><tr><td>&quot;4d92b679b053b60c78857fcb&quot;</td><td>22</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4ae277f6f964a5207b8e21e3&quot;</td><td>12</td></tr><tr><td>&quot;4b765f93f964a520dc492ee3&quot;</td><td>10</td></tr><tr><td>&quot;5131dd1b526291007b1d5e7e&quot;</td><td>10</td></tr><tr><td>&quot;40db6b00f964a5207d011fe3&quot;</td><td>58</td></tr><tr><td>&quot;409d7480f964a520f2f21ee3&quot;</td><td>24</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 2)\n",
       "┌──────────────────────────┬───────┐\n",
       "│ pois                     ┆ count │\n",
       "│ ---                      ┆ ---   │\n",
       "│ str                      ┆ u32   │\n",
       "╞══════════════════════════╪═══════╡\n",
       "│ 4bd4720acfa7b7130b0b24da ┆ 47    │\n",
       "│ 503d1682e4b031746f8f8f83 ┆ 24    │\n",
       "│ 4b525412f964a520807727e3 ┆ 11    │\n",
       "│ 4b5a280af964a520d2b028e3 ┆ 27    │\n",
       "│ 4d92b679b053b60c78857fcb ┆ 22    │\n",
       "│ …                        ┆ …     │\n",
       "│ 4ae277f6f964a5207b8e21e3 ┆ 12    │\n",
       "│ 4b765f93f964a520dc492ee3 ┆ 10    │\n",
       "│ 5131dd1b526291007b1d5e7e ┆ 10    │\n",
       "│ 40db6b00f964a5207d011fe3 ┆ 58    │\n",
       "│ 409d7480f964a520f2f21ee3 ┆ 24    │\n",
       "└──────────────────────────┴───────┘"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_pois = frequent_pois[\"pois\"]\n",
    "frequent_pois = set(frequent_pois.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (21_697, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>n_pois</th><th>n_checkins</th><th>pois</th><th>dates</th><th>TZs</th></tr><tr><td>i64</td><td>u32</td><td>u32</td><td>list[str]</td><td>list[str]</td><td>list[i64]</td></tr></thead><tbody><tr><td>191538</td><td>26</td><td>44</td><td>[&quot;4ae282e2f964a520c18e21e3&quot;, &quot;4ae282e2f964a520c18e21e3&quot;, … &quot;4dc08eee6a234f005538d918&quot;]</td><td>[&quot;Fri Apr 13 02:57:24 +0000 2012&quot;, &quot;Fri Apr 13 06:43:35 +0000 2012&quot;, … &quot;Thu Dec 06 20:27:19 +0000 2012&quot;]</td><td>[-300, -300, … -360]</td></tr><tr><td>234173</td><td>29</td><td>32</td><td>[&quot;4b058716f964a520fd7e22e3&quot;, &quot;4b60f670f964a520b4032ae3&quot;, … &quot;4b37c338f964a520b34525e3&quot;]</td><td>[&quot;Mon Apr 23 05:15:19 +0000 2012&quot;, &quot;Sat Apr 28 00:48:30 +0000 2012&quot;, … &quot;Mon Jan 28 14:15:15 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td></tr><tr><td>261329</td><td>24</td><td>30</td><td>[&quot;4cb9a4f443ec6dcb1b5e9e31&quot;, &quot;4a9979e8f964a520872e20e3&quot;, … &quot;4aef9d80f964a52094d921e3&quot;]</td><td>[&quot;Wed Sep 05 18:43:09 +0000 2012&quot;, &quot;Fri Sep 14 20:33:52 +0000 2012&quot;, … &quot;Wed Aug 28 12:25:56 +0000 2013&quot;]</td><td>[-300, -300, … -300]</td></tr><tr><td>102857</td><td>24</td><td>36</td><td>[&quot;4c4a15b89e6dbe9a01650d0a&quot;, &quot;49f47c7cf964a5200d6b1fe3&quot;, … &quot;4c2f76e766e40f478befc18b&quot;]</td><td>[&quot;Sat Apr 07 21:25:17 +0000 2012&quot;, &quot;Sat Apr 07 22:02:56 +0000 2012&quot;, … &quot;Mon Jul 30 19:43:46 +0000 2012&quot;]</td><td>[-240, -240, … -240]</td></tr><tr><td>256931</td><td>28</td><td>31</td><td>[&quot;4df968b6b61c7e9df14c45ac&quot;, &quot;4bd3f60a41b9ef3b545401e6&quot;, … &quot;4b289bf4f964a520379424e3&quot;]</td><td>[&quot;Fri Jun 01 13:41:52 +0000 2012&quot;, &quot;Sun Jun 03 07:09:22 +0000 2012&quot;, … &quot;Tue May 14 08:52:07 +0000 2013&quot;]</td><td>[480, 480, … 480]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>51894</td><td>33</td><td>42</td><td>[&quot;4b76f871f964a520e36f2ee3&quot;, &quot;4e5cddc145dd045aab533a23&quot;, … &quot;5106248ae4b040a89461909d&quot;]</td><td>[&quot;Sun Jul 08 07:13:26 +0000 2012&quot;, &quot;Sun Jul 15 14:07:35 +0000 2012&quot;, … &quot;Sat Aug 31 10:34:28 +0000 2013&quot;]</td><td>[180, 180, … 180]</td></tr><tr><td>151362</td><td>27</td><td>30</td><td>[&quot;4b612f2af964a5204a0c2ae3&quot;, &quot;4b058806f964a52066ad22e3&quot;, … &quot;50b1fa54e4b0df43714d6c25&quot;]</td><td>[&quot;Sat Aug 11 10:38:10 +0000 2012&quot;, &quot;Sun Nov 25 01:18:42 +0000 2012&quot;, … &quot;Mon Aug 05 07:28:56 +0000 2013&quot;]</td><td>[480, 480, … 480]</td></tr><tr><td>109751</td><td>19</td><td>27</td><td>[&quot;4bfd46f855539c749ca0bcf3&quot;, &quot;4f445630e4b00b32df882d28&quot;, … &quot;4f307c28e4b0f99d8767930a&quot;]</td><td>[&quot;Tue Apr 03 22:39:32 +0000 2012&quot;, &quot;Wed Apr 04 02:27:43 +0000 2012&quot;, … &quot;Mon May 21 20:37:43 +0000 2012&quot;]</td><td>[-240, -240, … -360]</td></tr><tr><td>227146</td><td>22</td><td>26</td><td>[&quot;4f02e11a6c25c5ce84103f8d&quot;, &quot;4ef8d21c7ee5bf7994a650cc&quot;, … &quot;51a73fa1abd8dc940d14c715&quot;]</td><td>[&quot;Tue Feb 26 10:15:57 +0000 2013&quot;, &quot;Tue Feb 26 10:24:22 +0000 2013&quot;, … &quot;Mon Sep 16 11:32:48 +0000 2013&quot;]</td><td>[120, 120, … 180]</td></tr><tr><td>217109</td><td>34</td><td>35</td><td>[&quot;5054cf89e4b0719d67f72b4a&quot;, &quot;4b5f69f4f964a520f1b829e3&quot;, … &quot;4d4d6236a7f86ea87cf535de&quot;]</td><td>[&quot;Sat Sep 15 19:52:55 +0000 2012&quot;, &quot;Wed Jan 16 21:04:57 +0000 2013&quot;, … &quot;Mon Sep 16 19:15:13 +0000 2013&quot;]</td><td>[-180, -180, … -180]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (21_697, 6)\n",
       "┌────────┬────────┬────────────┬──────────────────────┬──────────────────────┬─────────────────────┐\n",
       "│ user   ┆ n_pois ┆ n_checkins ┆ pois                 ┆ dates                ┆ TZs                 │\n",
       "│ ---    ┆ ---    ┆ ---        ┆ ---                  ┆ ---                  ┆ ---                 │\n",
       "│ i64    ┆ u32    ┆ u32        ┆ list[str]            ┆ list[str]            ┆ list[i64]           │\n",
       "╞════════╪════════╪════════════╪══════════════════════╪══════════════════════╪═════════════════════╡\n",
       "│ 191538 ┆ 26     ┆ 44         ┆ [\"4ae282e2f964a520c1 ┆ [\"Fri Apr 13         ┆ [-300, -300, …      │\n",
       "│        ┆        ┆            ┆ 8e21e3\", \"…          ┆ 02:57:24 +0000 20…   ┆ -360]               │\n",
       "│ 234173 ┆ 29     ┆ 32         ┆ [\"4b058716f964a520fd ┆ [\"Mon Apr 23         ┆ [-180, -180, …      │\n",
       "│        ┆        ┆            ┆ 7e22e3\", \"…          ┆ 05:15:19 +0000 20…   ┆ -180]               │\n",
       "│ 261329 ┆ 24     ┆ 30         ┆ [\"4cb9a4f443ec6dcb1b ┆ [\"Wed Sep 05         ┆ [-300, -300, …      │\n",
       "│        ┆        ┆            ┆ 5e9e31\", \"…          ┆ 18:43:09 +0000 20…   ┆ -300]               │\n",
       "│ 102857 ┆ 24     ┆ 36         ┆ [\"4c4a15b89e6dbe9a01 ┆ [\"Sat Apr 07         ┆ [-240, -240, …      │\n",
       "│        ┆        ┆            ┆ 650d0a\", \"…          ┆ 21:25:17 +0000 20…   ┆ -240]               │\n",
       "│ 256931 ┆ 28     ┆ 31         ┆ [\"4df968b6b61c7e9df1 ┆ [\"Fri Jun 01         ┆ [480, 480, … 480]   │\n",
       "│        ┆        ┆            ┆ 4c45ac\", \"…          ┆ 13:41:52 +0000 20…   ┆                     │\n",
       "│ …      ┆ …      ┆ …          ┆ …                    ┆ …                    ┆ …                   │\n",
       "│ 51894  ┆ 33     ┆ 42         ┆ [\"4b76f871f964a520e3 ┆ [\"Sun Jul 08         ┆ [180, 180, … 180]   │\n",
       "│        ┆        ┆            ┆ 6f2ee3\", \"…          ┆ 07:13:26 +0000 20…   ┆                     │\n",
       "│ 151362 ┆ 27     ┆ 30         ┆ [\"4b612f2af964a5204a ┆ [\"Sat Aug 11         ┆ [480, 480, … 480]   │\n",
       "│        ┆        ┆            ┆ 0c2ae3\", \"…          ┆ 10:38:10 +0000 20…   ┆                     │\n",
       "│ 109751 ┆ 19     ┆ 27         ┆ [\"4bfd46f855539c749c ┆ [\"Tue Apr 03         ┆ [-240, -240, …      │\n",
       "│        ┆        ┆            ┆ a0bcf3\", \"…          ┆ 22:39:32 +0000 20…   ┆ -360]               │\n",
       "│ 227146 ┆ 22     ┆ 26         ┆ [\"4f02e11a6c25c5ce84 ┆ [\"Tue Feb 26         ┆ [120, 120, … 180]   │\n",
       "│        ┆        ┆            ┆ 103f8d\", \"…          ┆ 10:15:57 +0000 20…   ┆                     │\n",
       "│ 217109 ┆ 34     ┆ 35         ┆ [\"5054cf89e4b0719d67 ┆ [\"Sat Sep 15         ┆ [-180, -180, …      │\n",
       "│        ┆        ┆            ┆ f72b4a\", \"…          ┆ 19:52:55 +0000 20…   ┆ -180]               │\n",
       "└────────┴────────┴────────────┴──────────────────────┴──────────────────────┴─────────────────────┘"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_culled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_culled = data_culled.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\")\n",
    "        .list.eval(\n",
    "            rs.element().is_in(frequent_pois),\n",
    "        )\n",
    "        .alias(\"is_frequent\")\n",
    "    ]\n",
    ")  # prep mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = (\n",
    "    data_culled.lazy()\n",
    "    .with_row_index()\n",
    "    .explode(\n",
    "        [\n",
    "            \"pois\",\n",
    "            \"dates\",\n",
    "            \"TZs\",\n",
    "            \"is_frequent\",\n",
    "        ]\n",
    "    )\n",
    "    .group_by(\"user\")\n",
    "    .agg(\n",
    "        [\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).alias(\"pois\"),\n",
    "            rs.col(\"dates\").filter(rs.col(\"is_frequent\")).alias(\"dates\"),\n",
    "            rs.col(\"TZs\").filter(rs.col(\"is_frequent\")).alias(\"TZs\"),\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).n_unique().alias(\"n_pois\"),\n",
    "            rs.col(\"pois\").filter(rs.col(\"is_frequent\")).count().alias(\"n_checkins\"),\n",
    "        ]\n",
    "    )\n",
    "    .filter(rs.col(\"n_checkins\") > 0)\n",
    "    .filter(rs.col(\"n_pois\") > 0)\n",
    "    .collect()\n",
    ")  # filter out infrequent pois and users with no pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>user</th><th>pois</th><th>dates</th><th>TZs</th><th>n_pois</th><th>n_checkins</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td><td>19862.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>156852.822274</td><td>null</td><td>null</td><td>null</td><td>6.123452</td><td>8.831437</td></tr><tr><td>&quot;std&quot;</td><td>76314.892884</td><td>null</td><td>null</td><td>null</td><td>4.609024</td><td>6.877662</td></tr><tr><td>&quot;min&quot;</td><td>49.0</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>1.0</td></tr><tr><td>&quot;25%&quot;</td><td>95613.0</td><td>null</td><td>null</td><td>null</td><td>3.0</td><td>4.0</td></tr><tr><td>&quot;50%&quot;</td><td>167846.0</td><td>null</td><td>null</td><td>null</td><td>5.0</td><td>7.0</td></tr><tr><td>&quot;75%&quot;</td><td>224576.0</td><td>null</td><td>null</td><td>null</td><td>8.0</td><td>12.0</td></tr><tr><td>&quot;max&quot;</td><td>266909.0</td><td>null</td><td>null</td><td>null</td><td>32.0</td><td>46.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 7)\n",
       "┌────────────┬───────────────┬─────────┬─────────┬─────────┬──────────┬────────────┐\n",
       "│ statistic  ┆ user          ┆ pois    ┆ dates   ┆ TZs     ┆ n_pois   ┆ n_checkins │\n",
       "│ ---        ┆ ---           ┆ ---     ┆ ---     ┆ ---     ┆ ---      ┆ ---        │\n",
       "│ str        ┆ f64           ┆ f64     ┆ f64     ┆ f64     ┆ f64      ┆ f64        │\n",
       "╞════════════╪═══════════════╪═════════╪═════════╪═════════╪══════════╪════════════╡\n",
       "│ count      ┆ 19862.0       ┆ 19862.0 ┆ 19862.0 ┆ 19862.0 ┆ 19862.0  ┆ 19862.0    │\n",
       "│ null_count ┆ 0.0           ┆ 0.0     ┆ 0.0     ┆ 0.0     ┆ 0.0      ┆ 0.0        │\n",
       "│ mean       ┆ 156852.822274 ┆ null    ┆ null    ┆ null    ┆ 6.123452 ┆ 8.831437   │\n",
       "│ std        ┆ 76314.892884  ┆ null    ┆ null    ┆ null    ┆ 4.609024 ┆ 6.877662   │\n",
       "│ min        ┆ 49.0          ┆ null    ┆ null    ┆ null    ┆ 1.0      ┆ 1.0        │\n",
       "│ 25%        ┆ 95613.0       ┆ null    ┆ null    ┆ null    ┆ 3.0      ┆ 4.0        │\n",
       "│ 50%        ┆ 167846.0      ┆ null    ┆ null    ┆ null    ┆ 5.0      ┆ 7.0        │\n",
       "│ 75%        ┆ 224576.0      ┆ null    ┆ null    ┆ null    ┆ 8.0      ┆ 12.0       │\n",
       "│ max        ┆ 266909.0      ┆ null    ┆ null    ┆ null    ┆ 32.0     ┆ 46.0       │\n",
       "└────────────┴───────────────┴─────────┴─────────┴─────────┴──────────┴────────────┘"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, culling is done, we can appreciate that `polars`'s SQL/functional-style API is different from Pandas, but it is very powerful and efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is geohashing the POIs, that is, we want to convert the latitude-longitude positions of the POIs into a grid-based geohash representation, which will form the basis for our network's embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash2 as gh\n",
    "\n",
    "pois = rs.read_csv(\n",
    "    \"dataset_TIST2015/dataset_TIST2015_POIs.txt\",\n",
    "    has_header=False,\n",
    "    low_memory=True,\n",
    "    separator=\"\\t\",\n",
    ")\n",
    "pois.columns = [\"poi\", \"lat\", \"long\", \"category\", \"country\"]\n",
    "pois = pois.drop(\"category\").drop(\"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois = (\n",
    "    pois.lazy()\n",
    "    .filter(rs.col(\"poi\").is_in(frequent_pois))\n",
    "    .select(\n",
    "        [\n",
    "            rs.col(\"poi\"),\n",
    "            rs.struct(\n",
    "                [\n",
    "                    rs.col(\"lat\").cast(rs.Float32),\n",
    "                    rs.col(\"long\").cast(rs.Float32),\n",
    "                ]\n",
    "            )\n",
    "            .alias(\"location\")\n",
    "            .map_elements(\n",
    "                lambda s: gh.encode(s[\"lat\"], s[\"long\"], precision=6),\n",
    "                return_dtype=rs.String,\n",
    "            )\n",
    "            .alias(\"geohash\"),\n",
    "        ]\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "poi_geo_dict = dict(zip(pois[\"poi\"], pois[\"geohash\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row in final_data, add the geohash of the pois by hitting the poi_geo_dict\n",
    "\n",
    "final_data = final_data.with_columns(\n",
    "    [\n",
    "        rs.col(\"pois\")\n",
    "        .map_elements(\n",
    "            lambda s: [poi_geo_dict[s] for s in s],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "        .alias(\"geohashes\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sat Apr 14 16:10:05 +0000 2012',\n",
       " 'Sun Apr 15 12:14:39 +0000 2012',\n",
       " 'Sun Apr 15 15:33:50 +0000 2012',\n",
       " 'Sun Dec 30 11:20:04 +0000 2012',\n",
       " 'Mon Dec 31 10:27:45 +0000 2012',\n",
       " 'Tue Jan 01 17:38:14 +0000 2013']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"dates\"][79].to_list()  # check out a temporal sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[120, 120, 120, 60, 60, 60]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[\"TZs\"][79].to_list()  # ... and the corresponding timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work *might* seem over, however, we still have timezones to account for, we want to normalize everything according to GMT, so we convert the timestamps accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "def UTC_to_local(utc, tz):\n",
    "\n",
    "    date = datetime.datetime.strptime(utc, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    date = date.replace(tzinfo=datetime.timezone.utc)\n",
    "\n",
    "    # shift by tz offset\n",
    "    date = date.astimezone(datetime.timezone(datetime.timedelta(minutes=tz)))\n",
    "\n",
    "    date_s = datetime.datetime.strftime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return date_s\n",
    "\n",
    "\n",
    "def to_UNIX_time(date):\n",
    "    return datetime.datetime.strptime(\n",
    "        date, \"%Y-%m-%d %H:%M:%S\"\n",
    "    ).timestamp()  # we use UNIX time as a key for sorting the POIs in our polars query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-05-21 08:53:01'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UTC_to_local(\"Mon May 21 15:53:01 +0000 2012\", -420)  # example of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.with_columns(\n",
    "    [\n",
    "        rs.struct([rs.col(\"dates\"), rs.col(\"TZs\")])\n",
    "        .alias(\"times\")\n",
    "        .map_elements(\n",
    "            lambda struct: [\n",
    "                UTC_to_local(date, tz)\n",
    "                for date, tz in zip(struct[\"dates\"], struct[\"TZs\"])\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "    ]\n",
    ")  # This performs timezone conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sorted = final_data.select(  # sort the times\n",
    "    [\n",
    "        rs.col(\"user\"),\n",
    "        rs.struct(\n",
    "            [\n",
    "                rs.col(\"pois\"),\n",
    "                rs.col(\"times\"),\n",
    "            ]\n",
    "        ).map_elements(\n",
    "            lambda struct: [\n",
    "                poi\n",
    "                for poi, _ in sorted(\n",
    "                    zip(  # here we sort the POIs struct by UNIX timestamps of the GMT times\n",
    "                        struct[\"pois\"], [to_UNIX_time(date) for date in struct[\"times\"]]\n",
    "                    ),\n",
    "                    key=lambda s: s[1],\n",
    "                )\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        ),\n",
    "        rs.struct(\n",
    "            [\n",
    "                rs.col(\"geohashes\"),\n",
    "                rs.col(\"times\"),\n",
    "            ]\n",
    "        ).map_elements(\n",
    "            lambda struct: [\n",
    "                geo\n",
    "                for geo, _ in sorted(\n",
    "                    zip(\n",
    "                        struct[\"geohashes\"],  # same thing goes on for geohashes\n",
    "                        [to_UNIX_time(date) for date in struct[\"times\"]],\n",
    "                    ),\n",
    "                    key=lambda s: s[1],\n",
    "                )\n",
    "            ],\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        ),\n",
    "        rs.col(\"times\")\n",
    "        .map_elements(\n",
    "            lambda dates: sorted(dates, key=to_UNIX_time),\n",
    "            return_dtype=rs.List(rs.String),\n",
    "        )\n",
    "        .alias(\"times_sorted\"),\n",
    "        rs.col(\"n_checkins\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# P.S, admittedly, it would have been more efficient to encode the geohashes *after* sorting the POIs,\n",
    "# so that we could save on the sorting of the geohashes. Tough luck, you can't win 'em all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (19_862, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user</th><th>pois</th><th>geohashes</th><th>times_sorted</th><th>n_checkins</th></tr><tr><td>i64</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>u32</td></tr></thead><tbody><tr><td>128006</td><td>[&quot;4b46e964f964a520812926e3&quot;, &quot;4b46e964f964a520812926e3&quot;, … &quot;4b058782f964a520bc9622e3&quot;]</td><td>[&quot;wdw49e&quot;, &quot;wdw49e&quot;, … &quot;wydm9w&quot;]</td><td>[&quot;2012-04-25 20:28:18&quot;, &quot;2012-04-25 21:20:04&quot;, … &quot;2012-04-29 10:54:38&quot;]</td><td>5</td></tr><tr><td>12806</td><td>[&quot;4b793ac7f964a520faef2ee3&quot;, &quot;4ee467ea722ea7b945271daa&quot;, … &quot;4b269592f964a520e57d24e3&quot;]</td><td>[&quot;xn324f&quot;, &quot;xn0me7&quot;, … &quot;wyn5wt&quot;]</td><td>[&quot;2012-05-05 13:51:26&quot;, &quot;2012-05-05 14:43:40&quot;, … &quot;2012-10-12 18:01:50&quot;]</td><td>8</td></tr><tr><td>140981</td><td>[&quot;4bdbf95ac79cc92857ec84e9&quot;, &quot;4bdbf95ac79cc92857ec84e9&quot;, … &quot;4d678903cba6a35df698cdc1&quot;]</td><td>[&quot;qqgudx&quot;, &quot;qqgudx&quot;, … &quot;qqguf8&quot;]</td><td>[&quot;2012-08-14 16:31:55&quot;, &quot;2012-12-02 19:06:52&quot;, … &quot;2013-06-01 20:19:52&quot;]</td><td>10</td></tr><tr><td>75683</td><td>[&quot;4b3b3bfef964a520af7125e3&quot;, &quot;4b3b3bfef964a520af7125e3&quot;, … &quot;4b5662c7f964a520370e28e3&quot;]</td><td>[&quot;wvuxpf&quot;, &quot;wvuxpf&quot;, … &quot;wvuz0k&quot;]</td><td>[&quot;2012-04-14 11:25:54&quot;, &quot;2012-04-14 21:36:52&quot;, … &quot;2012-06-14 16:12:17&quot;]</td><td>10</td></tr><tr><td>220224</td><td>[&quot;50ab393de4b00936cfd2b4f0&quot;, &quot;4b0f8426f964a520de6223e3&quot;, … &quot;4b058805f964a520fbac22e3&quot;]</td><td>[&quot;w2834g&quot;, &quot;w283ft&quot;, … &quot;w2839x&quot;]</td><td>[&quot;2012-12-31 12:17:21&quot;, &quot;2013-01-01 21:31:58&quot;, … &quot;2013-07-10 14:13:48&quot;]</td><td>8</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>96916</td><td>[&quot;4b2d0e1af964a52037cd24e3&quot;, &quot;4b2d0e1af964a52037cd24e3&quot;, … &quot;4b2d0e1af964a52037cd24e3&quot;]</td><td>[&quot;6gycd7&quot;, &quot;6gycd7&quot;, … &quot;6gycd7&quot;]</td><td>[&quot;2012-04-18 20:58:42&quot;, &quot;2012-04-19 09:15:21&quot;, … &quot;2012-08-17 17:02:27&quot;]</td><td>5</td></tr><tr><td>238001</td><td>[&quot;41059b00f964a520850b1fe3&quot;, &quot;49e03a9df964a52047611fe3&quot;, … &quot;4aa76d20f964a520d24c20e3&quot;]</td><td>[&quot;9q8vzp&quot;, &quot;9q9ng0&quot;, … &quot;dhvr1v&quot;]</td><td>[&quot;2012-04-11 17:27:05&quot;, &quot;2012-04-18 19:40:37&quot;, … &quot;2012-10-24 19:09:09&quot;]</td><td>8</td></tr><tr><td>110621</td><td>[&quot;4b4de485f964a52052da26e3&quot;]</td><td>[&quot;w282cn&quot;]</td><td>[&quot;2012-12-15 21:20:54&quot;]</td><td>1</td></tr><tr><td>17208</td><td>[&quot;4beed91be24d20a143777314&quot;, &quot;4bb8e2367421a593c439c240&quot;, … &quot;4b793d31f964a5205bf02ee3&quot;]</td><td>[&quot;d2g63r&quot;, &quot;d2g6dc&quot;, … &quot;d2g68z&quot;]</td><td>[&quot;2012-05-18 08:13:41&quot;, &quot;2012-06-10 16:13:07&quot;, … &quot;2013-05-06 13:20:27&quot;]</td><td>6</td></tr><tr><td>91185</td><td>[&quot;4b7980a2f964a5202bfd2ee3&quot;, &quot;4ba0786cf964a520ec6e37e3&quot;, … &quot;49f65012f964a5202f6c1fe3&quot;]</td><td>[&quot;sp36zj&quot;, &quot;ezp8tj&quot;, … &quot;9q5ctn&quot;]</td><td>[&quot;2012-11-16 21:12:38&quot;, &quot;2013-01-11 12:55:43&quot;, … &quot;2013-08-17 14:49:17&quot;]</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (19_862, 5)\n",
       "┌────────┬──────────────────────────────┬────────────────────────┬────────────────────┬────────────┐\n",
       "│ user   ┆ pois                         ┆ geohashes              ┆ times_sorted       ┆ n_checkins │\n",
       "│ ---    ┆ ---                          ┆ ---                    ┆ ---                ┆ ---        │\n",
       "│ i64    ┆ list[str]                    ┆ list[str]              ┆ list[str]          ┆ u32        │\n",
       "╞════════╪══════════════════════════════╪════════════════════════╪════════════════════╪════════════╡\n",
       "│ 128006 ┆ [\"4b46e964f964a520812926e3\", ┆ [\"wdw49e\", \"wdw49e\", … ┆ [\"2012-04-25       ┆ 5          │\n",
       "│        ┆ \"…                           ┆ \"wydm9w…               ┆ 20:28:18\", \"2012-… ┆            │\n",
       "│ 12806  ┆ [\"4b793ac7f964a520faef2ee3\", ┆ [\"xn324f\", \"xn0me7\", … ┆ [\"2012-05-05       ┆ 8          │\n",
       "│        ┆ \"…                           ┆ \"wyn5wt…               ┆ 13:51:26\", \"2012-… ┆            │\n",
       "│ 140981 ┆ [\"4bdbf95ac79cc92857ec84e9\", ┆ [\"qqgudx\", \"qqgudx\", … ┆ [\"2012-08-14       ┆ 10         │\n",
       "│        ┆ \"…                           ┆ \"qqguf8…               ┆ 16:31:55\", \"2012-… ┆            │\n",
       "│ 75683  ┆ [\"4b3b3bfef964a520af7125e3\", ┆ [\"wvuxpf\", \"wvuxpf\", … ┆ [\"2012-04-14       ┆ 10         │\n",
       "│        ┆ \"…                           ┆ \"wvuz0k…               ┆ 11:25:54\", \"2012-… ┆            │\n",
       "│ 220224 ┆ [\"50ab393de4b00936cfd2b4f0\", ┆ [\"w2834g\", \"w283ft\", … ┆ [\"2012-12-31       ┆ 8          │\n",
       "│        ┆ \"…                           ┆ \"w2839x…               ┆ 12:17:21\", \"2013-… ┆            │\n",
       "│ …      ┆ …                            ┆ …                      ┆ …                  ┆ …          │\n",
       "│ 96916  ┆ [\"4b2d0e1af964a52037cd24e3\", ┆ [\"6gycd7\", \"6gycd7\", … ┆ [\"2012-04-18       ┆ 5          │\n",
       "│        ┆ \"…                           ┆ \"6gycd7…               ┆ 20:58:42\", \"2012-… ┆            │\n",
       "│ 238001 ┆ [\"41059b00f964a520850b1fe3\", ┆ [\"9q8vzp\", \"9q9ng0\", … ┆ [\"2012-04-11       ┆ 8          │\n",
       "│        ┆ \"…                           ┆ \"dhvr1v…               ┆ 17:27:05\", \"2012-… ┆            │\n",
       "│ 110621 ┆ [\"4b4de485f964a52052da26e3\"] ┆ [\"w282cn\"]             ┆ [\"2012-12-15       ┆ 1          │\n",
       "│        ┆                              ┆                        ┆ 21:20:54\"]         ┆            │\n",
       "│ 17208  ┆ [\"4beed91be24d20a143777314\", ┆ [\"d2g63r\", \"d2g6dc\", … ┆ [\"2012-05-18       ┆ 6          │\n",
       "│        ┆ \"…                           ┆ \"d2g68z…               ┆ 08:13:41\", \"2012-… ┆            │\n",
       "│ 91185  ┆ [\"4b7980a2f964a5202bfd2ee3\", ┆ [\"sp36zj\", \"ezp8tj\", … ┆ [\"2012-11-16       ┆ 5          │\n",
       "│        ┆ \"…                           ┆ \"9q5ctn…               ┆ 21:12:38\", \"2013-… ┆            │\n",
       "└────────┴──────────────────────────────┴────────────────────────┴────────────────────┴────────────┘"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now need to obtain a dataframe containing: each POI, it's geohash, and a set of all the check-ins it appears in\n",
    "this is just one `polars` query away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pois_checkins = final_sorted.explode([\"pois\", \"geohashes\"]).drop(\"n_checkins\")\n",
    "\n",
    "pois_checkins = (\n",
    "    pois_checkins.with_columns(\n",
    "        [\n",
    "            rs.col(\"geohashes\").map_elements(lambda s: s[:4], rs.String).alias(\"g4\"),\n",
    "        ]\n",
    "    )\n",
    "    .drop(\"geohashes\")\n",
    "    .group_by([\"pois\", \"g4\"])\n",
    "    .agg([rs.col(\"times_sorted\").flatten().alias(\"checkin_times\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4b7980a2f964a5202bfd2ee3&quot;</td><td>&quot;sp36&quot;</td><td>[&quot;2013-08-13 17:32:42&quot;, &quot;2013-08-20 14:56:09&quot;, … &quot;2013-08-17 14:49:17&quot;]</td></tr><tr><td>&quot;4c9426c038dd8cfa45adc662&quot;</td><td>&quot;w0zf&quot;</td><td>[&quot;2013-01-12 20:47:50&quot;, &quot;2013-01-22 17:04:44&quot;, … &quot;2013-07-20 14:57:18&quot;]</td></tr><tr><td>&quot;4bd2f7ffb221c9b67b89d8d0&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-11-12 19:26:34&quot;, &quot;2012-12-01 12:59:23&quot;, … &quot;2013-02-17 17:17:39&quot;]</td></tr><tr><td>&quot;4b1bc93ef964a52068fd23e3&quot;</td><td>&quot;6gyc&quot;</td><td>[&quot;2012-12-17 14:49:08&quot;, &quot;2012-12-18 16:19:31&quot;, … &quot;2013-04-11 08:37:00&quot;]</td></tr><tr><td>&quot;4b4b87b5f964a5204a9f26e3&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2013-03-12 14:01:18&quot;, &quot;2013-03-20 15:53:13&quot;, … &quot;2013-08-27 15:36:51&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4ae9e965f964a5208db721e3&quot;</td><td>&quot;dnru&quot;</td><td>[&quot;2012-04-07 23:10:28&quot;, &quot;2012-04-18 19:07:51&quot;, … &quot;2013-06-02 17:32:59&quot;]</td></tr><tr><td>&quot;4d683074d4c288bf50da7065&quot;</td><td>&quot;ezjm&quot;</td><td>[&quot;2013-06-22 19:57:39&quot;, &quot;2013-06-30 16:49:07&quot;, … &quot;2013-06-16 20:51:21&quot;]</td></tr><tr><td>&quot;4f109f74e4b0b827c66a1513&quot;</td><td>&quot;sy89&quot;</td><td>[&quot;2012-04-23 18:56:44&quot;, &quot;2012-05-14 15:45:47&quot;, … &quot;2013-08-05 12:07:37&quot;]</td></tr><tr><td>&quot;4b4bee5ff964a5207cab26e3&quot;</td><td>&quot;xn77&quot;</td><td>[&quot;2012-10-18 23:55:50&quot;, &quot;2012-11-22 23:50:21&quot;, … &quot;2013-08-25 15:25:20&quot;]</td></tr><tr><td>&quot;4c1a343cf551ef3b52574768&quot;</td><td>&quot;sxjd&quot;</td><td>[&quot;2013-04-21 16:51:10&quot;, &quot;2013-05-09 09:04:48&quot;, … &quot;2013-02-17 17:17:39&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 3)\n",
       "┌──────────────────────────┬──────┬─────────────────────────────────┐\n",
       "│ pois                     ┆ g4   ┆ checkin_times                   │\n",
       "│ ---                      ┆ ---  ┆ ---                             │\n",
       "│ str                      ┆ str  ┆ list[str]                       │\n",
       "╞══════════════════════════╪══════╪═════════════════════════════════╡\n",
       "│ 4b7980a2f964a5202bfd2ee3 ┆ sp36 ┆ [\"2013-08-13 17:32:42\", \"2013-… │\n",
       "│ 4c9426c038dd8cfa45adc662 ┆ w0zf ┆ [\"2013-01-12 20:47:50\", \"2013-… │\n",
       "│ 4bd2f7ffb221c9b67b89d8d0 ┆ sxk9 ┆ [\"2012-11-12 19:26:34\", \"2012-… │\n",
       "│ 4b1bc93ef964a52068fd23e3 ┆ 6gyc ┆ [\"2012-12-17 14:49:08\", \"2012-… │\n",
       "│ 4b4b87b5f964a5204a9f26e3 ┆ sxk9 ┆ [\"2013-03-12 14:01:18\", \"2013-… │\n",
       "│ …                        ┆ …    ┆ …                               │\n",
       "│ 4ae9e965f964a5208db721e3 ┆ dnru ┆ [\"2012-04-07 23:10:28\", \"2012-… │\n",
       "│ 4d683074d4c288bf50da7065 ┆ ezjm ┆ [\"2013-06-22 19:57:39\", \"2013-… │\n",
       "│ 4f109f74e4b0b827c66a1513 ┆ sy89 ┆ [\"2012-04-23 18:56:44\", \"2012-… │\n",
       "│ 4b4bee5ff964a5207cab26e3 ┆ xn77 ┆ [\"2012-10-18 23:55:50\", \"2012-… │\n",
       "│ 4c1a343cf551ef3b52574768 ┆ sxjd ┆ [\"2013-04-21 16:51:10\", \"2013-… │\n",
       "└──────────────────────────┴──────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_checkins  # with this we can *efficiently* build our POI-POI spatial-temporal graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UTC_to_weekslot(utc: str) -> int:\n",
    "    \"\"\"UTC_to_weekslot converts a UTC timestamp to a weekslot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    utc : str\n",
    "        A string representing a UTC timestamp.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        A weekslot in the range [0, 56).\n",
    "    \"\"\"\n",
    "\n",
    "    date = datetime.datetime.strptime(utc, \"%Y-%m-%d %H:%M:%S\")\n",
    "    week = date.weekday()\n",
    "    hour = date.hour\n",
    "\n",
    "    return week * 8 + hour // 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to encode all of our inputs for our neural networks, this could *probably* be done \n",
    "with polars magic, but it's too delicate and we prefer classic for-looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dict = {\n",
    "    \"users\": LabelEncoder(),\n",
    "    \"pois\": LabelEncoder(),\n",
    "    \"g2\": LabelEncoder(),\n",
    "    \"g3\": LabelEncoder(),\n",
    "    \"g4\": LabelEncoder(),\n",
    "    \"g5\": LabelEncoder(),\n",
    "    \"g6\": LabelEncoder(),\n",
    "}\n",
    "\n",
    "encoded_data = {\n",
    "    \"users\": [],\n",
    "    \"pois\": [],\n",
    "    \"g2\": [],\n",
    "    \"g3\": [],\n",
    "    \"g4\": [],\n",
    "    \"g5\": [],\n",
    "    \"g6\": [],\n",
    "}\n",
    "\n",
    "unique_data = {\n",
    "    \"users\": set(),\n",
    "    \"pois\": set(),\n",
    "    \"g2\": set(),\n",
    "    \"g3\": set(),\n",
    "    \"g4\": set(),\n",
    "    \"g5\": set(),\n",
    "    \"g6\": set(),\n",
    "}\n",
    "\n",
    "# quick and dirty encoding:\n",
    "# 1. put every unique symbol in a list\n",
    "# 2. fit the respective encoder\n",
    "# 3. transform the lists\n",
    "\n",
    "for i, row in enumerate(final_sorted.iter_rows()):\n",
    "\n",
    "    user, pois, geohashes, times_sorted, n_checkins = row\n",
    "\n",
    "    g2 = [geo[:2] for geo in geohashes]\n",
    "    g3 = [geo[:3] for geo in geohashes]\n",
    "    g4 = [geo[:4] for geo in geohashes]\n",
    "    g5 = [geo[:5] for geo in geohashes]\n",
    "    g6 = [geo[:6] for geo in geohashes]  # redundant, but I like symmetry\n",
    "\n",
    "    unique_data[\"users\"].add(user)\n",
    "    unique_data[\"pois\"].update(pois)\n",
    "    unique_data[\"g2\"].update(g2)\n",
    "    unique_data[\"g3\"].update(g3)\n",
    "    unique_data[\"g4\"].update(g4)\n",
    "    unique_data[\"g5\"].update(g5)\n",
    "    unique_data[\"g6\"].update(g6)\n",
    "\n",
    "for property, enc, data in zip(\n",
    "    encoder_dict.keys(), encoder_dict.values(), unique_data.values()\n",
    "):\n",
    "    enc.fit(list(data))\n",
    "    encoder_dict[property] = enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19862/19862 [03:17<00:00, 100.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# this could be optimized, right now it takes a while, at least we have a nice progress bar to look at\n",
    "\n",
    "ds_size = len(final_sorted)\n",
    "\n",
    "for i, row in tqdm(enumerate(final_sorted.iter_rows()), total=ds_size):\n",
    "\n",
    "    user, pois, geohashes, times_sorted, n_checkins = row\n",
    "\n",
    "    g2 = [geo[:2] for geo in geohashes]\n",
    "    g3 = [geo[:3] for geo in geohashes]\n",
    "    g4 = [geo[:4] for geo in geohashes]\n",
    "    g5 = [geo[:5] for geo in geohashes]\n",
    "    g6 = [geo[:6] for geo in geohashes]\n",
    "\n",
    "    encoded_data[\"users\"].append(encoder_dict[\"users\"].transform([user])[0])\n",
    "    encoded_data[\"pois\"].append(encoder_dict[\"pois\"].transform(pois))\n",
    "    encoded_data[\"g2\"].append(encoder_dict[\"g2\"].transform(g2))\n",
    "    encoded_data[\"g3\"].append(encoder_dict[\"g3\"].transform(g3))\n",
    "    encoded_data[\"g4\"].append(encoder_dict[\"g4\"].transform(g4))\n",
    "    encoded_data[\"g5\"].append(encoder_dict[\"g5\"].transform(g5))\n",
    "    encoded_data[\"g6\"].append(encoder_dict[\"g6\"].transform(g6))\n",
    "\n",
    "    # sum 1 to all values to avoid 0s\n",
    "    encoded_data[\"users\"][-1] += 1\n",
    "    encoded_data[\"pois\"][-1] += 1\n",
    "    encoded_data[\"g2\"][-1] += 1\n",
    "    encoded_data[\"g3\"][-1] += 1\n",
    "    encoded_data[\"g4\"][-1] += 1\n",
    "    encoded_data[\"g5\"][-1] += 1\n",
    "    encoded_data[\"g6\"][-1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that we left space for the padding token\n",
    "min((arr.min() for arr in encoded_data[\"pois\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4_455, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>pois</th><th>g4</th><th>checkin_times</th></tr><tr><td>str</td><td>str</td><td>list[str]</td></tr></thead><tbody><tr><td>&quot;4b7980a2f964a5202bfd2ee3&quot;</td><td>&quot;sp36&quot;</td><td>[&quot;2013-08-13 17:32:42&quot;, &quot;2013-08-20 14:56:09&quot;, … &quot;2013-08-17 14:49:17&quot;]</td></tr><tr><td>&quot;4c9426c038dd8cfa45adc662&quot;</td><td>&quot;w0zf&quot;</td><td>[&quot;2013-01-12 20:47:50&quot;, &quot;2013-01-22 17:04:44&quot;, … &quot;2013-07-20 14:57:18&quot;]</td></tr><tr><td>&quot;4bd2f7ffb221c9b67b89d8d0&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2012-11-12 19:26:34&quot;, &quot;2012-12-01 12:59:23&quot;, … &quot;2013-02-17 17:17:39&quot;]</td></tr><tr><td>&quot;4b1bc93ef964a52068fd23e3&quot;</td><td>&quot;6gyc&quot;</td><td>[&quot;2012-12-17 14:49:08&quot;, &quot;2012-12-18 16:19:31&quot;, … &quot;2013-04-11 08:37:00&quot;]</td></tr><tr><td>&quot;4b4b87b5f964a5204a9f26e3&quot;</td><td>&quot;sxk9&quot;</td><td>[&quot;2013-03-12 14:01:18&quot;, &quot;2013-03-20 15:53:13&quot;, … &quot;2013-08-27 15:36:51&quot;]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4ae9e965f964a5208db721e3&quot;</td><td>&quot;dnru&quot;</td><td>[&quot;2012-04-07 23:10:28&quot;, &quot;2012-04-18 19:07:51&quot;, … &quot;2013-06-02 17:32:59&quot;]</td></tr><tr><td>&quot;4d683074d4c288bf50da7065&quot;</td><td>&quot;ezjm&quot;</td><td>[&quot;2013-06-22 19:57:39&quot;, &quot;2013-06-30 16:49:07&quot;, … &quot;2013-06-16 20:51:21&quot;]</td></tr><tr><td>&quot;4f109f74e4b0b827c66a1513&quot;</td><td>&quot;sy89&quot;</td><td>[&quot;2012-04-23 18:56:44&quot;, &quot;2012-05-14 15:45:47&quot;, … &quot;2013-08-05 12:07:37&quot;]</td></tr><tr><td>&quot;4b4bee5ff964a5207cab26e3&quot;</td><td>&quot;xn77&quot;</td><td>[&quot;2012-10-18 23:55:50&quot;, &quot;2012-11-22 23:50:21&quot;, … &quot;2013-08-25 15:25:20&quot;]</td></tr><tr><td>&quot;4c1a343cf551ef3b52574768&quot;</td><td>&quot;sxjd&quot;</td><td>[&quot;2013-04-21 16:51:10&quot;, &quot;2013-05-09 09:04:48&quot;, … &quot;2013-02-17 17:17:39&quot;]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4_455, 3)\n",
       "┌──────────────────────────┬──────┬─────────────────────────────────┐\n",
       "│ pois                     ┆ g4   ┆ checkin_times                   │\n",
       "│ ---                      ┆ ---  ┆ ---                             │\n",
       "│ str                      ┆ str  ┆ list[str]                       │\n",
       "╞══════════════════════════╪══════╪═════════════════════════════════╡\n",
       "│ 4b7980a2f964a5202bfd2ee3 ┆ sp36 ┆ [\"2013-08-13 17:32:42\", \"2013-… │\n",
       "│ 4c9426c038dd8cfa45adc662 ┆ w0zf ┆ [\"2013-01-12 20:47:50\", \"2013-… │\n",
       "│ 4bd2f7ffb221c9b67b89d8d0 ┆ sxk9 ┆ [\"2012-11-12 19:26:34\", \"2012-… │\n",
       "│ 4b1bc93ef964a52068fd23e3 ┆ 6gyc ┆ [\"2012-12-17 14:49:08\", \"2012-… │\n",
       "│ 4b4b87b5f964a5204a9f26e3 ┆ sxk9 ┆ [\"2013-03-12 14:01:18\", \"2013-… │\n",
       "│ …                        ┆ …    ┆ …                               │\n",
       "│ 4ae9e965f964a5208db721e3 ┆ dnru ┆ [\"2012-04-07 23:10:28\", \"2012-… │\n",
       "│ 4d683074d4c288bf50da7065 ┆ ezjm ┆ [\"2013-06-22 19:57:39\", \"2013-… │\n",
       "│ 4f109f74e4b0b827c66a1513 ┆ sy89 ┆ [\"2012-04-23 18:56:44\", \"2012-… │\n",
       "│ 4b4bee5ff964a5207cab26e3 ┆ xn77 ┆ [\"2012-10-18 23:55:50\", \"2012-… │\n",
       "│ 4c1a343cf551ef3b52574768 ┆ sxjd ┆ [\"2013-04-21 16:51:10\", \"2013-… │\n",
       "└──────────────────────────┴──────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_checkins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also encode the graph dataframe so we can build the graphs\n",
    "\n",
    "pois_checkins = (\n",
    "    pois_checkins.lazy()\n",
    "    .with_columns(\n",
    "        [\n",
    "            rs.col(\"pois\").map_elements(\n",
    "                lambda s: encoder_dict[\"pois\"].transform([s])[0] + 1, rs.Int64\n",
    "            ),\n",
    "            rs.col(\"g4\").map_elements(\n",
    "                lambda s: encoder_dict[\"g4\"].transform([s])[0] + 1, rs.Int64\n",
    "            ),  # apply utc_to_weekslot to each timestamp in the list\n",
    "            rs.col(\"checkin_times\").map_elements(\n",
    "                lambda s: [UTC_to_weekslot(date) for date in s], rs.List(rs.Int64)\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    .sort(\"pois\")\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fictitious POI 0 to the graph, with nonexistent geohash and no timeslot, so we get a 0 row and column for the padding token\n",
    "fake_datapoint = rs.DataFrame(\n",
    "    {\n",
    "        \"pois\": [0],\n",
    "        \"g4\": [pois_checkins[\"g4\"].max() + 42],\n",
    "        \"checkin_times\": [[43]],\n",
    "    }\n",
    ")\n",
    "# this is a lot of work since polars dataframes are immutable by default, we have to run a query to change the 43 into an empty list\n",
    "# we NEED the 43 otherwise polars won't infer the datatype of the list\n",
    "\n",
    "fake_datapoint = fake_datapoint.with_columns(\n",
    "    [rs.col(\"checkin_times\").map_elements(lambda s: [], rs.List(rs.Int64))]\n",
    ")\n",
    "\n",
    "pois_checkins = fake_datapoint.vstack(pois_checkins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_row = np.array(pois_checkins[\"g4\"].to_list()).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer product using equality\n",
    "spatial_graph = (spatial_row == spatial_row.T).astype(np.int32)\n",
    "spatial_graph[0, 0] = (\n",
    "    0  # the fake g4 is still equal to itself, we suppress this equality\n",
    ")\n",
    "spatial_graph = torch.tensor(spatial_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_row = pois_checkins[\"checkin_times\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_graph = np.zeros((spatial_row.shape[0], spatial_row.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_sets = [np.array(list(set(row))) for row in temporal_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_sets = torch.zeros((len(temporal_sets), 56), dtype=torch.int8)\n",
    "\n",
    "for i, r in enumerate(temporal_row):\n",
    "    indices = torch.tensor(r, dtype=torch.long)\n",
    "    time_sets[i, indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4456, 56])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_sets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND outer product\n",
    "\n",
    "intersection = time_sets @ time_sets.T\n",
    "union = time_sets.unsqueeze(1) | time_sets.unsqueeze(0)\n",
    "union = union.sum(dim=2)\n",
    "iou = intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_graph = iou >= 0.9\n",
    "# cast to int\n",
    "temporal_graph = temporal_graph.int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_graph[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print information about the sparsity of the graphs, we note that \n",
    "the sparsity of the graphs is similar to that of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal sparsity: 97.05%\n",
      "Spatial sparsity: 96.99%\n"
     ]
    }
   ],
   "source": [
    "temporal_density = (\n",
    "    temporal_graph.sum() / (temporal_graph.shape[0] * temporal_graph.shape[1])\n",
    ").item()\n",
    "spatial_density = (\n",
    "    spatial_graph.sum() / (spatial_graph.shape[0] * spatial_graph.shape[1])\n",
    ").item()\n",
    "\n",
    "print(f\"Temporal sparsity: {(1 - temporal_density) * 100:.2f}%\")\n",
    "\n",
    "print(f\"Spatial sparsity: {(1 - spatial_density) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper utilizes metrics that check if the target is in the top-k recommendations, we implement them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyAtK(nn.Module):\n",
    "    def __init__(self, k: int):\n",
    "        \"\"\"__init__ initializes the AccuracyAtK module.\n",
    "\n",
    "        Accuracy@k is the proportion of correct predictions in the top-k elements.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            The number of top-k elements to consider.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"forward computes the accuracy at k between logits and targets.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        logits : torch.Tensor\n",
    "            Class probability, either (B, C) or (B, T, C)\n",
    "        targets : torch.Tensor\n",
    "            Ground truth class indices, either (B,) or (B, T)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The accuracy at k, a scalar-tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        # Gotta have at least one nasty python one-liner, in memory of the old\n",
    "        # programming lab 1 bachelor course\n",
    "        return (\n",
    "            (logits.topk(self.k, dim=-1)[1] == targets.unsqueeze(-1))\n",
    "            .any(dim=-1)\n",
    "            .float()\n",
    "            .mean()\n",
    "        )\n",
    "\n",
    "\n",
    "class MeanReciprocalRank(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"__init__ initializes the MeanReciprocalRank module.\n",
    "\n",
    "        Mean reciprocal rank is the average of the reciprocal ranks of the top-k elements.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"forward computes the mean reciprocal rank between logits and targets.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        logits : torch.Tensor\n",
    "            Class probability\n",
    "        targets : torch.Tensor\n",
    "            Ground truth class indices\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The mean reciprocal rank, a scalar-tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        _, indices = logits.topk(logits.shape[-1], dim=-1)\n",
    "        ranks = (indices == targets.unsqueeze(-1)).nonzero()[:, -1].float() + 1\n",
    "        return (1.0 / ranks).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Datamodule\n",
    "\n",
    "We then define a pytorch dataset and a custom collation function that allows us to dynamically\n",
    "pad sequences to the longest one in the batch (as opposed to the longest one in the dataset)\n",
    "as they are loaded during training, this gives us an edge in performance by dramatically reducing the \n",
    "sparsity of our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def rnn_collation_fn(batch):\n",
    "\n",
    "    users = []\n",
    "    pois = []\n",
    "    g2 = []\n",
    "    g3 = []\n",
    "    g4 = []\n",
    "    g5 = []\n",
    "    g6 = []\n",
    "\n",
    "    for user, poi, geo2, geo3, geo4, geo5, geo6 in batch:\n",
    "        users.append(user)\n",
    "        pois.append(poi)\n",
    "        g2.append(geo2)\n",
    "        g3.append(geo3)\n",
    "        g4.append(geo4)\n",
    "        g5.append(geo5)\n",
    "        g6.append(geo6)\n",
    "    seq = (\n",
    "        torch.tensor(users, dtype=torch.long),\n",
    "        pad_sequence(pois, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g2, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g3, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g4, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g5, batch_first=True, padding_value=0),\n",
    "        pad_sequence(g6, batch_first=True, padding_value=0),\n",
    "    )  # build a sequence\n",
    "\n",
    "    x = (\n",
    "        seq[0],\n",
    "        seq[1][:, :-1],\n",
    "        seq[2][:, :-1],\n",
    "        seq[3][:, :-1],\n",
    "        seq[4][:, :-1],\n",
    "        seq[5][:, :-1],\n",
    "        seq[6][:, :-1],\n",
    "    )  # omit the last one for sample\n",
    "\n",
    "    y = (\n",
    "        seq[0],\n",
    "        seq[1][:, 1:],\n",
    "        seq[2][:, 1:],\n",
    "        seq[3][:, 1:],\n",
    "        seq[4][:, 1:],\n",
    "        seq[5][:, 1:],\n",
    "        seq[6][:, 1:],\n",
    "    )  # omit the first one for ground truth\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class CheckinDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[\"users\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = (\n",
    "            torch.tensor(encoded_data[\"users\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"pois\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g2\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g3\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g4\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g5\"][idx], dtype=torch.long),\n",
    "            torch.tensor(encoded_data[\"g6\"][idx], dtype=torch.long),\n",
    "        )\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckinModule(pl.LightningDataModule):\n",
    "    def __init__(self, encoded_data, batch_size=32, workers=4):\n",
    "        super().__init__()\n",
    "        self.encoded_data = encoded_data\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.whole_dataset = CheckinDataset(self.encoded_data)\n",
    "\n",
    "        l = len(self.whole_dataset)\n",
    "\n",
    "        train_size = int(0.8 * l)\n",
    "        val_size = int(0.1 * l)\n",
    "        test_size = l - train_size - val_size\n",
    "\n",
    "        # generate train, val, test datasets by random split\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = (\n",
    "            torch.utils.data.random_split(\n",
    "                self.whole_dataset, [train_size, val_size, test_size]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.workers,\n",
    "            collate_fn=rnn_collation_fn,\n",
    "        )\n",
    "\n",
    "    def save(self, whole_path, train_path, val_path, test_path):\n",
    "        torch.save(self.whole_dataset, whole_path)\n",
    "        torch.save(self.train_dataset, train_path)\n",
    "        torch.save(self.val_dataset, val_path)\n",
    "        torch.save(self.test_dataset, test_path)\n",
    "\n",
    "    @staticmethod  # load without instantiating\n",
    "    def load(whole_path, train_path, val_path, test_path):\n",
    "        whole_dataset = torch.load(whole_path)\n",
    "        train_dataset = torch.load(train_path)\n",
    "        val_dataset = torch.load(val_path)\n",
    "        test_dataset = torch.load(test_path)\n",
    "        return whole_dataset, train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BaselineDimensions:\n",
    "    nuser: int\n",
    "    npoi: int\n",
    "    g2len: int\n",
    "    g3len: int\n",
    "    g4len: int\n",
    "    g5len: int\n",
    "    g6len: int\n",
    "\n",
    "\n",
    "# HMT_RN (Hierarchical Multi-Task Recurrent Network)\n",
    "class HMT_RN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dimensions: BaselineDimensions,\n",
    "        embedding_dim,\n",
    "        lstm_hidden_dim,\n",
    "        dropout_rate=0.9,  # 0.9 is a lot, but the paper says so.\n",
    "    ):\n",
    "        super(HMT_RN, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = lstm_hidden_dim\n",
    "        self.dims = dimensions\n",
    "\n",
    "        # Embedding layers one for user, one for poi and one for each G@P\n",
    "        self.poi_embedding = nn.Embedding(dimensions.npoi, embedding_dim, padding_idx=0)\n",
    "        self.g2_embed = nn.Embedding(dimensions.g2len, embedding_dim, padding_idx=0)\n",
    "        self.g3_embed = nn.Embedding(dimensions.g3len, embedding_dim, padding_idx=0)\n",
    "        self.g4_embed = nn.Embedding(dimensions.g4len, embedding_dim, padding_idx=0)\n",
    "        self.g5_embed = nn.Embedding(dimensions.g5len, embedding_dim, padding_idx=0)\n",
    "        self.g6_embed = nn.Embedding(dimensions.g6len, embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Dropout layer for embeddings\n",
    "        self.e_drop = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim, hidden_size=lstm_hidden_dim, batch_first=True\n",
    "        )\n",
    "\n",
    "        # Linear layers for prediction tasks\n",
    "        self.linear_poi = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.npoi)\n",
    "        self.linear_g2 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g2len)\n",
    "        self.linear_g3 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g3len)\n",
    "        self.linear_g4 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g4len)\n",
    "        self.linear_g5 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g5len)\n",
    "        self.linear_g6 = nn.Linear(lstm_hidden_dim + embedding_dim, dimensions.g6len)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.top1 = AccuracyAtK(1)\n",
    "        self.top5 = AccuracyAtK(5)\n",
    "        self.top10 = AccuracyAtK(10)\n",
    "        self.top20 = AccuracyAtK(20)\n",
    "        self.mrr = MeanReciprocalRank()\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, w):\n",
    "\n",
    "        if type(w) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "        elif type(w) == nn.LSTM:\n",
    "            for name, param in w.named_parameters():\n",
    "                if \"bias\" in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "                elif \"weight\" in name:\n",
    "                    nn.init.kaiming_normal_(param)\n",
    "        elif type(w) == nn.Embedding:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.weight[0], 0)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"forward passes the batch through the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : `tuple[torch.Tensor]`\n",
    "            A tuple of tensors ordered as follows:\n",
    "            (users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6)\n",
    "        \"\"\"\n",
    "\n",
    "        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = batch\n",
    "\n",
    "        B, T = poi.shape\n",
    "\n",
    "        # make it so  that users are tiled T times\n",
    "        users = users.repeat(T, 1).T\n",
    "\n",
    "        e_poi = self.e_drop(self.poi_embedding(poi))\n",
    "        e_gap2 = self.e_drop(self.g2_embed(x_geoHash2))\n",
    "        e_gap3 = self.e_drop(self.g3_embed(x_geoHash3))\n",
    "        e_gap4 = self.e_drop(self.g4_embed(x_geoHash4))\n",
    "        e_gap5 = self.e_drop(self.g5_embed(x_geoHash5))\n",
    "        e_gap6 = self.e_drop(self.g6_embed(x_geoHash6))\n",
    "\n",
    "        h_t, c_t = self.lstm(e_poi)\n",
    "\n",
    "        # dense layers\n",
    "        next_poi = self.linear_poi(torch.cat((h_t, e_poi), dim=2))\n",
    "        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n",
    "        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n",
    "        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n",
    "        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n",
    "        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n",
    "\n",
    "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/loss_gap2\", loss_gap2)\n",
    "        self.log(\"train/loss_gap3\", loss_gap3)\n",
    "        self.log(\"train/loss_gap4\", loss_gap4)\n",
    "        self.log(\"train/loss_gap5\", loss_gap5)\n",
    "        self.log(\"train/loss_gap6\", loss_gap6)\n",
    "        self.log(\"train/loss_poi\", loss_poi)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "\n",
    "        top1_acc = self.top1(poi_pred, y[1])\n",
    "        top5_acc = self.top5(poi_pred, y[1])\n",
    "        top10_acc = self.top10(poi_pred, y[1])\n",
    "        top20_acc = self.top20(poi_pred, y[1])\n",
    "        mrr = self.mrr(poi_pred, y[1])\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "        self.log(\"val/loss_gap2\", loss_gap2)\n",
    "        self.log(\"val/loss_gap3\", loss_gap3)\n",
    "        self.log(\"val/loss_gap4\", loss_gap4)\n",
    "        self.log(\"val/loss_gap5\", loss_gap5)\n",
    "        self.log(\"val/loss_gap6\", loss_gap6)\n",
    "        self.log(\"val/loss_poi\", loss_poi)\n",
    "\n",
    "        # log \"leaderboard\" metrics\n",
    "        self.log(\"val/top1\", top1_acc)\n",
    "        self.log(\"val/top5\", top5_acc)\n",
    "        self.log(\"val/top10\", top10_acc)\n",
    "        self.log(\"val/top20\", top20_acc)\n",
    "        self.log(\"val/mrr\", mrr)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer and scheduler\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Components\n",
    "\n",
    "\n",
    "class attn_LSTM(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim):\n",
    "        super(attn_LSTM, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.U = nn.Linear(hidden_dim, 4 * hidden_dim)\n",
    "\n",
    "        self.s_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "        self.t_W = nn.Linear(embedding_dim, 4 * hidden_dim)\n",
    "\n",
    "    def forward(self, x, hidden, spatial, temporal, numTimeSteps):\n",
    "        h_t, c_t = hidden\n",
    "\n",
    "        previous_h_t = h_t\n",
    "        previous_c_t = c_t\n",
    "\n",
    "        allGates_preact = (\n",
    "            self.W(x) + self.U(previous_h_t) + self.s_W(spatial) + self.t_W(temporal)\n",
    "        )\n",
    "\n",
    "        input_g = allGates_preact[:, :, : self.hidden_dim].sigmoid()\n",
    "        forget_g = allGates_preact[\n",
    "            :, :, self.hidden_dim : 2 * self.hidden_dim\n",
    "        ].sigmoid()\n",
    "        output_g = allGates_preact[\n",
    "            :, :, 2 * self.hidden_dim : 3 * self.hidden_dim\n",
    "        ].sigmoid()\n",
    "        c_t_g = allGates_preact[:, :, 3 * self.hidden_dim :].tanh()\n",
    "\n",
    "        c_t = forget_g * previous_c_t + input_g * c_t_g\n",
    "        h_t = output_g * c_t.tanh()\n",
    "\n",
    "        batchSize = x.shape[0]\n",
    "        h_t = h_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
    "        c_t = c_t.view(batchSize, numTimeSteps, self.hidden_dim)\n",
    "\n",
    "        return h_t, c_t\n",
    "\n",
    "\n",
    "def get_neighbours(adj_matrix, poi):\n",
    "    neigh_indices_list = []\n",
    "    max_length = 0\n",
    "\n",
    "    for batch_poi in poi:\n",
    "        batch_indices = []\n",
    "        for single_poi in batch_poi:\n",
    "            poi_row = adj_matrix[single_poi]\n",
    "            neigh_indices = torch.where(poi_row == 1)[0]\n",
    "            batch_indices.append(neigh_indices)\n",
    "            max_length = max(max_length, len(neigh_indices))\n",
    "\n",
    "        neigh_indices_list.append(batch_indices)\n",
    "\n",
    "    padded_neigh_indices_list = []\n",
    "    for batch_indices in neigh_indices_list:\n",
    "        padded_batch_indices = pad_sequence(\n",
    "            batch_indices, batch_first=True, padding_value=0\n",
    "        )\n",
    "        padded_neigh_indices_list.append(padded_batch_indices)\n",
    "\n",
    "    padded_tensor = torch.stack(padded_neigh_indices_list)\n",
    "\n",
    "    return padded_tensor\n",
    "\n",
    "\n",
    "class GRNSelfAttention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, n_heads):\n",
    "\n",
    "        super(GRNSelfAttention, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.Wp = nn.Linear(hidden_dim, hidden_dim)  # embeddings to pre-concat\n",
    "        self.Wa = nn.Linear(2 * hidden_dim, hidden_dim)  # concatenation to pre-softmax\n",
    "\n",
    "        # total size = 3 * (hidden_dim) ** 2, quadratic in embedding size\n",
    "\n",
    "    def forward(self, poi, neighbors):\n",
    "        \"\"\"forward\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        poi: torch.Tensor\n",
    "            A batched tensor of embedded POI vectors, (B x H) where H is the\n",
    "            embedding dimension\n",
    "        neighbors: torch.Tensor\n",
    "            A batched tensor of sequences of embedded POI vectors that are extracted\n",
    "            from an adjacency matrix (temporal or spatial neighbors of POI),\n",
    "            (B x N x H), where N is the number of neighbours of POI, B is the\n",
    "            batch size, H is the embedding dimension, and must be the same as POI\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[torch.Tensor, torch.Tensor]\n",
    "          A tuple containing the self-attention weighted hadamard product of neighbour activations\n",
    "          in the first index, the attention weights in the second index.\n",
    "        \"\"\"\n",
    "        # assert len(poi.shape) == 2, f\"POI tensor must be 2D, got {poi.shape} instead\"\n",
    "        assert (\n",
    "            len(neighbors.shape) == 3\n",
    "        ), f\"Neighbour tensor must be 3D, got {neighbors.shape} instead\"\n",
    "\n",
    "        B, N, H = neighbors.shape\n",
    "\n",
    "        h_poi = self.Wp(poi)\n",
    "        h_n = self.Wp(neighbors)\n",
    "        h_cat = torch.cat([h_poi.expand(B, N, -1), h_n], dim=2)\n",
    "        h_att = F.leaky_relu(self.Wa(h_cat))\n",
    "\n",
    "        alpha = torch.nn.functional.softmax(h_att, dim=1)\n",
    "\n",
    "        p = torch.sum(alpha * h_n, dim=1)\n",
    "        return p, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRN (Graph Recurrent Network)\n",
    "class GRN(pl.LightningModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dims: BaselineDimensions,\n",
    "        spatial_graph,\n",
    "        temporal_graph,\n",
    "        hidden_dim,\n",
    "        n_heads,\n",
    "        dropout_rate=0.9,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super(GRN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.dims = dims\n",
    "\n",
    "        self.spatial_graph = spatial_graph.to(device)\n",
    "        self.temporal_graph = temporal_graph.to(device)\n",
    "\n",
    "        self.spatial_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
    "        self.temporal_attn = GRNSelfAttention(hidden_dim, n_heads)\n",
    "\n",
    "        self.lstm = attn_LSTM(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.user_embedding = nn.Embedding(dims.nuser, hidden_dim, padding_idx=0)\n",
    "        self.poi_embedding = nn.Embedding(dims.npoi, hidden_dim, padding_idx=0)\n",
    "        self.g2_embed = nn.Embedding(dims.g2len, hidden_dim, padding_idx=0)\n",
    "        self.g3_embed = nn.Embedding(dims.g3len, hidden_dim, padding_idx=0)\n",
    "        self.g4_embed = nn.Embedding(dims.g4len, hidden_dim, padding_idx=0)\n",
    "        self.g5_embed = nn.Embedding(dims.g5len, hidden_dim, padding_idx=0)\n",
    "        self.g6_embed = nn.Embedding(dims.g6len, hidden_dim, padding_idx=0)\n",
    "\n",
    "        self.linear_poi = nn.Linear(2 * hidden_dim, dims.npoi)\n",
    "        self.linear_g2 = nn.Linear(2 * hidden_dim, dims.g2len)\n",
    "        self.linear_g3 = nn.Linear(2 * hidden_dim, dims.g3len)\n",
    "        self.linear_g4 = nn.Linear(2 * hidden_dim, dims.g4len)\n",
    "        self.linear_g5 = nn.Linear(2 * hidden_dim, dims.g5len)\n",
    "        self.linear_g6 = nn.Linear(2 * hidden_dim, dims.g6len)\n",
    "\n",
    "        # extract indices from one-hot neighbor list\n",
    "        self.iota = torch.arange(self.dims.npoi, requires_grad=False, device=device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def init_weights(self, w):\n",
    "        if type(w) == nn.Linear:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.bias, 0)\n",
    "        elif type(w) == nn.LSTM:\n",
    "            for name, param in w.named_parameters():\n",
    "                if \"bias\" in name:\n",
    "                    nn.init.constant_(param, 0)\n",
    "                elif \"weight\" in name:\n",
    "                    nn.init.kaiming_normal_(param)\n",
    "        elif type(w) == nn.Embedding:\n",
    "            nn.init.kaiming_normal_(w.weight)\n",
    "            nn.init.constant_(w.weight[0], 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        users, poi, x_geoHash2, x_geoHash3, x_geoHash4, x_geoHash5, x_geoHash6 = x\n",
    "\n",
    "        B, T = poi.shape\n",
    "\n",
    "        users = users.repeat(T, 1).T\n",
    "\n",
    "        neighbors_spatial = self.spatial_graph[poi]\n",
    "        neighbors_temporal = self.temporal_graph[poi]\n",
    "\n",
    "        e_user = self.dropout(self.user_embedding(users))\n",
    "        e_poi = self.dropout(self.poi_embedding(poi))\n",
    "        e_gap2 = self.dropout(self.g2_embed(x_geoHash2))\n",
    "        e_gap3 = self.dropout(self.g3_embed(x_geoHash3))\n",
    "        e_gap4 = self.dropout(self.g4_embed(x_geoHash4))\n",
    "        e_gap5 = self.dropout(self.g5_embed(x_geoHash5))\n",
    "        e_gap6 = self.dropout(self.g6_embed(x_geoHash6))\n",
    "\n",
    "        spatial_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
    "        temporal_atts = torch.empty((B, T, self.hidden_dim), device=self.device)\n",
    "\n",
    "        for b in range(B):\n",
    "            for t in range(T):\n",
    "\n",
    "                print(b, t)\n",
    "\n",
    "                spatial_neigh = neighbors_spatial[b, t] * self.iota\n",
    "                temporal_neigh = neighbors_temporal[b, t] * self.iota\n",
    "\n",
    "                spatial_neigh = spatial_neigh[spatial_neigh != 0]\n",
    "                temporal_neigh = temporal_neigh[temporal_neigh != 0]\n",
    "\n",
    "                spatial_neigh = spatial_neigh.unsqueeze(0)\n",
    "                temporal_neigh = temporal_neigh.unsqueeze(0)\n",
    "\n",
    "                e_spatial = self.dropout(self.poi_embedding(spatial_neigh))\n",
    "                e_temporal = self.dropout(self.poi_embedding(temporal_neigh))\n",
    "\n",
    "                curr_poi = e_poi[b, t].unsqueeze(0)\n",
    "\n",
    "                spatial_p, _ = self.spatial_attn(curr_poi, e_spatial)\n",
    "                temporal_p, _ = self.temporal_attn(curr_poi, e_temporal)\n",
    "\n",
    "                # we are not using the batch dimension, so we squeeze it\n",
    "                spatial_atts[b, t] = spatial_p.squeeze()\n",
    "                temporal_atts[b, t] = temporal_p.squeeze()\n",
    "\n",
    "        # zero-init LSTM states\n",
    "        h_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
    "        c_t = torch.zeros(B, T, self.hidden_dim, device=self.device)\n",
    "\n",
    "        h_t, c_t = self.lstm(e_poi, (h_t, c_t), spatial_atts, temporal_atts, T)\n",
    "\n",
    "        next_poi = self.linear_poi(torch.cat((h_t, e_poi), dim=2))\n",
    "        next_g2 = self.linear_g2(torch.cat((h_t, e_gap2), dim=2))\n",
    "        next_g3 = self.linear_g3(torch.cat((h_t, e_gap3), dim=2))\n",
    "        next_g4 = self.linear_g4(torch.cat((h_t, e_gap4), dim=2))\n",
    "        next_g5 = self.linear_g5(torch.cat((h_t, e_gap5), dim=2))\n",
    "        next_g6 = self.linear_g6(torch.cat((h_t, e_gap6), dim=2))\n",
    "\n",
    "        return next_poi, next_g2, next_g3, next_g4, next_g5, next_g6\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "        self.log(\"train/loss\", loss)\n",
    "        self.log(\"train/loss_gap2\", loss_gap2)\n",
    "        self.log(\"train/loss_gap3\", loss_gap3)\n",
    "        self.log(\"train/loss_gap4\", loss_gap4)\n",
    "        self.log(\"train/loss_gap5\", loss_gap5)\n",
    "        self.log(\"train/loss_gap6\", loss_gap6)\n",
    "        self.log(\"train/loss_poi\", loss_poi)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        (\n",
    "            poi_pred,\n",
    "            gap2_pred,\n",
    "            gap3_pred,\n",
    "            gap4_pred,\n",
    "            gap5_pred,\n",
    "            gap6_pred,\n",
    "        ) = self(x)\n",
    "\n",
    "        loss_poi = self.criterion(\n",
    "            poi_pred.reshape(-1, self.dims.npoi), y[1].reshape(-1)\n",
    "        )\n",
    "        loss_gap2 = self.criterion(\n",
    "            gap2_pred.reshape(-1, self.dims.g2len), y[2].reshape(-1)\n",
    "        )\n",
    "        loss_gap3 = self.criterion(\n",
    "            gap3_pred.reshape(-1, self.dims.g3len), y[3].reshape(-1)\n",
    "        )\n",
    "        loss_gap4 = self.criterion(\n",
    "            gap4_pred.reshape(-1, self.dims.g4len), y[4].reshape(-1)\n",
    "        )\n",
    "        loss_gap5 = self.criterion(\n",
    "            gap5_pred.reshape(-1, self.dims.g5len), y[5].reshape(-1)\n",
    "        )\n",
    "        loss_gap6 = self.criterion(\n",
    "            gap6_pred.reshape(-1, self.dims.g6len), y[6].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            loss_poi + loss_gap2 + loss_gap3 + loss_gap4 + loss_gap5 + loss_gap6\n",
    "        ) / 6\n",
    "\n",
    "        self.log(\"val/loss\", loss)\n",
    "        self.log(\"val/loss_gap2\", loss_gap2)\n",
    "        self.log(\"val/loss_gap3\", loss_gap3)\n",
    "        self.log(\"val/loss_gap4\", loss_gap4)\n",
    "        self.log(\"val/loss_gap5\", loss_gap5)\n",
    "        self.log(\"val/loss_gap6\", loss_gap6)\n",
    "        self.log(\"val/loss_poi\", loss_poi)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Define optimizer and scheduler\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-4, amsgrad=True)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = encoder_dict[\"users\"].classes_.shape[0]\n",
    "n_pois = encoder_dict[\"pois\"].classes_.shape[0]\n",
    "n_g2 = encoder_dict[\"g2\"].classes_.shape[0]\n",
    "n_g3 = encoder_dict[\"g3\"].classes_.shape[0]\n",
    "n_g4 = encoder_dict[\"g4\"].classes_.shape[0]\n",
    "n_g5 = encoder_dict[\"g5\"].classes_.shape[0]\n",
    "n_g6 = encoder_dict[\"g6\"].classes_.shape[0]\n",
    "\n",
    "\n",
    "# account for the padding token\n",
    "dims = BaselineDimensions(\n",
    "    n_users + 1, n_pois + 1, n_g2 + 1, n_g3 + 1, n_g4 + 1, n_g5 + 1, n_g6 + 1\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mloi-1940849\u001b[0m (\u001b[33mpoi-dl-airo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dario/foursquare/wandb/run-20240511_234028-35txjio4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/35txjio4' target=\"_blank\">worthy-snowflake-203</a></strong> to <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/35txjio4' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/35txjio4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dario/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name          | Type               | Params\n",
      "------------------------------------------------------\n",
      "0  | poi_embedding | Embedding          | 4.6 M \n",
      "1  | g2_embed      | Embedding          | 114 K \n",
      "2  | g3_embed      | Embedding          | 287 K \n",
      "3  | g4_embed      | Embedding          | 561 K \n",
      "4  | g5_embed      | Embedding          | 1.4 M \n",
      "5  | g6_embed      | Embedding          | 2.8 M \n",
      "6  | e_drop        | Dropout            | 0     \n",
      "7  | lstm          | LSTM               | 8.4 M \n",
      "8  | linear_poi    | Linear             | 9.1 M \n",
      "9  | linear_g2     | Linear             | 229 K \n",
      "10 | linear_g3     | Linear             | 575 K \n",
      "11 | linear_g4     | Linear             | 1.1 M \n",
      "12 | linear_g5     | Linear             | 2.8 M \n",
      "13 | linear_g6     | Linear             | 5.7 M \n",
      "14 | criterion     | CrossEntropyLoss   | 0     \n",
      "15 | top1          | AccuracyAtK        | 0     \n",
      "16 | top5          | AccuracyAtK        | 0     \n",
      "17 | top10         | AccuracyAtK        | 0     \n",
      "18 | top20         | MeanReciprocalRank | 0     \n",
      "19 | mrr           | MeanReciprocalRank | 0     \n",
      "------------------------------------------------------\n",
      "37.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.6 M    Total params\n",
      "150.509   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb151fb98cd4e12a2500f72a61168b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d4cc2866544aa69ed086e6916f4f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbae70e3065498ea915c0a423959b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37651aebe134516b52a60cf6bb3cb45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dario/foursquare/.venv/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b78467c8614fd0bcd506a55983ecfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 21.1%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅██████████</td></tr><tr><td>lr-AdamW</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▃▂▄▂▃▄▃▄▂▃▂▃▃▂▂▂▁▂▂▂▂▃▂▂▂▂▃▁▃▂▂▂▂▂▃▃▂</td></tr><tr><td>train/loss_gap2</td><td>█▄▃▃▃▄▂▂▄▃▄▂▃▂▃▃▂▂▂▁▂▁▂▂▂▁▂▁▁▂▁▂▂▁▁▁▁▂▂▁</td></tr><tr><td>train/loss_gap3</td><td>█▄▃▃▂▄▂▃▄▃▃▂▃▂▃▃▂▂▂▁▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▂▂▃▃▁</td></tr><tr><td>train/loss_gap4</td><td>█▄▃▃▂▄▂▃▄▃▄▂▃▂▃▃▂▂▂▁▂▂▂▂▂▂▂▁▂▃▁▂▂▂▂▂▂▃▃▂</td></tr><tr><td>train/loss_gap5</td><td>█▅▃▃▂▄▂▃▄▃▄▂▄▂▃▃▂▂▂▁▂▂▂▂▃▂▂▂▂▃▁▃▃▂▂▂▂▄▃▂</td></tr><tr><td>train/loss_gap6</td><td>█▄▃▃▂▄▂▃▄▃▄▂▄▂▃▃▂▂▂▁▂▂▂▂▃▃▂▂▂▃▁▃▃▂▂▂▂▄▃▂</td></tr><tr><td>train/loss_poi</td><td>█▅▃▃▂▄▂▃▄▃▄▂▄▂▃▃▂▂▂▁▂▂▂▂▃▃▂▂▂▃▁▃▃▂▂▂▂▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val/loss</td><td>█▁</td></tr><tr><td>val/loss_gap2</td><td>█▁</td></tr><tr><td>val/loss_gap3</td><td>█▁</td></tr><tr><td>val/loss_gap4</td><td>█▁</td></tr><tr><td>val/loss_gap5</td><td>█▁</td></tr><tr><td>val/loss_gap6</td><td>█▁</td></tr><tr><td>val/loss_poi</td><td>█▁</td></tr><tr><td>val/mrr</td><td>▁█</td></tr><tr><td>val/top1</td><td>▁█</td></tr><tr><td>val/top10</td><td>▁█</td></tr><tr><td>val/top20</td><td>▁█</td></tr><tr><td>val/top5</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>lr-AdamW</td><td>0.0001</td></tr><tr><td>train/loss</td><td>1.60114</td></tr><tr><td>train/loss_gap2</td><td>0.4454</td></tr><tr><td>train/loss_gap3</td><td>0.82833</td></tr><tr><td>train/loss_gap4</td><td>1.17751</td></tr><tr><td>train/loss_gap5</td><td>1.88636</td></tr><tr><td>train/loss_gap6</td><td>2.48656</td></tr><tr><td>train/loss_poi</td><td>2.78268</td></tr><tr><td>trainer/global_step</td><td>1319</td></tr><tr><td>val/loss</td><td>1.75378</td></tr><tr><td>val/loss_gap2</td><td>0.66781</td></tr><tr><td>val/loss_gap3</td><td>1.05799</td></tr><tr><td>val/loss_gap4</td><td>1.41962</td></tr><tr><td>val/loss_gap5</td><td>2.10036</td></tr><tr><td>val/loss_gap6</td><td>2.52112</td></tr><tr><td>val/loss_poi</td><td>2.75576</td></tr><tr><td>val/mrr</td><td>0.7105</td></tr><tr><td>val/top1</td><td>0.7033</td></tr><tr><td>val/top10</td><td>0.72368</td></tr><tr><td>val/top20</td><td>0.7105</td></tr><tr><td>val/top5</td><td>0.71365</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-snowflake-203</strong> at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/35txjio4' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/35txjio4</a><br/> View project at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240511_234028-35txjio4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "TRAIN_BASELINE = True\n",
    "\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()\n",
    "# cargo-cult like stuff that is supposed to make you faster\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "ds = CheckinModule(encoded_data, batch_size=32, workers=4)\n",
    "\n",
    "wandb.init(project=\"trovailpoi\")\n",
    "\n",
    "classifier_baseline = HMT_RN(dims, embedding_dim=1024, lstm_hidden_dim=1024)\n",
    "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=40,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    log_every_n_steps=10,\n",
    "    logger=wandb_logger,\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        torchpl.callbacks.ModelCheckpoint(\n",
    "            monitor=\"val/loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            save_last=True,\n",
    "            filename=\"best_model\",\n",
    "        ),\n",
    "        torchpl.callbacks.EarlyStopping(\n",
    "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if TRAIN_BASELINE:\n",
    "    trainer.fit(model=classifier_baseline, datamodule=ds)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1bdff1a7a24cff8fe5fe499a328fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113296355567097, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dario/foursquare/wandb/run-20240511_195413-6ljioz32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32' target=\"_blank\">rose-frog-202</a></strong> to <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f1b244f3d74fdda9bba89df6c43c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-frog-202</strong> at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi/runs/6ljioz32</a><br/> View project at: <a href='https://wandb.ai/poi-dl-airo/trovailpoi' target=\"_blank\">https://wandb.ai/poi-dl-airo/trovailpoi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240511_195413-6ljioz32/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_GNN = False\n",
    "\n",
    "batch_size = 60\n",
    "wandb.finish()\n",
    "torch.cuda.empty_cache()\n",
    "# cargo-cult like stuff that is supposed to make you faster\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "wandb.init(project=\"trovailpoi\")\n",
    "\n",
    "classifier_gnn = GRN(\n",
    "    dims,\n",
    "    spatial_graph,\n",
    "    temporal_graph,\n",
    "    hidden_dim=1024,\n",
    "    n_heads=1,\n",
    "    dropout_rate=0.9,\n",
    "    device=device,\n",
    ")\n",
    "wandb_logger = WandbLogger(project=\"trovailpoi\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=40,\n",
    "    accelerator=\"auto\",\n",
    "    devices=[0],\n",
    "    log_every_n_steps=10,\n",
    "    logger=wandb_logger,\n",
    "    strategy=\"auto\",\n",
    "    callbacks=[\n",
    "        torchpl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "        torchpl.callbacks.ModelCheckpoint(\n",
    "            monitor=\"val/loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            save_last=True,\n",
    "            filename=\"best_model\",\n",
    "        ),\n",
    "        torchpl.callbacks.EarlyStopping(\n",
    "            monitor=\"val/loss\", patience=3, min_delta=0.0005, mode=\"min\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "if TRAIN_GNN:\n",
    "    trainer.fit(model=classifier_gnn, datamodule=ds)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapbook for Experimentation\n",
    "\n",
    "Ignore all code below, it's just for quick prototyping"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
